---
layout: post
categories: [NET]
description: none
keywords: NET
---
# 测试性能压测
http://blog.sina.com.cn/s/blog_4080505a01016o3d.html


最佳线程数:

性能压测的情况下，起初随着用户数的增加，QPS会上升，当到了一定的阀值之后，用户数量增加QPS并不会增加，或者增加不明显，同时请求的响应时间却大幅增加。这个阀值我们认为是最佳线程数。



为什么要找最佳线程数

1.过多的线程只会造成，更多的内存开销，更多的CPU开销，但是对提升QPS确毫无帮助

2.找到最佳线程数后通过简单的设置，可以让web系统更加稳定，得到最高，最稳定的QPS输出



最佳线程数的获取：

1、通过用户慢慢递增来进行性能压测，观察QPS，响应时间

2、根据公式计算:服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量

3、单用户压测，查看CPU的消耗，然后直接乘以百分比，再进行压测，一般这个值的附近应该就是最佳线程数量。



影响最佳线程数的主要因素：

1、IO

2、CPU

根据公式：服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量

一般来说是IO和CPU。IO开销较多的应用其CPU线程等待时间会比较长，所以线程数量可以开的多一些，相反则线程数量要少一些，其实有两种极端，纯IO的应用，比如proxy，则线程数量可以开到非常大（实在太大了则需要考虑线程切换的开销），这种应用基本上后端（比如这个proxy是代理搜索的）的QPS能有多少，proxy就有多少。

另一种是耗CPU的计算，这种情况一般来讲只能开到CPU个数的线程数量。但是并不是说这种应用的QPS就不高，往往这种应用的QPS可以很高。



QPS和线程数的关系

1、在最佳线程数量之前，QPS和线程是互相递增的关系，线程数量到了最佳线程之后，QPS持平，不在上升，甚至略有下降，同时相应时间持续上升。

2、同一个系统而言，支持的线程数越多（最佳线程数越多而不是配置的线程数越多），QPS越高



QPS和响应时间的关系

1、对于一般的web系统，响应时间一般有CPU执行时间+IO等待时间组成

2、CPU的执行时间减少，对QPS有实质的提升，IO时间的减少，对QPS提升不明显。如果要想明显提升QPS，优化系统的时候要着重优化CPU消耗大户。



最佳线程数和jvm堆内存得关系：

以上都是依据性能瓶颈在CPU的情况，对于java应用还有一个因素是FULL GC，我们要保证在最佳线程数量下，不会发生频繁FULL GC

根据公式：：(小GC时间间隔/rt)*(并发线程数量 * thm) <=young 计算得到的并发线程数量如果<最佳线程数量 则可能导致FULL GC较频繁，实际情况看来这种情况在web系统上非常少。不过可以模拟出来。

所以我们在设置jboss线程的时候，可以利用内存公式计算出来的线程数量来设置，通过压测和计算得到最佳线程数，然后设置线程数。



设置线程数量：

压测最佳线程数<真实设置的线程数量<内存极限线程数

比如，通过压测得到某系统的最佳线程数量是10，然后通过内存计算的线程数量是20，则，设置jboss的线程数量为15是可行的，如果直接设置了10，由于系统本身会受到一些依赖系统的变化而产生一些变化，比如系统依赖一些IO的响应时间会突然延长，由于线程数量还是10，其实这个时候最佳线程数量已经变成了13了，由于我们设置死了10，其结果就是导致qps下降，但是如果超过20，则又会引起FULL gc非常频繁，反过来影响QPS的下降。

即：真实设置的线程数过大，则会导致full gc;过小，则会导致qps下降

jboss的线程数设置：

对于jboss而言，设置线程数量要看使用了那种线程连接，如http、ajp等

http和ajp的设置是完全一样的，非常简单：

以ajp为例，找到server.xml或者tomcat-server.xml:

默认线程数量是200个

 <Connector port="8009" address="${jboss.bind.address}" connectionTimeout="15000" protocol="AJP/1.3" maxThreads="200" minSpareThreads="40" maxSpareThreads="75" maxPostSize="512000" acceptCount="300" bufferSize="16384" emptySessionPath="false" enableLookups="false" redirectPort="8443" useBodyEncodingForURI="true"/>

这里将默认的线程数量改成了20，当然相应的其他最小空闲线程数和最大空闲线程数也做一下调整：

<Connector port="8009" address="${jboss.bind.address}" connectionTimeout="15000" protocol="AJP/1.3" maxThreads="20" minSpareThreads="20" maxSpareThreads="20" maxPostSize="512000" acceptCount="300" bufferSize="16384" emptySessionPath="false" enableLookups="false" redirectPort="8443" useBodyEncodingForURI="true"/>



按照上方理论，jmeter压测得出实践到的最佳线程数：
在性能测试方法论中，很典型的方法就是二八原则，量化业务需求。

二八原则：指80%的业务量在20%的时间里完成。

如何理解，下面我们来个例子吧



用户登录场景：早高峰时段，8：50---9：10，5000坐席上线登陆。

      业务量：5000个 

      时间：20x60=1200秒

    吞吐量=80%x业务量/(20%*时间)=4000/240=16.7/秒

而并非5000/1200=4.1/秒

实际上，登录请求数分布是一个正态分布，最高峰时肯定比4.1/秒更高，高峰段实际上完成了80%的业务量，却只花了20%的时间。



温馨提示：

1.二八原则计算的结果并非在线并发用户数，是系统要达到的处理能力（吞吐量），初学者容易被误导，那这这个数据就去设置并发数，这是错误滴。

2.如果你的系统性能要求更高，也可以选择一九原则或更严格的算法，二八原则比较通用，一般系统性能比较接近这个算法而已，大家应该活用。

3.tps、响应时间、在线并发数三者关系详解：点击打开链接



三者关系图





2.  结论



小并发数区间测试，找拐点（如：100-300并发持续5分钟，可以发现上图中200并发时出现拐点）
大并发数区间测试，找符合需求的最大并发数（如：1800-2200并发持续5分钟，可以找到满足响应时间在3秒内的最大并发数2000）
利用最大并发数，压测环境在极限时的资源消耗（压测时间1小时以内）
80%最大并发数，进行稳定性测试（压测时间1小时以上）


注：执行机资源消耗必须监控上，保证能提供稳定的并发负载。

注：这里的响应时间是90%响应时间

tps:

每秒事务处理量 - 性能测试的术语介绍
TPS(Transaction Per Second)
每秒钟系统能够处理的交易或事务的数量。它是衡量系统处理能力的重要指标。TPS是LoadRunner中重要的性能参数指标。
