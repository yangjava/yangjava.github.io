---
layout: post
categories: [Hive]
description: none
keywords: Hive
---
# Hive优化实战Join

## 实战Join
在阐述Hive Join具体的优化方法之前，首先看一下Hive Join的几个重要特点，在实际使用时也可以利用下列特点做相应优化：
- 只支持等值连接
- 底层会将写的HQL语句转换为MapReduce，并且reduce会将join语句中除最后一个表外都缓存起来
- 当三个或多个以上的表进行join操作时，如果每个on使用相同的字段连接时只会产生一个mapreduce

## 具体的优化建议
- 合理的设置map和reduce数量
jvm重用。可在hadoop的mapred-site.xml中设置jvm被重用的次数，参数mapred.job.reuse.jvm.num.tasks

- 对于任务重没有依赖关系的阶段开启并发执行，设置属性：set hive.exec.parallel=true

- 查询分区表时，在查询条件中指定分区
- 尽量使用left semi join 替代in、not in、exists。
因为left semi join在执行时，对于左表中指定的一条记录，一旦在右表中找到立即停止扫描，效率更高

- 当多个表进行查询时，从左到右表的大小顺序应该是从小到大。原因：hive在对每行记录操作时会把其他表先缓存起来，直到扫描最后的表进行计算

- 对于经常join的表，针对join字段进行分桶，这样在join时不必全表扫描

- 小表进行mapjoin
如果在join的表中，有一张表数据量较小，可以存于内存中，这样该表在和其他表join时可以直接在map端进行，省掉reduce过程，效率高。设置方式主要分两种：
1）自动方式
set hive.auto.convert.join=true;
hive.mapjoin.smalltable.filesize，设置可以mapjoin的表的大小，默认值是25Mb
2）手动方式
select  /*+ mapjoin(A)*/  x.a,  y.b from t_x x join t_y y on x.id=y.id;

- 同一种数据的多种处理：从一个数据源产生的多个数据聚合，无需每次聚合都需要重新扫描一次。
例如：任务重需要执行insert overwrite table t_y select * from t_x;和

insert overwrite table t_z select * from t_x;
可以优化成：from t_x insert overwrite table t_y select * insert overwrite table t_z select *

- join中的数据倾斜处理
set hive.optimize.skewjoin=true;
set hive.skewjoin.key=100000;

当单个reduce节点处理数据阈值，会进行skewjoin，建议设置为平均数据量的2-4倍。
原理：会产生两个job，第一个job会将超过hive.skewjoin.key设置值的记录的key加上一些随机数，将这些相同的key打乱，然后分配到不同的节点上面进行计算。最后再启动一个job，在第一个job处理的基础上（即第一个job的reduce输出结果）再进行处理，将相同的key分发到相同的节点上处理。因为会产生两个job进行处理，在实际使用中还是要注意以及阈值的设置。
- limit调优
limit语句通常是执行整个语句后返回部分结果。但通过设置参数set hive.limit.optimize.enable=true，将针对查询对元数据进行抽样。同时可能还需要设置以下两个参数：
set hive.limit.row.max.size=10000;设置最小的采样容量
set hive.limit.optimize.limit.file=20;设置最大的采样样本数
这种优化方式存在一个缺点：有可能部分数据永远不会被处理到



