---
layout: post
categories: [Hadoop]
description: none
keywords: Hadoop
---
# Hadoop数据存储

## 传统系统常见文件存储格式
在 Windows 有很多种文件格式，例如：JPEG 文件用来存储图片、MP3 文件用来存储音乐、DOC 文件用来存储 WORD 文档。每一种文件存储某一类的数据，例如：我们不会用文本来存储音乐、不会用文本来存储图片。Windows 上支持的存储格式是非常的多。

## Hadoop中文件存储格式
Hadoop 上的文件存储格式，肯定不会像 Windows 这么丰富，因为目前我们用 Hadoop 来存储、处理数据。我们不会用 Hadoop 来听歌、看电影、或者打游戏。

文件格式是定义数据文件系统中存储的一种方式，可以在文件中存储各种数据结构，特别是 Row、Map，数组以及字符串，数字等。

在 Hadoop 中，没有默认的文件格式，格式的选择取决于其用途。而选择一种优秀、适合的数据存储格式是非常重要的。
后续我们要讲的，使用 HDFS 的应用程序（例如 MapReduce 或 Spark、Flink）性能中的最大问题、瓶颈是在特定位置查找数据的时间和写入到另一个位置的时间，而且管理大量数据的处理和存储也很复杂（例如：数据的格式会不断变化，原来一行有 12 列，后面要存储 20 列）。
Hadoop 文件格式发展了好一段时间，这些文件存储格式可以解决大部分问题。我们在开发大数据中，选择合适的文件格式可能会带来一些明显的好处：
可以保证写入的速度
可以保证读取的速度
文件是可被切分的
对压缩支持友好
支持schema的更改

某些文件格式是为通用设计的（如 MapReduce 或 Spark、Flink），而其他文件则是针对更特定的场景，有些在设计时考虑了特定的数据特征。因此，确实有很多选择。

## Hadoop丰富的存储格式

### Text File
简介
文本文件在非 Hadoop 领域很常见，在 Hadoop 领域也很常见。
数据一行一行到排列，每一行都是一条记录。以典型的 UNIX 方式以换行符\n终止。
文本文件是可以被切分的，但如果对文本文件进行压缩，则必须使用支持切分文件的压缩编解码器，例如 BZIP2。因为这些文件只是文本文件，压缩时会对所有内容进行编码。
可以将每一行成为 JSON 文档，可以让数据带有结构。

应用场景
仅在需要从 Hadoop 中直接提取数据，或直接从文件中加载大量数据的情况下，才建议使用纯文本格式或 CSV。

优缺点
优点
简单易读、轻量级
缺点
读写速度慢。
不支持块压缩，在 Hadoop 中对文本文件进行压缩/解压缩会有较高的读取成本，因为需要将整个文件全部压缩或者解压缩。
无法切分压缩文件（会导致较大的 map task）。

### Sequence File

简介
Sequence 最初是为 MapReduce 设计的，因此和 MapReduce 集成很好。
在 Sequence File 中，每个数据都是以一个 key 和一个 value 进行序列化存储，仅此而已。
Sequence File 中的数据是以二进制格式存储，这种格式所需的存储空间小于文本的格式。与文本文件一样，Sequence File 内部也不支持对键和值的结构指定格式编码。

应用场景
通常把 Sequence file 作为中间数据存储格式。例如：将大量小文件合并放入到一个 SequenceFIle 中

优缺点
优点
与文本文件相比更紧凑，支持块级压缩。
压缩文件内容的同时，支持将文件切分。
序列文件在 Hadoop 和许多其他支持 HDFS 的项目支持很好，例如：Spark。
它是让我们摆脱文本文件迈出第一步。
它可以作为大量小文件的容器。
缺点
对于具有 SQL 类型的 Hive 支持不好，需要读取和解压缩所有字段。
不存储元数据，并且对 schema 扩展中的唯一方式是在末尾添加新字段。

### Avro File
简介
Apache Avro 是与语言无关的序列化系统，由 Hadoop 创始人 Doug Cutting开发
Avro 是基于行的存储格式，它在每个文件中都包含 JSON 格式的 schema 定义，从而提高了互操作性并允许 schema 的变化（删除列、添加列）。 除了支持可切分以外，还此次块压缩。
Avro 是一种自描述格式，它将数据的 schema 直接编码存储在文件中，可以用来存储复杂结构的数据。
Avro 可以进行快速序列化，生成的序列化数据也比较小。

应用场景
适合于一次性需要将大量的列（数据比较宽）、写入频繁的场景
随着更多存储格式的发展，常用于 Kafka 和 Druid 中
直接将一行数据序列化在一个block中

优缺点
优点
Avro 是与语言无关的数据序列化系统。
Avro 将 schema 存储在 header 中，数据是自描述的。
序列化和反序列化速度很快。
Avro 文件是可切分的、可压缩的，非常适合在 Hadoop 生态系统中进行数据存储。
缺点
如果我们只需要对数据文件中的少数列进行操作，行式存储效率较低。例如：我们读取 15 列中的 2 列数据，基于行式存储就需要读取数百万行的 15 列。而列式存储就会比行式存储方式高效
列式存储因为是将同一列（类）的数据存储在一起，压缩率要比方式存储高

### RCFile
简介
RCFile 是为基于 MapReduce 的数据仓库系统设计的数据存储结构。它结合了行存储和列存储的优点，可以满足快速数据加载和查询，有效利用存储空间以及适应高负载的需求。
RCFile 是由二进制键/值对组成的flat文件，它与 sequence file 有很多相似之处。
在数仓中执行分析时，这种面向列的存储非常有用。当我们使用面向列的存储类型时，执行分析很容易。
注： 无法将数据直接加载到 RCFile 中。首先需要将数据加载到另一个表中，然后将其覆盖写入到新创建的 RCFile 中。

应用场景
常用在Hive中

RCFile 可将数据分为几组行，并且在其中将数据存储在列中。
RCFile 首先将行水平划分为行拆分（Row Group），然后以列方式垂直划分每个行拆分（Columns）。
RCFile 将行拆分的元数据存储为 record 的 key，并将行拆分的所有数据存储 value。
作为行存储，RCFile 保证同一行中的数据位于同一节点中。
作为列存储，RCFile 可以利用列数据压缩，并跳过不必要的列读取。

优缺点
优点
基于列式的存储，更好的压缩比。
利用元数据存储来支持数据类型。
支持 Split。
缺点
RC 不支持 schema 扩展，如果要添加新的列，则必须重写文件，这会降低操作效率。

### ORC File
简介
Apache ORC（Optimized Row Columnar，优化行列）是 Apache Hadoop 生态系统面向列的开源数据存储格式，它与 Hadoop 环境中的大多数计算框架兼容。
ORC 代表“优化行列”，它以比 RC 更为优化的方式存储数据，提供了一种非常有效的方式来存储关系数据，然后存储 RC 文件。
ORC 将原始数据的大小最多减少 75％，数据处理的速度也提高了。
常用在 Hive 中

优缺点
优点
比 TextFile，Sequence File 和 RC File 具备更好的的性能。
列数据单独存储。
带类型的数据存储格式，使用类型专用的编码器。
轻量级索引。
缺点
与 RC 文件一样，ORC 也是不支持列扩展的。

### Parquet File
简介
Parquet File 是另一种列式存储的结构，来自于 Hadoop 的创始人 Doug Cutting 的 Trevni 项目。
和 ORCFile 一样，Parquet 也是基于列的二进制存储格式，可以存储嵌套的数据结构。
当指定要使用列进行操作时，磁盘输入/输出操效率很高。
Parquet 与 Cloudera Impala 兼容很好，并做了大量优化。
支持块压缩。
与 RC 和 ORC 文件不同，Parquet serdes 支持有限的 schema 扩展。在 Parquet 中，可以在结构的末尾添加新列。
关于 Hive 对 Parquet 文件的支持的一个注意事项： Parquet 列名必须小写，这一点非常重要。如果 Parquet 文件包含大小写混合的列名，则 Hive 将无法读取该列。

优缺点
优点
和 ORC 文件一样，它非常适合进行压缩，具有出色的查询性能，尤其是从特定列查询数据时，效率很高
缺点
与 RC 和 ORC 一样，Parquet 也具有压缩和查询性能方面的优点，与非列文件格式相比，写入速度通常较慢。

ORC 文件格式压缩比 parquet 要高，parquet 文件的数据格式 schema 要比 ORC 复杂，占用的空间也就越高。
ORC 文件格式的读取效率要比 parquet 文件格式高。
如果数据中有嵌套结构的数据，则 Parquet 会更好。
Hive 对 ORC 的支持更好，对 parquet 支持不好，ORC 与 Hive 关联紧密。
ORC 还可以支持 ACID、Update 操作等。
Spark 对 parquet 支持较好，对 ORC 支持不好。
为了数据能够兼容更多的查询引擎，Parquet 也是一种较好的选择。

### ProtoBuf和Thrift
由于 Protobuf 和 Thrift 是不可 split 的，因此它们在 HDFS 中并不流行。

Arrow简介
Apache Arrow 是一个跨语言平台，是一种列式内存数据结构，主要用于构建数据系统。Apache Arrow 在 2016 年 2 月 17 日作为顶级 Apache 项目引入。

Apache Arrow 发展非常迅速，并且在未来会有更好的发展空间。 它可以在系统之间进行高效且快速的数据交换，而无需进行序列化，而这些成本已与其他系统（例如 Thrift，Avro 和 Protocol Buffers）相关联。

每一个系统实现，它的方法（method）都有自己的内存存储格式，在开发中，70%-80%的时间浪费在了序列化和反序列化上。

Arrow 促进了许多组件之间的通信。 例如，使用Python（pandas）读取复杂的文件并将其转换为Spark DataFrame。

Arrow是如何提升数据移动性能的
利用 Arrow 作为内存中数据表示的两个过程可以将数据从一种方法“重定向”到另一种方法，而无需序列化或反序列化。 例如，Spark 可以使用 Python 进程发送 Arrow 数据来执行用户定义的函数。
无需进行反序列化，可以直接从启用了 Arrow 的数据存储系统中接收 Arrow 数据。 例如，Kudu 可以将 Arrow 数据直接发送到 Impala 进行分析。
Arrow 的设计针对嵌套结构化数据（例如在 Impala 或 Spark Data 框架中）的分析性能进行了优化。

## 文件压缩格式
在 Hadoop 中，一般存储着非常大的文件，以及在存储 HDFS 块或运行 MapReduce 任务时，Hadoop 集群中节点之间的存在大量数据传输。 如果条件允许时，尽量减少文件大小，这将有助于减少存储需求以及减少网络上的数据传输。

Hadoop支持的压缩算法
Hadoop对文件压缩均实现org.apache.hadoop.io.compress.CompressionCodec接口，所有的实现类都在org.apache.hadoop.io.compress包下。

### 压缩算法比较
有不少的压缩算法可以应用到 Hadoop 中，但不同压缩算法有各自的特点。

| 压缩格式    | 工具    | 算法      | 文件扩展名    | 是否可切分 | 对应的编码/解码器                                  |
|---------|-------|---------|----------|-------|--------------------------------------------|
| DEFAULT | 无     | DEFAULT | .deflate | 否     | org.apache.hadoop.io.compress.DefaultCodec |
| Gzip    | gzip  | DEFAULT | .gz      | 否     | org.apache.hadoop.io.compress.GzipCodec    |
| bzip2   | bzip2 | bzip2   | .bz2     | 是     | org.apache.hadoop.io.compress.BZip2Codec   |
| LZO     | lzop  | LZO     | .lzo     | 是（索引） | com.hadoop.compression.lzo.LzopCodec       |
| LZ4     | 无     | LZ4     | .lz4     | 否     | org.apache.hadoop.io.compress.Lz4Codec     |
| Snappy  | 无     | Snappy  | .snappy  | 否     | org.apache.hadoop.io.compress.SnappyCodec  |

存放数据到 HDFS 中，可以选择指定的压缩方式，在 MapReduce 程序读取时，会根据扩展名自动解压。例如：如果文件扩展名为.snappy，Hadoop 框架将自动使用 SnappyCodec 解压缩文件。
































































