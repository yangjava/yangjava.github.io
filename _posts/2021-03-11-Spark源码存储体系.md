---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# Spark源码存储体系
无论是SparkContext的初始化，还是任务的提交与执行，始终都离不开存储体系。Spark为了避免Hadoop频繁读写磁盘造成磁盘I/O成为性能瓶颈，优先会将配置信息、计算结果等数据存入内存，这极大地提升了系统的执行效率。

## 序列化管理器SerializerManager
Spark中很多对象在通过网络传输或者写入存储体系时，都需要序列化。SparkEnv中有两个序列化的组件，分别是SerializerManager和closureSerializer。

SparkEnv中创建它们的代码如下。
```
val serializer = instantiateClassFromConf[Serializer](
    "spark.serializer", "org.apache.spark.serializer.JavaSerializer")
  logDebug(s"Using serializer: $ {serializer.getClass}")

  val serializerManager = new SerializerManager(serializer, conf, ioEncryptionKey)

val closureSerializer = new JavaSerializer(conf)
```
可以看到这里创建的serializer默认为org.apache.spark.serializer.JavaSerializer，用户可以通过spark.serializer属性配置其他的序列化实现，如org.apache.spark.serializer.Kryo-Serializer。closureSerializer的实际类型固定为org.apache.spark.serializer.JavaSerializer，用户不能够自己指定。

### 序列化管理器SerializerManager的属性

SerializerManager给各种Spark组件提供序列化、压缩及加密的服务。这里主要对SerializerManager中的各个成员属性进行介绍。

































