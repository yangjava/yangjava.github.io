---
layout: post
categories: [Gradle]
description: none
keywords: Gradle
---
# AI图像处理

## DragGAN
DragGAN ：用崭新的方式进行图像处理
火热近一个月的 DragGAN 源代码正式放出，目前在 GitHub 上已有超过 20,000 颗星标。该项目的论文被SIGGRAPH 2023 收录，论文以 StyleGAN2 架构为基础，实现了 “Drag” 关键点就能轻松 P 图的效果。

https://github.com/XingangPan/DragGAN

虽然最近扩散模型飞速发展，并产生了令人十分惊喜的逼真图像效果，然而，自然语言无法对图像的空间属性进行细粒度控制，文本条件方法主要用于高级语义编辑。此外，当前的扩散模型推理较慢，因为它们需要多个去噪步骤。因此，通过 GAN 作为图像编辑的思路，仍是一种行之有效的方法，基于 GAN 的学习生成图像流形，做出更加逼真的输出。比如在官方 Demo 中，作者轻触鼠标，一拖一拽，让狗狗微笑、让猫咪"Wink"、让倒影拉长、让太阳升起......完美贴合现实世界的物理结构和物理逻辑。

根据论文中的介绍，DragGAN 是一种用于直观基于点的图像编辑的交互方法。利用预先训练的 GAN 来合成不仅精确跟随用户输入的图像，而且停留在真实图像的流形上。与之前的许多方法相比，是一个不依赖于特定领域的建模或辅助网络的通用框架。这是基于两种新方法实现的：一是对隐编码的优化，这些隐编码增量地将多个抓取点移动到它们的目标位置；二是通过点跟踪过程来准确地跟踪抓取点的轨迹。这两个组件利用 GAN 中间特征图的判别质量来进行图像变形，实现交互性能。目前已经证明，此方法在基于 GAN 的操作中优于最先进的方法，并为使用生成先验的强大图像编辑开辟了新的方向。而对于未来的工作，作者计划将基于点的编辑扩展到 3D 生成模型。

DragGAN APP：无需部署， 在线体验
是不是觉得 DragGAN 效果很神奇？现在无需部署，开箱即玩！我们联合项目作者潘老师，在项目开源的第二天火速上线了 DragGAN 在线体验应用。比如通过拖动衣服的袖口、裤尾、领带或配饰来更改穿搭的款式和风格；通过拖动身体的某个部位来更改人的姿势和表情；通过拖动宠物的眼睛或嘴巴来做一些动作；通过拖动风景照中的树木和山川，来改变眼前的景色。

如果你希望改造 AI 生成的图像，现在有了一种崭新的方式——不妨打开 DragGAN 试一试，因为它几乎不需要学习成本，通过简单的拖拉拽即可对图像进行轻松编辑。

应用体验链接：https://openxlab.org.cn/apps/detail/XingangPan/DragGAN