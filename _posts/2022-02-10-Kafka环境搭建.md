---
layout: post
categories: [Kafka]
description: none
keywords: Kafka
---
# Kafka环境搭建


## 搭建前准备

### Java环境
Kafka采用的是Scala语言开发，运行在JVM上，因此部署Kafka的服务器需要安装JDK。

### Zookeeper环境
Kafka依赖于Zookeeper进行分布式协调，因此需要部署Zookeeper。Zookeeper的安装步骤如下：
```
# 下载Zookeeper安装包
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.5.8/apache-zookeeper-3.5.8-bin.tar.gz
#解压
tar -zxvf apache-zookeeper-3.5.8-bin.tar.gz
#重命名
mv apache-zookeeper-3.5.8-bin zookeeper-3.5.8
cd zookeeper-3.5.8
cp conf/zoo_sample.cfg conf/zoo.cfg
# 启动zookeeper服务
bin/zkServer.sh start
#查看zk的根目录相关节点
bin/zkCli.sh
ls /
```

## 单节点搭建
下载&解压安装包
```
wget https://archive.apache.org/dist/kafka/2.4.1/kafka_2.11-2.4.1.tgz  # 2.11是scala的版本，2.4.1是kafka的版本
tar -xzf kafka_2.11-2.4.1.tgz
cd kafka_2.11-2.4.1
```

修改配置文件
修改conf/server.properties配置文件：
```
#broker.id属性在kafka集群中必须要是唯一
broker.id=0
#kafka部署的机器ip和提供服务的端口号
listeners=PLAINTEXT://192.168.68.100:9092   
#kafka的消息存储文件
log.dir=/usr/local/data/kafka-logs
#kafka连接zookeeper的地址
zookeeper.connect=192.168.68.100:2181
```

## server.properties核心配置详解

| Property                   | Default           | Description                                                                                                                                          |
|----------------------------|-------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| broker.id                  | 0                 | 每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯一的即可。                                                                        |
| log.dirs                   | /tmp/kafka-logs   | kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最少partitions的路径下进行。                                                             |
| listeners                  | PLAINTEXT://:9092 | server接受客户端连接的端口，ip配置kafka本机ip即可                                                                                                                     |
| zookeeper.connect          | localhost:2181    | zooKeeper连接字符串的格式为：hostname:port，此处hostname和port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果是集群，连接方式为 hostname1:port1, hostname2:port2, hostname3:port3 |
| log.retention.hours        | 168               | 每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。                                                                                                                 |
| num.partitions             | 1                 | 创建topic的默认分区数                                                                                                                                        |
| default.replication.factor | 1                 | 自动创建topic的默认副本数量，建议设置为大于等于2                                                                                                                          |
| min.insync.replicas        | 1                 | 当producer设置acks为-1时，min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer发送消息会产生异常                                          |
| delete.topic.enable        | false             | 是否允许删除主题                                                                                                                                             |

启动服务
```
bin/kafka-server-start.sh config/server.properties &
```

## 集群搭建
对于Kafka来说，一个单独的broker意味着kafka集群只有一个节点。想要增加kafka集群中的节点数，只需要多启动几个broker的实例节点即可。

现在搭建三个节点的kafka集群，kafka集群三台服务器IP分别为：IP1、IP2、IP3，在这三台服务器上分别执行以下操作，修改对应kafka实例的IP及实例ID。

修改配置文件
修改conf/server.properties配置文件：
```
#broker.id属性在kafka集群中必须要是唯一
broker.id=0
#kafka部署的机器ip和提供服务的端口号
listeners=PLAINTEXT://IP1:9092   
#kafka的消息存储文件
log.dir=/usr/local/data/kafka-logs
#kafka连接zookeeper的地址，要把多个kafka实例组成集群，对应连接的zookeeper必须相同
zookeeper.connect=zk1:2181,zk2:2181,zk3:2181
```
启动服务
```
bin/kafka-server-start.sh config/server.properties &
```

## 环境验证
创建Topic

创建一个topic，副本数设置为3，分区数设置为2
```
bin/kafka-topics.sh --create --zookeeper zk1:2181,zk2:2181,zk3:2181 --replication-factor 3 --partitions 2 --topic my-replicated-topic
```

### 集群消费
log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka集群支持配置一个partition备份的数量。针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用。leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)。如果这个leader失效了，其中的一个follower将会自动的变成新的leader。

Producers
生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。

Consumers
传统的消息传递模式有2种：队列( queue) 和（publish-subscribe）

queue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。

publish-subscribe模式：消息会被广播给所有的consumer。

Kafka基于这2种模式提供了一种consumer的抽象概念：consumer group。

queue模式：所有的consumer都位于同一个consumer group 下。

publish-subscribe模式：所有的consumer都有着自己唯一的consumer group。

### 消费顺序
一个partition同一个时刻在一个consumer group中只能有一个consumer instance在消费，从而保证消费顺序。Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。

consumer group中的consumer instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息。

如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。

















