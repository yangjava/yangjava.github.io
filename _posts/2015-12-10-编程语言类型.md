---
layout: post
categories: Assembly
description: none
keywords: Assembly
---
# 编程语言类型
如对于C语言的变量，我们有整型，实型，字符型等。 那我们为什么需要为编程语言设计变量类型这个概念？

## 编程语言设计类型
为什么各种编程语言设计者不约而同地使用了【类型】这个概念，即使如Python这种不显式指定类型的语言，一样是强调类型这个概念。

最初的编程语言设计者是如何想到，为【变量】设计【类型】这个概念呢？有了类型这个概念后，能为编程带来什么样的好处呢？

如果我们是最初的那批编程语言的设计者，我们能够理所当然地想到为变量设计类型这一固有属性吗？为什么？或者说，如果为变量放弃了类型这个概念后，是否同样能够设计一套理所当然的编程语言。

## 为什么编程语言的都要定义数据类型
对于一个程序员来讲，写代码的第一件是请，恐怕就是需要定义一些数据类型。而程序本身，就是对这些数据类型进行操作，有没有人思考过，为什么每种语言编写的程序，开始都需要定义数据类型呢？

以下面的C代码为例，我们来说明这个问题：
```

#include<stdio.h>
 
int main()
{
    int a=100;
    int b=200;
 
    double a1=10.1;
    double b1=10.2;
 
    a=a+b;
 
    a1=a1+b1;
 
    getchar();
    return 0;
}
```
这段代码非常简单，定义了四个数据，两个类型。大家看，a=a+b;和a1=a1+b1;这两个语句，几乎一样，那么，我问你，这两个语句，在编译时，编译器会用同一段代码来替换这两个语句吗？

显然不可是同一段代码，因为浮点数和整数，在计算机里面，使用了不同的处理器，整数使用普通的CPU，而浮点数必须使用浮点运算器。所以，这两句话，产生的机器代码完全不同！

那么问题来了，编译器如何知道，在碰到两个数相加的时候，是使用浮点运算器的机器指令，还是使用普通CPU的机器指令？此时，编译器就会检查进行加法操作的两个加数的数据类型，根据他们的数据类型，来确定到底使用哪一个运算器的机器代码。此时，数据类型定义的意义就凸显出来了。

通过上述简单的描述，我们就能够清楚，任何编程语言（除了汇编，汇编只规定数据的字长），都会有自己的数据类型，数据类型背后，隐藏的是编译器或者解释器对数据处理方式的定义。知道了这个以后，我们在定义数据类型的时候，就应该知道，我们定义的这种数据类型，可以进行哪些操作，这些操作的规则是什么，这样我们才算真正掌握了这个数据类型。

更高级的语言，例如C++可以定义自己的数据类型和数据类型的算法，类的重载操作符就是一个例子。

## 类型的原理
实践中，无论你学习数学、物理还是别的什么，数字都是有类型的。 比如说，桌子两条边的夹角是90度，这个90就是有类型的，为了方便，我们记为90°。

然后，同样的，桌子的宽度是90厘米，这个90就是一个长度类型的数据，记为90cm。 这两个90是不能直接加的。桌子边长90cm，加上桌角90°，得个180——什么鬼东西这是？

类似的，有人调侃小学数学题：红色的恒星表面温度是4000℃，蓝色的恒星表面温度是9000℃，问它们的温度加起来等于多少？

问这种题目的都是弱智，对吧。“不同恒星表面温度加起来”是没有意义的。

进一步的，物理学有个手段叫“量纲分析”，简单说就是让数据的单位也参与运算，比如加速度的单位就是（米/秒²）。

那么，当你总结出一个物理公式时，就可以先做个“量纲分析”：公式等号左右两边算出来的东西，其量纲一样吗？不一样就丢掉吧，肯定错了！

类似的，两个项做加减？它们的量纲一样吗？不一样？你把加速度和速度加起来算什么鬼。

能通过量纲分析的也未必就对，但通不过量纲分析的肯定是个错误。

借助这个工具，我们可以花费尽量小的代价、尽量快的识别出错误，避免浪费更多时间。

类似的，在程序中，我们也可以借助类型，让编译器帮我们查错。

比如，小张的生日是7月1日，小王月薪￥12000；程序员脑抽，写了个计算公式：

```
int sum = zhang.birthday+wang.salary;
```

编译器马上就可以指出这是个错误：

错误，+两侧数据类型不匹配：datetime型数据和decimal型数据之间不能执行＋操作。

不仅如此，我们还可以借助类型，让编译器“心领神会”的帮我们选择（dispatch）正确操作。

比如，我们要给小张记个功，给小王涨100块钱薪水；如果没有类型系统，那么你可能得这样写：

//zhang.CV指向一块字符串区域，要往末尾续写就要计算原有CV的长度
```
zhang.CV = strcpy(zhang.CV + strlen(zhang.CV), "10月1日获得个人三等功。");

wang.salary += 100;
```
很麻烦，对吧。

但如果zhang.CV是一个string类型，那么就简单了：
```
zhang.CV += "10月1日获得个人三等功。";
wang.salary += 100;
```
编译器知道“字符串的＋操作就是往后面拼凑另一个字符串”，和 decimal 的数值增加不是一回事；而我们就可以忘记底层差异，都写成+=就行了，编译器会自动选择正确实现。

程序写起来是不是就变得简洁快捷多了？程序员的记忆负担是不是也减轻了？

假设你参加单位组织的知识竞赛，理论上你可以知无不言言无不尽，可以在试卷上奋笔疾书、充分展示自己的才华……

但现实中呢，答题有时间限制，不可能让你一个人说一天；试卷留的空白有限，不允许你长篇大论——有些不太专业的人甚至会搞出“试卷上留白太少写不完答案”之类飞机。于是你只能留下一句名言“我知道答案，但是地方太小写不下”……

计算机也一样：我们的内存并不是无限的，不可能允许你在“性别”里面填写“12岁前男12岁后女18岁后女变男20岁后男变女”……

咳咳，开个玩笑。实践中，很多时候，一个字节也是生死攸关的。比如你要处理几千万条信息，如果每条信息压缩一个字节，它可能就能放到内存里完成；但多了一个字节……

Out Of Memory，BOOM!

在正常使用的数据结构里，人的年龄一般是个unsigned char，单字节无符号整数最大可以表示到255，足够用了；如果你搞错了：
```
wang.age = wang.salary
```

编译器就会告诉你，“薪水”使用的类型decimal太大，放不到年龄使用的无符号单字节整型里面（提示你“操作可能造成数据溢出”）。

不仅如此。

如果完全用二进制表示整数或者简单定点数，那么天文数字（比如十后面三四十个零）、高精度小数（精确到小数点100位，但前90位都是0），这些是不是也太浪费空间了？当然应该上基于科学计数法的单精度、双精度数啊。

再比如，二进制仅仅是数字，英文字符、中文方块字，这些怎么表示？

因此，我们不得不制定各种各样的编码方案；而不同的编码方案支持的运算法则、具体的运算过程，肯定是不一样的。

比如，对应到CPU整数指令上，就有“单字节加”“双字节加”“四字节加”“八字节加”乃至“有符号数加”和“无符号数加”和“加进位位的加”和“不加进位位的加”等等区别；甚至BCD码表示的整数在加法运算后还必须附加一个DAA指令完成调整（相应的，减法要用DAS指令调整）……

这些，都是半点混淆不得的。

这还仅仅是整数加减法运算。再加上单精度、双精度浮点数，再加上四则运算以及正切余切平方求根取对数等等等等……

明白为什么现在没人用汇编编程了吧？

这些东西，都可以借助类型系统，让编译器自动的安排合适指令、确保计算结果正确。

说白了，这还是前面提到的 dispatch（当然，同时还有类型匹配与否的检查）。

过去，编程语言的类型系统往往仅仅包含“基本类型”的完整支持，对用户自定义数据结构只有有限的支持；面向对象彻底的改变了这一点：从此，就连用户自定义数据结构，也可以通过“晚绑定”在运行时dispatch了。

与之同时，面向对象编程也增加了“接口检查”之类动作——你可以调用 Person.Run()，但调用Stone.Run()编译器就会报错。因为“石头不会跑”。

这东西继续发展，还有强类型、弱类型，动态类型、静态类型，以及“我不关心你的类型，只关心你能不能执行某个操作”的鸭类型等等东西。

但归根结底，类型系统做的就是两件事：

1、根据类型安排合适的操作

2、借助类型系统发现部分逻辑错误

做为初学者、业余开发者，类型系统对你可能是个束缚，因为你实在搞不明白这东西是干嘛用的、为什么有那么多类型、这些类型都有哪些差异。那么“无”类型的脚本语言对你来说就非常方便。

但实际上，哪怕号称“只有字符串一种类型”的TCL语言也是支持各种数据类型的。只是在你看不见的地方，这种语言自动替你做了类型转换而已。

这种隐式转换反而容易形成很多“坑”。比如知乎上经常被吐槽的 javascript，甚至因为数据值的不同，其加法、判断等等等操作都会有不同结果——想要用好它，你就不得不死记硬背这些结果，或者写个表达式就上网查查真伪……呸，是上网查查“加法的正确用法”。这显然太过累人了。

对专业开发者，如前所述，类型系统是个极为重要极为犀利的工具。

用好它，一方面可以借助它的“自动分派”简化程序，另一方面又可以借助“类型检查”自动探测出很多很多的错误。

你的程序越复杂、规模越大，类型系统的重要性就越突出。


