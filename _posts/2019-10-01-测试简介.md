---
layout: post
categories: Test
description: none
keywords: Test
---
# 测试简介


## 软件测试过程

第一步：对要执行测试的产品/项目进行分析，确定测试策略，制定测试计划。该计划被审核批准后转向第二步。测试工作启动前一定要确定正确的测试策略和指导方针，这些是后期开展工作的基础。只有将本次的测试目标和要求分析清楚，才能决定测试资源的投入。

第二步：设计测试用例。设计测试用例要根据测试需求和测试策略来进行，进度压力不大时，应该设计的详细，如果进度、成本压力较大，则应该保证测试用例覆盖到关键性的测试需求。该用例被批准后转向第三步。

第三步：如果满足“启动准则”（EntryCriteria），那么执行测试。执行测试主要是搭建测试环境，执行测试用例。执行测试时要进行进度控制、项目协调等工作。

第四步：提交缺陷。这里要进行缺陷审核和验证等工作。

第五步：消除软件缺陷。通常情况下，开发经理需要审核缺陷，并进行缺陷分配。程序员修改自己负责的缺陷。在程序员修改完成后，进入到回归测试阶段。如果满足“完成准则”（ExitCriteria），那么正常结束测试。

第六步：撰写测试报告。对测试进行分析，总结本次的经验教训，在下一次的工作中改。

软件测试过程管理，主要包括软件测试是什么样的过程，如何评价一个软件测试过程，如何进行配置管理和测试风险分析以及测试成本的管理。

## 软件测试流程

1、制定测试计划

2、编辑测试用例

3、执行测试用例

4、发现并提交BUG

5、开发组修正BUG

6、对已修正BUG进行返测

7、修正完成的BUG将状态置为已关闭，未正确修正的BUG重新激活

## 测试用例

测试用例（Test Case）是为某个特殊目标而编制的一组测试输入、执行条件以及预期结果，以便测试某个程序路径或核实是否满足某个特定需求。

测试用例的要素为：版本号、模块名称、用例编号、用例名称、用例级别、预置条件、验证步骤、期望结果（含判断标准）、测试结果、测试时间、测试人员等。（其中核心要素为预置条件、验证步骤、期望结果）

测试用例的设计方法：等价类划分、边界值分析、错误推测法、因果图法、场景设计法

一份好的测试用例所要达到以下几点要求：测试用例必须完成对需求的完整覆盖（即用例和需求的双向可追溯性）；测试用例必须是可执行的；测试用例的结果唯一性；测试用例必须简洁明了

## 缺陷报告（提交bug）

一份有效的缺陷报告要素通常包括：标题、前提、测试环境、操作步骤、实际结果、期望结果、出现的频率、优先级、严重等级、附件（一般是图片形式）。
另外还会有一些附加信息，如测试人员、开发负责人等。

标题：简明扼要，无歧义


###  优先级
优先级 Priority（4个等级）：软件被修复的紧急程度
1--立即解决：缺陷导致系统几乎不能运行使用 或 严重妨碍测试的执行（需立即修改）
2--高优先级：缺陷严重，影响到测试了（当天或第二天要及时解决的）
3--正常：一般错误
4--低优先级：可以在开发有时间的时候处理，如页面文本框对齐显示

### 严重等级
严重等级 Severity（4个等级）：缺陷引起的故障对用户使用系统的影响
1--致命的：主流程不通，导致系统功能缺失、用户数据被破坏、系统崩溃、死机
2--严重的：影响流程的 比较严重的，比如系统主要功能部分未实现
3--一般：系统的次要功能没有完全实现，但不影响用户的正常使用
4--较小：操作不方便或遇到麻烦，但不影响功能的使用，如字体不美观、按钮大小不合适、文字排列对齐等（属于建议性或者美观方面的）

一般来说，缺陷越严重，优先级越高，但也有例外：
1）从用户角度看，缺陷不是很严重，但可能影响到测试执行了（优先级高严重等级低）
2） 有些缺陷比较严重，但由于技术的限制，暂时没法修改。这时优先级就降低了

### 附件
附件
有时候，用文字很难清楚描述缺陷，此时用图片（画笔指明问题）就很直观了
如何有效的报告缺陷？

单一准确：每个报告只针对一个缺陷，如果有多个缺陷，可能开发只修正了其中一个，其他的没有得到修改，加长了缺陷的生命周期

可以再现：不能忽视或省略任何一项操作步骤，特别是关键性的操作，如描述的不够清楚，RD（Research and Development engineer）就会过来沟通怎么操作的，浪费了大家的时间

完整统一：完整的描述信息

短小简练：使用关键词

特定条件：有些问题只在特定环境下存在

## 测试报告

测试报告是指把测试的过程和结果写成文档，对发现的问题和缺陷进行分析，为纠正软件的存在的质量问题提供依据，同时为软件验收和交付打下基础。

一份详细的测试报告包含足够的信息，包括产品质量和测试过程的评价，测试报告基于测试中的数据采集以及对最终的测试结果分析。

测试报告的主体框架为：

1、首页

·· 报告名称（软件名称+版本号+用户端类型（android，iphone，后台管理等等）+测试范围（单元，集成，系统，模块等等）+测试报告）

·· 报告委托方，报告责任方，报告日期等

·· 版本变化历史

·· 密级

2、引言

2.1编写目的

本测试报告的具体编写目的，指出预期的读者范围。

2.2 项目背景

对项目目标和目的进行简要说明。必要时包括简史，这部分不需要脑力劳动，直接从需求或者招标文件中拷贝即可。

2.3 系统简介

如果设计说明书有此部分，照抄。注意必要的框架图和网络拓扑图能吸引眼球。

2.4 术语和缩略语

列出设计本系统/项目的专用术语和缩写语约定。对于技术相关的名词和与多义词一定要注明清楚，以便阅读时不会产生歧义。

2.5 参考资料

3、测试概要

测试的概要介绍，包括测试的一些声明、测试范围、测试目的等等，主要是测试情况简介。（其他测试经理和质量人员关注部分）

3.1测试方法(和工具)

简要介绍测试中采用的方法(和工具)。

3.2测试范围

介绍本次所测试的软件功能

3.3测试环境与配置

简要介绍测试环境及其配置。

4、测试结果与缺陷分析

整个测试报告中这是最激动人心的部分，这部分主要汇总各种数据并进行度量，度量包括对测试过程的度量和能力评估、对软件产品的质量度量和产品评估。对于不需要过程度量或者相对较小的项目，例如用于验收时提交用户的测试报告、小型项目的测试报告，可省略过程方面的度量部分；而采用了CMM/ISO或者其他工程标准过程的，需要提供过程改进建议和参考的测试报告－主要用于公司内部测试改进和缺陷预防机制－则过程度量需要列出。

4.1测试执行情况与记录

描述测试资源消耗情况，记录实际数据。（测试、项目经理关注部分）

4.1.1测试组织

可列出简单的测试组架构图

4.1.2测试时间

列出测试的跨度和工作量，最好区分测试文档和活动的时间。数据可供过程度量使用。

4.1.3测试版本

4.2覆盖分析

4.2.1需求覆盖

需求覆盖率是指经过测试的需求/功能和需求规格说明书中所有需求/功能的比值，通常情况下要达到100%的目标。

4.2.2测试覆盖

需求/功能（或编号） 用例个数 执行总数 未执行 未/漏测分析和原因

测试覆盖率计算 执行数/用例总数 ×100%

.3缺陷的统计与分析

缺陷统计主要涉及到被测系统的质量，因此，这部分成为开发人员、质量人员重点关注的部分。

4.3.1缺陷汇总

被测系统 系统测试 回归测试 总计

合计

按严重程度

严重 一般 微小

按缺陷类型

用户界面 一致性 功能 算法 接口 文档 用户界面 其他

按功能分布

功能一 功能二 功能三 功能四 功能五 功能六 功能七

最好给出缺陷的饼状图和柱状图以便直观查看。俗话说一图胜千言，图标能够使阅读者迅速获得信息，尤其是各层面管理人员没有时间去逐项阅读文章。

4.3.2缺陷分析

本部分对上述缺陷和其他收集数据进行综合分析

缺陷综合分析

缺陷发现效率 = 缺陷总数/执行测试用时

可到具体人员得出平均指标

用例质量 = 缺陷总数/测试用例总数 ×100%

缺陷密度 = 缺陷总数/功能点总数

缺陷密度可以得出系统各功能或各需求的缺陷分布情况，开发人员可以在此分析基础上得出那部分功能/需求缺陷最多，从而在今后开发注意避免并注意在实施时予与关注，测试经验表明，测试缺陷越多的部分，其隐藏的缺陷也越多。

4.3.3残留缺陷与未解决问题

残留缺陷

评价：对这些问题的看法，也就是这些问题如果发出去了会造成什么样的影响

5、测试结论与建议

5.1 测试结论

1． 测试执行是否充分（可以增加对安全性、可靠性、可维护性和功能性描述）

2． 对测试风险的控制措施和成效

3． 测试目标是否完成

4． 测试是否通过

5． 是否可以进入下一阶段项目目标

5.2 建议

1．对系统存在问题的说明，描述测试所揭露的软件缺陷和不足，以及可能给软件实施和运行带来的影响

2．可能存在的潜在缺陷和后续工作

3．对缺陷修改和产品设计的建议

4．对过程改进方面的建议

6、附录

· 缺陷列表

· 缺陷等级定义标准

· 测试通过标准

## UI自动化

现在自动化测试已经成为测试人员提高薪资的一个必要技能，这里推荐几个我知道的UI自动化的方案：web页面的自动化Python+selenuim；移动端的自动化（ios+android）Python+appium。其他的方案还有很多，介于我没接触过也没了解过，所有就不瞎说了。要做UI自动化，还需要了解的知识有html、css、javascript。

## 接口测试（手工+自动化）

一个是手动做接口测试，推荐postman，适用于对数量比较少的接口去做测试，比如集成其他系统时的技术验证。多接口的批跑测试我接触到的是ant+jmeter工具，jmeter可以批跑接口，在每个请求里加上检查点。ant是Java的一种文件打包集成工具，可以控制调用jmeter，生产html格式的结果报告，方便查看结果

## 性能测试

性能测试是通过自动化的测试工具模拟多种正常、峰值以及异常负载条件来对系统的各项性能指标进行测试。负载测试和压力测试都属于性能测试，两者可以结合进行。通过负载测试，确定在各种工作负载下系统的性能，目标是测试当负载逐渐增加时，系统各项性能指标的变化情况。压力测试是通过确定一个系统的瓶颈或者不能接受的性能点，来获得系统能提供的最大服务级别的测试。
性能测试我主要接触过两个工具 loadrunner、jmeter。jmeter比较适合公司自己内部做一个性能评估，他是免费的，轻量型的，安装和使用都很方便，就是在报表和结果分析上没有那么完善和漂亮。loadrunner，大名鼎鼎，很多对外提供的数据报告都是只认可loadrunner，能生成完善的数据分析和漂亮的报表。

## 测试框架的演变

代码管理 Git
代码分析  FindBugs Sonar   给jar包也可以
单元测试  Junit
持续集成管理  Jenkins
自动化环境构建：Docker
自动化测试、研发、预发布环境管理：Chef、Puppet、Docker
灰度发布：灰度发布a/b测试    把线上流量引导到测试环境。放少量人，放落后地区，放年龄，或者a/b版本
质量监控：全链路分析、统一监控平台，性能问题。奔溃日志
前台自动化： selenium，appium,ATX,STF,UIAutomator,WebDriverAgent
服务端接口测试：
java:HttpClient、restAssured
python:Requests,httprunner
性能测试：Jmeter，nGrinder,Gating,Locust
编译器分析技术：gcc,javac,IIvm
插桩技术：jacoco
自研工具：测试框架与工具、WDA、Diffy/Qunit
平台构建能力：测试管理平台、DevOps/持续交付流程管理平台
开源平台与工具：Jenkins、Jenkins X、BlueOcean/K8s，容器管理技术
数据平台：ELK、Hadoop/Spark/tensorFlow大数据分析能力


## 测试框架介绍
进行代码库测试和生成测试数据的库。

测试框架
unittest – (Python 标准库) 单元测试框架。
nose – nose 扩展了 unittest 的功能。
contexts – 一个 Python 3.3+ 的 BDD 框架。受到C# – Machine.Specifications的启发。
hypothesis – Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。
mamba – Python 的终极测试工具， 拥护BDD。
PyAutoGUI – PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。
pyshould- Should 风格的断言，基于 PyHamcrest。
pytest- 一个成熟的全功能 Python 测试工具。
green- 干净，多彩的测试工具。
pyvows- BDD 风格的测试工具，受Vows.js的启发。
Robot Framework – 一个通用的自动化测试框架。
Web 测试
Selenium – Selenium WebDriver 的 Python 绑定。
locust – 使用 Python 编写的，可扩展的用户加载测试工具。
sixpack – 一个和语言无关的 A/B 测试框架。
splinter – 开源的 web 应用测试工具。
Mock测试
mock – (Python 标准库) 一个用于伪造测试的库。
doublex – Python 的一个功能强大的 doubles 测试框架。
freezegun – 通过伪造日期模块来生成不同的时间。
httmock – 针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。
httpretty – Python 的 HTTP 请求 mock 工具。
responses – 伪造 Python 中的 requests 库的一个通用库。
VCR.py – 在你的测试中记录和重放 HTTP 交互。
对象工厂
factoryboy – 一个 Python 用的测试固件 (test fixtures) 替代库。
mixer – 另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。
modelmommy – 为 Django 测试创建随机固件
代码覆盖率
coverage – 代码覆盖率测量。
伪数据
faker – 一个 Python 库，用来生成伪数据。
fake2db – 伪数据库生成器。
radar – 生成随机的日期/时间。
错误处理
FuckIt.py – FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。


## 码分析和Lint工具
进行代码分析，解析和操作代码库的库和工具。

- 代码分析
  - code2flow – 把你的 Python 和 JavaScript 代码转换为流程图。
  - pycallgraph -这个库可以把你的Python 应用的流程(调用图)进行可视化。
  - pysonar2 – Python 类型推断和检索工具。


- Lint工具
  - Flake8 – 模块化源码检查工具: pep8, pyflakes 以及 co。
  - Pylint – 一个完全可定制的源码分析器。
  - pylama – Python 和 JavaScript 的代码审查工具。

调试工具
用来进行代码调试的库。

调试器
ipdb – IPython 启用的 pdb。
pudb – 全屏，基于控制台的 Python 调试器。
pyringe – 可以在 Python 进程中附加和注入代码的调试器。
wdb – 一个奇异的 web 调试器，通过 WebSockets 工作。
winpdb – 一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。
django-debug-toolbar – 为 Django 显示各种调试信息。
django-devserver – 一个 Django 运行服务器的替代品。
flask-debugtoolbar – django-debug-toolbar 的 flask 版。


性能分析器
lineprofiler – 逐行性能分析。
memoryprofiler – 监控 Python 代码的内存使用。
profiling – 一个交互式 Python 性能分析工具。


其他
pyelftools – 解析和分析 ELF 文件以及 DWARF 调试信息。
python-statsd – statsd 服务器的 Python 客户端。
# 参考资料
测试框架介绍 [https://www.cnblogs.com/ck-zscs/p/16205122.html](https://www.cnblogs.com/ck-zscs/p/16205122.html)




