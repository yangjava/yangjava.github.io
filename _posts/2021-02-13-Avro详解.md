---
layout: post
categories: [Avro]
description: none
keywords: Avro
---
# Avro详解
Avro作为Hadoop下相对独立的子项目，是一个数据序列化的系统。

## Avro介绍
类似于其他序列化系统，Avro可以将数据结构或对象转化成便于存储或传输的格式，特别是在设计之初它可以用来支持数据密集型应用，适合于大规模数据的存储和交换。总之，Avro可以提供以下一些特性和功能：
- 丰富的数据结构类型；
- 快速可压缩的二进制数据形式；
- 存储持久数据的文件容器；
- 远程过程调用（RPC）；
- 简单的动态语言结合功能。

Avro和动态语言结合后，读写数据文件和使用RPC协议都不需要生成代码了，而代码作为一种可选的优化只需要在静态类型语言中实现。

Avro依赖于模式（Schema）。Avro数据的读/写操作很频繁，而这些操作都需要使用模式，这样可减少写入每个数据资料的开销，使得序列化快速而又轻巧。这种数据及其模式的自我描述方便了动态脚本语言的使用。

当Avro数据存储到文件中时，它的模式也随之存储，这样任何程序都可以对文件进行处理。如果读取数据时使用的模式与写入数据时使用的模式不同，那也很容易解决，因为读取和写入的模式都是已知的。

Avro模式是用JSON（一种轻量级的数据交换模式）定义的，这样对于已经拥有JSON库的语言来说就可以容易地实现。

Avro提供与诸如Thrift和Protocol Buffers等系统相似的功能，但是在一些基础方面还是有区别的，主要表现在以下几个方面：

动态类型：Avro并不需要与生成代码、模式和数据存放在一起，而整个数据的处理过程并不生成代码、静态数据类型等。这方便了数据处理系统和语言的构造。

未标记的数据：因为读取数据的时候模式是已知的，所以需要和数据一起编码的类型信息就很少了，这样序列化的规模也就小了。

不需要用户指定字段号：即使模式发生了改变，但是新旧模式都是已知的，所以处理数据时可以通过使用字段名称来解决差异问题。

## 模式声明
模式声明主要是定义数据的类型，Avro中的模式可以使用JSON通过以下方式表示。

1）JSON字符串，指定已定义的类型。

2）JSON对象，其形式为：

{"type"："typeName"……attributes……}

其中，typeName可以是原生的或衍生的类型名称，本章没有定义的属性可以视为元数据，但是其不能影响序列化数据的格式。

3）JSON数组，表示嵌入类型的联合。

声明的类型必须是Avro所支持的数据类型，其中包括原始类型（Primitive Types）和复杂类型（Complex Types），下面分别介绍它们。

原始类型名称包括以下几部分。

null：没有值；

boolean：二进制值；

int：32位有符号整数；

long：64位有符号整数；

float：单精度（32位）IEEE 754浮点数；

double：双精度（64位）IEEE 754浮点数；

bytes：8位无符号字节序列；

string：unicode字符序列。

原始类型没有特定的属性，其名称可以通过类型来定义，如模式"string"相当于：

{"type"："string"}

Avro支持六种复杂类型：记录（records）、枚举（enums）、数组（arrays）、映射（maps）、联合（unions）和固定型（fixed），下面一一介绍。

（1）记录（records）

记录使用类型名称“record”并且支持以下属性：

name：提供记录名称的JSON字符串（必须）。

namespace：限定名称的JSON字符串。

doc：向模式使用者提供说明的JSON字符串（可选）。

aliases：字符串的JSON数组，为记录提供代替名称（可选）。

field：一个JSON数组，用来列出字段（必须）。每个字段就是一个JSON对象且拥有以下属性。

·name：提供记录名称的JSON字符串（必须）。

·doc：为使用者提供字段说明的JSON字符串（可选）。

·type：定义模式的JSON对象，或者记录定义的JSON字符串（必须）。

·default：该字段的默认值用于读取缺少该字段的实例（可选）。如表16-1所示，允许的值依赖于字段的模式类型。联合字段的默认值对应于联合中的第一个模式。字节和固定字段的默认值是JSON字符，这里0～255的Unicode映射到0～255的8位无符号字节。

·order：指定该字段如何影响记录的排序（可选）。有效的值有“ascending”（默认）、“descending”或“ignore”。

·aliases：字符串的JSON数组，为该字段提供可选的名称（可选）。



例如，一个64位的链表可以定义为：

{

"type"："record"，

"name"："LongList"，

"aliases"：["LinkedLongs"]，//别名

"fields"：[

{"name"："value"，"type"："long"}，//每个元素都含有长整型

{"name"："next"，"type"：["LongList"，"null"]}

//下一元素

]

}

（2）枚举（enums）

枚举使用类型名称“enum”并且支持以下几种类型。

name：提供实例名称的JSON字符串（必须）。

namespace：限定名称的JSON字符串。

aliases：字符串的JSON数组，为枚举提供替代名称（可选）。

doc：对模式使用者提供说明的JSON字符串（可选）。

symbols：列出标记的JSON数组（必须）。枚举中的所有标记必须是唯一的，不允许有重复的标记。

例如，纸牌游戏可以定义为：

{"type"："enum"，

"name"："Suit"，

"symbols"：["SPADES"，"HEARTS"，"DIAMONDS"，"CLUBS"]

}

（3）数组（arrays）

数组使用类型名称“array”并且支持一个属性。

items：数组项目的模式。

例如，字符串数组可以定义为：

{"type"："array"，"items"："string"}

（4）映射（maps）

映射使用类型名称“map”并且支持一个属性。

values：映射值的模式。

映射值默认为字符串，例如，从字符串到长整型的映射可以声明为：

{"type"："map"，"values"："long"}

（5）联合（unions）

联合主要使用JSON数组表示，例如可以用["string"，"null"]声明一个是字符串或者null的模式。除了指定的记录、固定型（fixed）和枚举外，对于相同的类型，联合只能包含一个模式。例如，联合中不允许包含两个数组类型或两个映射类型，但是允许包含不同名称的两种类型。联合中不能直接包含其他的联合。

（6）固定型（fixed）

固定型使用类型名称“fixed”并且支持以下属性。

name：固定型名称的字符串（必须）。

namespace：限定名称的字符串。

aliases：提供替代名称的字符串的JSON数组（可选）。

size：说明每个值的字节数的整型（可选）。

例如，16字节大小的固定型可以声明为：

{"type"："fixed"，"size"：16，"name"："md5"}

记录、枚举和固定型都是指定的类型，其全名由两部分组成：名称和命名空间。全名为由点分开的名字序列，其名称部分和记录字段名字必须：

以字母A～Z或a～z或_开头；

后面应只含有A～Z、a～z、0～9或_。

在记录、枚举和固定型的定义中，全名可以通过以下几种方式定义。

指定名称和命名空间。如使用名称"name"："X"和命名空间"namespace"："org.foo"来表示全名org.foo.X。

指定全名。如果指定的名称中包含点，则可以使用名称作为全名，并且任何指定的命名空间都将被忽略。如使用名称"name"："org.foo.X"来表示全名org.foo.X。

只指定名称，且名称中不包含点。这种情况下命名空间取自外层的模式或协议，比如指定名称"name"："X"，其所在记录定义的字段则为org.foo.Y，即全名为org.foo.X。

总结以上后两种情况可得：如果名称包含点，则是全名；如果不包含点，则命名空间默认为外层定义的命名空间。原始类型没有命名空间并且它们的名称也不能定义为任何命名空间。

命名的类型和字段可以拥有别名。为方便模式的发展和处理不同的数据集，在实现中可以选择使用别名将作者的模式（writer’s schema）映射成读者的模式（reader’s schema）。使用别名可以改变作者的模式，例如，如果作者的模式命名为"Foo"，而读者的模式命名为"bar"且别名为"Foo"，那么在读取时即使"Foo"称作"Bar"也能实现。同理，如果数据曾经写成字段名为"x"的记录，那么即使是字段名为'"y"别名为"x"的记录也能读取，尽管"x"写成了"y"。

16.1.2　数据序列化

模式声明后就可以根据模式写入数据了。当数据存储或传输时需要对其序列化，需要注意的是，Avro数据和其模式会一起被序列化。基于Avro的RPC系统必须保证远程的数据接收器拥有写入数据的模式副本，因为读取数据时写入数据的模式是知道的，所以Avro数据本身不需要标记类型信息。

通常，序列化和还原序列化过程（见图16-1）可以看成是对模式深度优先、从左到右的遍历过程，并在遍历过程中序列化或还原序列化遇到的原始类型。

Avro指定两种序列化编码：二进制和JSON。在这两种序列化编码中，因为二进制编码速度快且生成的数据量小，所以大多数的应用程序使用二进制编码。但是基于调试和网络的应用程序有时使用JSON编码比较合适。下面先介绍各种类型的二进制编码。

原始类型的二进制编码有如下几种。

null编码成零字节。

boolean编码成单字节，值为0（false）或1（true）。

int和long使用可变长度的ZigZag编码 [1] ，如表16-2所示。



float占4字节，使用类似于Java中floatToIntBits的方法可以将浮点数转化成32位的整型，然后编码成低字节序的格式。

double占8字节，使用类似于Java中doubleToLongBits的方法可以将双精度数转化

为64位的整型，然后编码成低字节序的格式。

bytes根据数据的字节编码成长整型。

string根据UTF-8字符集编码成长整型。

如果UTF-8字符集中'f'、'o'、'o'的十六进制分别为66 6f 6f，并且字符串"foo"含有三（编码成十六进制06）个字符，那么"foo"编码为06 66 6f 6f。

复杂类型的二进制编码方法有如下几种。

（1）记录（records）

通过对声明的每个字段值按顺序编码来对记录进行编码。换句话说，记录的编码由每个字段的编码串联而成。例如，记录模式的代码如下：

{

"type"："record"，

"name"："test"，

"fields"：[

{"name"："a"，"type"："long"}，

{"name"："b"，"type"："string"}

]

}

以上代码中，假设a字段的值为27（十六进制为36），b字段的值为"foo"（十六进制为06 66 6f 6f），那么记录的编码仅仅是这些编码的串联，即十六进制序列36 06 66 6f 6f。

（2）枚举（enums）

枚举按整型编码，其中整型代表每个标志在模式中的位置（从0开始）。例如，枚举模式的代码如下：

{"type"："enum"，"name"："Foo"，"symbols"：["A"，"B"，"C"，"D"]}

上面的例子序列化时将被编码成整型0～3，其中0代表"A"，3代表"D"。

（3）数组（arrays）

数组编码成一系列块，每个块包含一个长整型的数值，长整形的数值组成为数组项，其中最后一块为0，表示是数组的结尾，每个数组项的模式都会编码。如果块中的值为负数，则取绝对值，紧跟数值后面的块的大小为长整型，表示块中的字节数。如果只映射记录部分字段，则利用块大小可以跳过部分数据。例如，数组模式为：

{"type"："array"，"items"："long"}

对于包含项3和27的数组，其数组包含两个长整型值，其中数组个数“2”使用ZigZag编码成十六进制为04，而3和27编码成十六进制分别为06和36，最后以0结尾，其数组编码成：04 06 36 00。

这种块表示方法允许读/写大小超过内存缓冲的数组，因为在不知道数组长度的情况下就可以开始写入。

（4）映射（maps）

映射的编码和数组相似，也是编码成一系列块，每个块包含一个长整型值，然后是键值对，值为0的块表示映射的结尾。如果块的值为负数，则取其绝对值。紧跟数值后面的块的大小为长整型，表示块中的字节数。如果只映射记录的部分字段，则利用块大小可以跳过部分数据。

同数组一样，在不知道映射长度的情况下就可以写入，因此这种块的表示方法也允许读/写大小超过内存缓冲的映射。

（5）联合（unions）

联合编码时先写入一个长整型值表示联合中每个模式值的位置（从0开始），再对联合中的值编码。例如，联合模式["string"，"null"]应如此编码：null为整数1（联合中null的索引，使用ZigZag编码成十六进制02）；字符串"a"为整数0（联合中"string"的索引）；随后为序列化的字符串61，所以最后这个联合编码应为00 02 61。

（6）固定型（fixed）

固定型实例编码可使用模式中声明的字节数。对于编码成JSON类型，除了联合之外，还可以参照表16-1中JSON类型与Avro类型的对应关系进行编码。联合的JSON编码如下所示：

如果值为null，那么按照JSON null来编码；

否则，按照带有名称/值的JSON对象进行编码，其中名称为类型名称，值为递归编码值。对于Avro的命名类型（记录、固定性和枚举）将使用用户指定的名称，对于其他类型将使用类型名。

例如，对于联合模式["null"，"string"，"Foo"]，其中Foo是记录名称，应如此编码：null作为null编码；

字符串"a"按照{"string"："a"}编码；

Foo实例按照{"Foo"：{……}}编码，这里{……}表示一个Foo实例的JSON编码。

需要注意的是，正确处理JSON编码数据仍需要模式，因为JSON编码并不区分int和long、float和double、记录（records）和映射（maps）、枚举（enums）和字符串（strings）等。

[1] ZigZag编码原使用于Protocol Buffers，是一种将有符号数映射成无符号数的一种编码方式。

16.1.3　数据排列顺序

对象化前最常使用的操作就是排序，在Avro确定了数据标准排列顺序后，就允许系统写入的数据可以被另外的系统高效地排序了，这是个很重要的优化。即使Avro二进制数据还没有反序列化成对象，也可以对其进行高效排序。

要对拥有相同模式的数据项进行比较，可以采用对模式的深度优先、从左到右递归成对的方式。遇到不能匹配的项即按原来顺序，比如boolean类型的数据和int类型的数据不能匹配，那就不用进行排序。具体来说，相同模式的两个项进行比较时须遵从下面的规则。

null数据总是相等的。

boolean类型中false排在true的前面。

int、long、float和double数据按照数值升序排列。

bytes和fixed数据根据8位无符号值按照字典序进行比较。

string数据根据Unicode按字典序进行比较，要注意的是，对字符串而言，既然UTF-8作为二进制编码使用，那么按字节排序和按字符串二进制数据排序是相同的。array数据根据元素按字典序进行比较。

enum数据根据枚举模式中符号的位置进行排序。例如，枚举的符号位["z"，"a"]把"z"排在"a"前面。

union数据先按照联合的分支进行排序，然后按照分支的类型排序。例如，联合["int"，"string"]中，所有整型将排在所有字符型值前，而整型和字符型各自按照上面的规则排序。

record数据根据字段按字典序排序。如果字段指定其顺序为：

·"ascending"，其值排序的顺序不变；

·"descending"，其值排序的顺序反转；

·"ignore"，排序时其值将忽略。

map数据不进行比较。试图比较包含映射的数据是非法的，除非映射是“有序”的，否则“忽略”记录字段。

16.1.4　对象容器文件

序列化后的数据需要存入文件中。Avro包含一个简单的对象容器文件，一个文件拥有一个模式，文件中所有存储的对象必须根据模式使用二进制编码写入。对象存储在可以压缩的块中，块之间使用同步机制为MapReduce处理提供高效的文件分离。文件中可能包含用户随意指定的元数据。那么一个文件包含：

文件头。

一个或多个文件数据块。

其中文件头包含：

4个字节，分别是ASCII码的o、b、j、1。

包含模式的文件元数据。

为此文件随机生成的16字节同步器。

文件的元数据包含：

指示元数据的一个键/值对的长整型。

每个对的字符串键和字节值。

所有以"Avro"开头的元数据属性是保留的，以下文件元属性主要用于：

avro. schema，包含存储在文件中对象的模式，如JSON数据（必须）。

avro. codec，编解码器名称，其编码器用来压缩诸如字符串的数据块。需要实现支持"null"和"deflate"编解码器，如果没有编解码器，那假设为"null"。

"null"编解码器不需要对数据解压缩，而"deflate"编解码器使用文档RFC1951中指定的deflate算法写入数据块并使用zlib库实现，要注意的是这个格式（不像RFC1950中的zlib格式）没有校验和。

一个文件头需要按照如下模式进行描述：

{"type"："record"，"name"："org.apache.avro.file.Header"，

"fields"：[

{"name"："magic"，"type"：{"type"："fixed"，"name"："Magic"，"size"：4}}，

{"name"："meta"，"type"：{"type"："map"，"values"："bytes"}}，

{"name"："sync"，"type"：{"type"："fixed"，"name"："Sync"，"size"：16}}，

]

}

文件数据块包括：

一个长整型，用于指示块中对象数目。

一个长整型，用于表示使用编解码器后，所在块中序列化对象的字节大小。

序列化对象，如果编解码器是指定的，则用它进行压缩。

16字节的文件同步器。

这样，即使不用反序列化，每个块的二进制数据也可以高效获得或跳过。这种块的大小、对象数目和同步器的结合可以检测出坏的块并且帮助保持数据的完整性。

图16-3表示了对象容器文件的具体格式。



图　16-3　对象容器文件的具体格式

16.1.5　协议声明

当Avro用于RPC时，Avro使用协议描述远程过程调用RPC接口。和模式一样，它们是用JSON文本来定义的。协议是带有以下属性的JSON对象：

protocol，协议名称的字符串（必须）。

namespace，限定名称的可选字符串。

doc，描述协议的可选字符串。

types，指定类型（记录、枚举、固定型和错误）定义的可选列表。错误的定义和记录一样，只不过错误使用"error"而记录使用"record"，要注意不允许对指定类型的向前引用。

messages，一个可选的JSON对象，其键是消息名称，值是对象，任意两个消息不能拥有相同的名称。

模式中定义的名称和命名空间规则也同样适用于协议。下面介绍的协议消息可以拥有以下属性：

doc，消息的可选描述。

request，指定的类型化的参数模式列表（这和记录声明中的字段有相同的形式）。

response，响应模式。

error union，所声明的错误模式的联合（可选）。有效的联合会在声明的联合前面加上"string"，允许传递未声明的“系统”错误。例如，如果声明的错误联合是["AccessError"]，那么有效的联合是["string"，"AcessError"]。如果没有错误声明，那么有效的错误联合是["string"]。使用有效联合错误可以序列化，且协议的JSON声明只能包含声明过的联合。

one-way，布尔参数（可选）。

处理请求参数列表相当于处理没有名称的记录。既然读取的记录字段列表和写入的记录字段列表可以不同，那么调用者和响应者的请求参数也可以不同，这种区别的解决方法与记录字段间差异的解决方式相同。只有当回应的类型是“null”并且没有错误列出的时候，one-way参数才为真。

下面来举一个简单的HelloWorld协议的例子，它可以定义为：

{

"namespace"："com.acme"，//名称的限定

"protocol"："HelloWorld"，//协议名称

"doc"："Protocol Greetings"，//协议的说明

"types"：[

{"name"："Greeting"，"type"："record"，"fields"：[

{"name"："message"，"type"："string"}]}，

{"name"："Curse"，"type"："error"，"fields"：[

{"name"："message"，"type"："string"}]}]，

"messages"：{//消息

"hello"：{

"doc"："Say hello."，

"request"：[{"name"："greeting"，"type"："Greeting"}]，

"response"："Greeting"，

"errors"：["Curse"]

}

}

}

16.1.6　协议传输格式

消息可以通过不同的传输机制进行传输，而传输中的消息则是一些字节序列，那么传输机制需要支持：

请求信息的传送。

对应响应信息的接收。

服务器会对客户机的请求信息发送响应信息，这种响应机制就是特定传输，例如在HTTP中，由于HTTP直接支持请求和响应，所以这种传输是透明的，但是利用同一套接字传输多种不同客户线程的时候需要用特定的标识来区分不同客户的信息。

传输可能是无状态的也可能是有状态的。在无状态传输中，是假定消息发送没有建立连接状态。而有状态传输则建立了连接，这个连接可以用来传输不同的消息。下面我们会在握手（handshake）部分中深入分析。

当用HTTP协议进行传输时，每个Avro消息交换都是一对HTTP请求/响应。一个Avro协议的所有消息共享一个HTTP服务器上的URL，正常的和错误的Avro消息都应该使用200（OK）响应代码。尽管Avro请求和响应是HTTP请求和响应的整个内容，但也可能使用大量的编码。HTTP请求和响应的内容类型应该指定为“avro/binary”而且请求应该使用POST方法生成。Avro使用HTTP作为无状态传输。

Avro消息经过框架处理后由一系列缓冲区组成，消息框架是消息和传输之间的一层，用来优化某些操作。经过框架处理后的消息数据格式如下（见图16-4）。



图　16-4　消息的封装

1）由一系列缓冲区组成，其中缓冲区包括：

4个字节，用大端字节（big-endian）方法 [1] 表示的缓冲区长度。

缓冲区数据。

2）最后以空字节（zero-length）的缓冲区结束。

对于请求和响应消息格式，框架是透明的，任何消息可以表示为一个或多个缓冲。框架使得消息接收者更高效地从不同的渠道获取不同的缓冲，也使得开发者更高效地向不同的目的地存储不同的缓冲。特别是当复制大量二进制对象时，它可以减少读/写的次数。例如，如果RPC参数中包含一个MB大小的文件数据，那么一方面，数据可以从文件描述符直接复制到套接字上，另一方面，数据可以直接写入文件描述符而不需要进入用户空间。

一个简单且值得推荐的框架策略是：相对于那些大于正常输出缓冲区的单个二进制对象建立新的段。小的对象可以附加在缓冲区中，而较大的对象可以写入自己的缓冲区中。当读者需要读取大的对象时，可以直接处理整个缓冲区而不用复制。

使用握手的目的是确保客户机和服务器有对方的协议定义，这样客户机可以正确地对响应反序列化，且服务器可以正确地对请求反序列化。客户机和服务器都应在高速缓冲区中保留最近的协议，这样在大多数情况下，可以不需要额外的往返网络交换或重新获取全部传输协议就能完成握手。

在完成握手过程后执行RPC请求和响应，对于无状态的传输，在所有请求和响应之前都要进行握手，而对于有状态的传输，在成功响应之前，握手过程应该附加在请求和响应上，之后就不需要握手了。

握手过程使用以下记录模式，代码如下：

{

"type"："record"，

"name"："HandshakeRequest"，"namespace"："org.apache.avro.ipc"，

"fields"：[

{"name"："clientHash"，

"type"：{"type"："fixed"，"name"："MD5"，"size"：16}}，

{"name"："clientProtocol"，"type"：["null"，"string"]}，

{"name"："serverHash"，"type"："MD5"}，

{"name"："meta"，"type"：["null"，{"type"："map"，"values"："bytes"}]}

]

}

{

"type"："record"，

"name"："HandshakeResponse"，"namespace"："org.apache.avro.ipc"，

"fields"：[

{"name"："match"，

"type"：{"type"："enum"，"name"："HandshakeMatch"，

"symbols"：["BOTH"，"CLIENT"，"NONE"]}}，

{"name"："serverProtocol"，

"type"：["null"，"string"]}，

{"name"："serverHash"，

"type"：["null"，{"type"："fixed"，"name"："MD5"，"size"：16}]}，

{"name"："meta"，"type"：["null"，{"type"："map"，"values"："bytes"}]}

]

}

客户机在每个请求前面加上HandshakeRequest，表示包含客户机和服务器协议（clientHash！=null, clientProtocol=null, serverHash！=null）的哈希值，这里哈希值是JSON协议内容的128位MD5哈希值。如果客户机没有连接到给定的服务器，那么它发送的哈希值就是对服务器哈希值的猜测，否则它会发送之前从服务器中获得的哈希值。服务器响应的HandshakeResponse包含以下内容之一。

1）match=BOTH, serverProtocol=null, serverHash=null。如果客户机发送的是服务器协议的有效哈希值，并且服务器知道响应客户机哈希值的协议，那么请求是完整的，并且响应数据加在HandshakeResponse后面。

2）match=CLIENT, serverProtocol！=null, serverHash！=null。如果服务器事前知道客户机的协议，而客户机却发送了一个错误的服务器协议哈希值，那么请求是完整的并且响应数据加在HandshakeResponse之后。之后客户机必须使用返回的协议来处理响应，并且在高速缓存中保留这个协议和与服务器通信的哈希值。

3）match=NONE。如果服务器事先不知道客户机的协议，且服务器的协议哈希值是错误的，则serverHash和serverProtocol的值可能也为non-null。在这种情况下，客户机必须使用其协议文本（clientHash！=null, clientProtocol！=null, serverHash！=null）重新提交它的请求，并且服务器应该以正确的方式响应（match=BOTH, serverProtocol=null, serverHash=null）。另外meta字段是保留字段，用于以后增加握手的功能。

一次调用包括请求消息和与之对应的结果响应或错误消息。请求和响应包含可扩展的元数据，两种消息都会如上进行框架处理。调用请求的格式包括以下几种：

1）请求元数据，即类型值的映射。

2）消息名称，即一个Avro字符串。

3）消息参数，根据消息请求声明对参数进行序列化。

当消息声明为单向的并通过成功握手响应建立有状态的连接，那么不需要发送响应数据。否则需要发送，发送的调用请求的格式如下：

1）响应元数据，即类型字节的映射。

2）单字节的错误标志布尔值，然后，如果错误标志为假，消息响应，序列化每个消息响应模式。

如果错误标志为真，即为错误，序列化每个消息有效错误联合模式。

[1] 存放字节顺序的方法，大端方式将高位存放在低地址，小端方式将高位存放在高地址。

16.1.7　模式解析

无论从RPC还是从文件中获得Avro数据，由于模式已知，读者都可以解析数据，但是那个模式可能并不完全是所期望的模式。例如，如果数据写入的软件版本与读者不同，那么记录中的一些字段可能会增加或减少，这一部分将详述如何解决这种模式区别。

我们称用来写数据的模式为写者的模式，应用程序期望的模式为读者的模式。两个模式之间是否匹配可按照下面的规则进行判断。

1）如果两个模式符合以下情况之一则为匹配，否则为不匹配，并产生错误：

模式都是数组且项类型匹配。

模式都是映射且值类型匹配。

模式都是枚举且名称匹配。

模式都是固定型且大小和名称匹配。

模式都是记录且名称相同。

模式是其中之一为联合。

两个模式拥有相同的原始类型。

写者的模式可以提升为读者的模式，如下所示：

·int可以转化为long、float或者double；

·long可以转化为float或double；

·float可以转化为double。

2）如果两个都是记录，则：

字段的顺序可以不同，因为字段是通过名称来匹配的。

有相同名称字段的模式记录是递归解析的。

如果写者的记录中包含读者记录中没有的字段，那么写者字段的值将被忽略。

如果读者记录模式中有一个为默认值的字段，并且写者的模式中没有相同名称的字段，那么读者的这个字段应该使用默认值。

如果读者记录模式中有一个没有默认值的字段，并且写者的模式中没有相同名称的字段，那么将发出错误信号。

3）如果两个都是枚举，且写者的符号并不在读者的枚举中，那么产生错误。

4）如果两个都是数组，解析算法递归应用于读者和写者的数组项的模式。

5）如果两个都是映射，解析算法递归应用于读者和写者映射值的模式。

6）如果两个都是联合，对读者联合中匹配写者联合模式的第一个模式进行递归解析，如果没有匹配的，将产生错误。

7）如果读者为联合，而写者的不是，对读者联合中匹配所选写者模式的第一个模式进行递归解析，如果没有匹配的，将产生错误。

8）如果写者的是联合，读者的不是，且读者的模式匹配所选写者的模式，那么对它进行递归解析，如果它们不匹配，将产生错误。

模式解析时将忽略模式中协议说明的"doc"字段，因此，序列化时模式中的"doc"部分将被抛弃。

16.2　Avro的C/C++实现

本节主要介绍Avro的C/C++实现，其中在Avro C库中已经嵌入Jansson（Jansson为编译和操控JSON数据的C语言库），这样可以将JSON解析成模式结构。目前C/C++实现支持：所有原始和复杂数据类型的二进制编码和解码；向Avro对象容器文件进行存储；模式解析、提升和映射；写入Avro数据的有效方式和无效方式，但C语言接口暂不支持远程过程调用RPC。

Avro C为所有模式和数据对象进行引用计数，当引用数降为零时便释放内存。例如，创建和释放一个字符串：

avro_datum_t string=avro_string（"This is my string"）；

……

avro_datum_decref（string）；

当考虑创建更加详细的模式和数据结构时就会有一点复杂，例如，创建带有字符串字段的记录：

avro_datum_t example=avro_record（"Example"）；

avro_datum_t solo_field=avro_string（"Example field value"）；

avro_record_set（example，"solo"，solo_field）；

……

avro_datum_decref（example）；

在这个例子中，solo_field数据没有被释放，因为它有两个引用：原来的引用和隐藏在记录Example中的引用。调用avro_datum_decref（example）只能将引用数减少为一。如果想结束solo_field模式，则需要avro_datum_decref（solo_field）来完全删除solo_field数据并释放。

一些数据类型是可以“包装”和“给予”的，这可以让C程序员自由地决定谁负责内存的分配回收。以字符串为例，建立一个字符串数据有三种方式：

avro_datum_t avro_string（const char*str）；

avro_datum_t avro_wrapstring（const char*str）；

avro_datum_t avro_givestring（const char*str）；

如果使用avro_string，那么Avro C会复制字符串并且当不再引用时释放它。在有些情况下，特别是当处理大量数据时要避免这种内存复制，这时需要使用avro_wrapstring和avro_givestring。如果使用avro_wrapstring，那么Avro C不做任何内存处理，它只保存指向数据的指针，这时需要自己来释放字符串。需要注意的是，当使用avro_wrapstring时，在用avro_datum_decref（）取消引用数据前不要释放字符串。如果使用avro_givestring，那么Avro C在数据取消引用之后会释放字符串，从某种程度上说，avro_givestring将释放字符串的“责任”给了Avro C。需要注意的是，如果没有使用如malloc或strdup分配堆给字符串，则不要把“责任”给Avro C。例如，不能这样做：

avro_datum_t bad_idea=avro_givestring（"This isn't allocated on the heap"）；

写入数据时可以使用下面的函数：

int avro_write_data（avro_writer_t writer，

avro_schema_t writers_schema, avro_datum_t datum）；

如果省略writers_schema值，那么数据在发送给写数据的函数前必须检验数据格式的正确性。如果已经确定数据是正确的，那么可以设置writers_schema为NULL，这时Avro C不会检查格式。需要注意的是，写入Avro文件对象容器的数据总是要进行验证。

下面介绍一个简单例子，例子中建立了学生信息的数据库，并向数据库中读写记录：

/*student.c*/

#include＜avro.h＞

#include＜inttypes.h＞

#include＜stdio.h＞

#include＜stdlib.h＞

#include＜unistd.h＞

avro_schema_t student_schema；

/*id用于添加记录时为学生建立学号*/

int64_t id=0；

/*定义学生模式，拥有字段学号、姓名、学院、电话和年龄*/

#define STUDENT_SCHEMA\

"{\"type\"：\"record\"，\

\"name\"：\"Student\"，\

\"fields\"：[\

{\"name\"：\"SID\"，\"type\"：\"long\"}，\

{\"name\"：\"Name\"，\"type\"：\"string\"}，\

{\"name\"：\"Dept\"，\"type\"：\"string\"}，\

{\"name\"：\"Phone\"，\"type\"：\"string\"}，\

{\"name\"：\"Age\"，\"type\"：\"int\"}]}"

/*把JSON定义的模式解析成模式的数据结构*/

void init（void）

{

avro_schema_error_t error；

if（avro_schema_from_json（STUDENT_SCHEMA，

sizeof（STUDENT_SCHEMA），

＆student_schema，＆error））{

fprintf（stderr，"Failed to parse student schema\n"）；

exit（EXIT_FAILURE）；

}

}

/*添加学生记录*/

void add_student（avro_file_writer_t db, const char*name, const char*dept, const

char*phone, int32_t age）

{

avro_datum_t student=avro_record（"Student"，NULL）；

avro_datum_t sid_datum=avro_int64（++id）；

avro_datum_t name_datum=avro_string（name）；

avro_datum_t dept_datum=avro_string（dept）；

avro_datum_t age_datum=avro_int32（age）；

avro_datum_t phone_datum=avro_string（phone）；

/*创建学生记录*/

if（avro_record_set（student，"SID"，sid_datum）

||avro_record_set（student，"Name"，name_datum）

||avro_record_set（student，"Dept"，dept_datum）

||avro_record_set（student，"Age"，age_datum）

||avro_record_set（student，"Phone"，phone_datum））{

fprintf（stderr，"Failed to create student datum structure"）；

exit（EXIT_FAILURE）；

}

/*将记录添加到数据库文件中*/

if（avro_file_writer_append（db, student））{

fprintf（stderr，"Failed to add student datum to database"）；

exit（EXIT_FAILURE）；

}

/*解除引用，释放内存空间*/

avro_datum_decref（sid_datum）；

avro_datum_decref（name_datum）；

avro_datum_decref（dept_datum）；

avro_datum_decref（age_datum）；

avro_datum_decref（phone_datum）；

avro_datum_decref（student）；

fprintf（stdout，"Successfully added%s\n"，name）；

}

/*输出数据库中的学生信息*/

int show_student（avro_file_reader_t db，

avro_schema_t reader_schema）

{

int rval；

avro_datum_t student；

rval=avro_file_reader_read（db, reader_schema，＆student）；

if（rval==0）{

int64_t i64；

int32_t i32；

char*p；

avro_datum_t sid_datum, name_datum, dept_datum，

phone_datum, age_datum；

if（avro_record_get（student，"SID"，＆sid_datum）==0）{

avro_int64_get（sid_datum，＆i64）；

fprintf（stdout，"%"PRId64""，i64）；

}

if（avro_record_get（student，"Name"，＆name_datum）==0）{

avro_string_get（name_datum，＆p）；

fprintf（stdout，"%12s"，p）；

}

if（avro_record_get（student，"Dept"，＆dept_datum）==0）{

avro_string_get（dept_datum，＆p）；

fprintf（stdout，"%12s"，p）；

}

if（avro_record_get（student，"Phone"，＆phone_datum）==0）{

avro_string_get（phone_datum，＆p）；

fprintf（stdout，"%12s"，p）；

}

if（avro_record_get（student，"Age"，＆age_datum）==0）{

avro_int32_get（age_datum，＆i32）；

fprintf（stdout，"%d"，i32）；

}

fprintf（stdout，"\n"）；

/*释放记录*/

avro_datum_decref（student）；

}

return rval；

}

int main（void）

{

int rval；

avro_file_reader_t dbreader；

avro_file_writer_t db；

avro_schema_t extraction_schema, name_schema，

phone_schema；

int64_t i；

const char*dbname="student.db"；

init（）；

/*如果student.db存在，则删除*/

unlink（dbname）；

/*创建数据库文件*/

rval=avro_file_writer_create（dbname, student_schema，＆db）；

if（rval）{

fprintf（stderr，"Failed to create%s\n"，dbname）；

exit（EXIT_FAILURE）；

}

/*向数据库文件中添加学生信息*/

add_student（db，"Zhanghua"，"Law"，"15201161111"，25）；

add_student（db，"Lili"，"Economy"，"15201162222"，24）；

add_student（db，"Wangyu"，"Information"，"15201163333"，25）；

add_student（db，"Zhaoxin"，"Art"，"15201164444"，23）；

add_student（db，"Sunqin"，"Physics"，"15201165555"，25）；

add_student（db，"Zhouping"，"Math"，"15201166666"，23）；

avro_file_writer_close（db）；

fprintf（stdout，"\nPrint all the records from database\n"）；

/*读取并输出所有的学生信息*/

avro_file_reader（dbname，＆dbreader）；

for（i=0；i＜id；i++）{

if（show_student（dbreader, NULL））{

fprintf（stderr，"Error printing student\n"）；

exit（EXIT_FAILURE）；

}

}

avro_file_reader_close（dbreader）；

/*输出学生的姓名和电话信息*/

extraction_schema=avro_schema_record（"Student"，NULL）；

name_schema=avro_schema_string（）；

phone_schema=avro_schema_string（）；

avro_schema_record_field_append（extraction_schema，

"Name"，name_schema）；

avro_schema_record_field_append（extraction_schema，"Phone"，phone_schema）；

/*只读取每个学生的姓名和电话*/

fprintf（stdout，

"\n\nExtract Name＆Phone of the records from database\n"）；

avro_file_reader（dbname，＆dbreader）；

for（i=0；i＜id；i++）{

if（show_student（dbreader, extraction_schema））{

fprintf（stderr，"Error printing student\n"）；

exit（EXIT_FAILURE）；

}

}

avro_file_reader_close（dbreader）；

avro_schema_decref（name_schema）；

avro_schema_decref（phone_schema）；

avro_schema_decref（extraction_schema）；

/*最后释放学生模式*/

avro_schema_decref（student_schema）；

return 0；

}

如果要编译上面的C文件，则需要安装Avro C。首先可以从网站http：//www.apache.org/dyn/closer.cgi/avro/选择镜像下载avro-c-1.6.3.tar.gz文件，使用命令tar-zxvf avro-c-1.6.3.tar.gz解压后进入其目录，并使用命令./configure和make、make install进行编译安装。注意，需要在root的权限下进行安装。安装成功后，在编译C语言前需要将libavro加入动态链接库中，使用命令：

export LD_LIBRARY_PATH=/usr/local/lib：$LD_LIBRARY_PATH

然后对程序进行编译：

gcc-o student-lavro student.c

运行生成的执行文件可得到如图16-5所示的结果。运行时在当前目录下生成student.db对象容器文件，可以使用命令cat查看文件中的内容—先存储学生的模式，然后存储学生的记录信息，具体内容可参见16.1.4节“对象容器文件”和图16-3。



图　16-5　运行结果

下面介绍Avro的C++应用程序接口。虽然Avro并不需要使用代码生成器，但是使用代码生成工具可以更简单地使用Avro C++库。代码生成器既可以读取模式并输出模式数据的C++对象，也可以产生代码来序列化或反序列化对象等所有复杂的译码工作。即使使用C++核心库来编写序列化器或者解析器，产生的代码也可以说明如何使用这些库。下面举一个使用模式的简单例子，此例用来表示一个虚数：

{

"type"："record"，

"name"："complex"，

"fields"：[

{"name"："real"，"type"："double"}，

{"name"："imaginary"，"type"："double"}

]

}

假设JSON可用来表示存储在名为imaginary文件中的模式，那么产生代码分成两步：

第一步：

precompile＜imaginary＞imaginary.flat

预编译会将模式转化为代码生成器所使用的中间格式，中间文件是模式的文本形式，它是通过对模式类型树深度优先遍历得到的。

第二步：

python scripts/gen-cppcode.py--input=example.flat--output=example.hh--namespace=Math

上面的命令告诉代码生成器去读取模式作为输入，并且在example.hh中生成C++头文件。可选参数将指定对象放置的命名空间，如果没有指定命名空间，仍可得到默认的命名空间。下面是所产生代码的开始部分：

namespace Math{

struct complex{

complex（）：

real（），

imaginary（）

{}

double real；

double imaginary；

}；

以上代码是用C++表示的模式，它创建记录、默认构造函数并为记录的每个字段建立成员。下面是序列化数据的例子：

void serializeMyData（）

{

Math：complex c；

c.real=10.0；

c.imaginary=20.0；

//writer是实际I/O和缓冲结果的对象

avro：Writer writer；

//在对象上调用writer

avro：serialize（writer, c）；

//这时，writer将序列化后的数据存储在缓冲区中

InputBuffer buffer=writer.buffer（）；

}

使用生成的代码，调用对象的avro：serialize（）函数可以序列化数据，通过调用avro：InputBuffer对象可以获取数据，通过网络可以发送文件。下面读取序列化的数据到对象中：

void parseMyData（const avro：InputBuffer＆myData）

{

Math：complex c；

//reader为实际I/O读取的对象

avro：Reader reader（myData）；

//在对象上调用reader

avro：parse（reader, c）；

//此时，C中存放的是反序列化后的数据

}

在下面的代码中avro：serialize（）函数和avro：parse（）函数可用于处理用户数据类型，具体实现如下：

template＜typename Serializer＞

inline void serialize（Serializer＆s, const complex＆val, const boost：true_type＆）

{

s.writeRecord（）；

serialize（s, val.real）；

serialize（s, val.imaginary）；

s.writeRecordEnd（）；

}

template＜typename Parser＞

inline void parse（Parser＆p, complex＆val, const boost：true_type＆）{

p.readRecord（）；

parse（p, val.real）；

parse（p, val.imaginary）；

p.readRecordEnd（）；

}

以下内容也可加入avro命名空间中：

template＜＞struct is_serializable＜Math：complex＞：public boost：true_type{}；

这样为复杂结构建立类型特征，告诉Avro对象的序列化和解析功能可用。

除了上面介绍的使用Avro C++代码生成器来读写对象外，Avro C++也可以读入JSON模式。库函数提供了一些工具来读取存储在JSON文件或字符串中的模式，如下所示：

void readSchema（）

{

//My schema is stored in a file called"example"

std：ifstream in（"example"）；

avro：ValidSchema mySchema；

avro：compileJsonSchema（in, mySchema）；

}

上面代码读取文件并将JSON模式解析成avro：ValidSchema类型的对象。如果模式是无效的，将无法建立有效模式（ValidSchema）对象并抛出异常，那么如何从JSON存储的模式中建立有效模式对象呢？

有效模式（ValidSchema）可以保证开发者实际写入的类型匹配模式所期望的类型。现在重写序列化函数并需要检查模式：

void serializeMyData（const ValidSchema＆mySchema）

{

Math：complex c；

c.real=10.0；

c.imaginary=20.0；

//ValidatingWriter保证序列化写入正确类型的数据

avro：ValidatingWriter writer（mySchema）；

try{

avro：serialize（writer, c）；

//这时，ostringstream"os"存储序列化后的数据

}

catch（avro：Exception＆e）{

std：cerr＜＜"ValidatingWriter encountered an error："＜＜e.what（）；

}

}

这段代码和前面的区别就是用ValidatingWriter代替了Writer object。如果序列化函数错误地写入不匹配模式的类型，那么ValidatingWriter将抛出异常。ValidatingWriter会在写入数据的时候增加很多处理过程。对于产生的代码则没有必要进行验证，因为自动生成的代码是匹配模式的。然而，在写入和测试自己序列化的代码时加上安全验证还是必要的。解析数据时也可以使用有效模式，它不仅可以确保解析器读取的类型匹配模式有效，还提供了接口，通过该接口可以查询下一个期望的类型和记录成员字段的名称。下面的例子介绍了如何使用API：

void parseMyData（const avro：InputBuffer＆myData, const avro：ValidSchema＆mySchema）

{

//手动解析数据，解析对象将数据绑定到模式上

avro：Parser＜ValidatingReader＞parser（mySchema, myData）；

assert（nextType（parser）==avro：AVRO_RECORD）；

//开始解析

parser.readRecord（）；

Math：complex c；

std：string recordName；

assert（currentRecordName（parser, recordName）==true）；

assert（recordName=="complex"）；

std：string fieldName；

for（int i=0；i＜2；++i）{

assert（nextType（parser）==avro：AVRO_DOUBLE）；

assert（nextFieldName（parser, fieldName）==true）；

if（fieldName=="real"）{

c.real=parser.readDouble（）；

}

else if（fieldName=="imaginary"）{

c.imaginary=parser.readDouble（）；

}

else{

std：cout＜＜"I did not expect that！\n"；

}

}

parser.readRecordEnd（）；

}

上面的代码表明，如果编译时不知道模式，也可以通过写出解析数据的代码在运行时读取模式，并且查询ValidatingReader来了解序列化数据的内容。

在自己的代码中使用对象来建立模式是允许的，每个原始类型和复合类型都有模式对象，并且它们拥有共同的Schema基类。下面是一个为复数记录数组建立模式的例子：

void createMySchema（）

{

//首先建立复数类型

avro：RecordSchema myRecord（"complex"）；

//在记录中加入字段（每个字段又是一个模式）

myRecord.addField（"real"，avro：DoubleSchema（））；

myRecord.addField（"imaginary"，avro：DoubleSchema（））；

//这个复数记录和之前使用的一样，下面为这些记录的数组建立模式

avro：ArraySchema complexArray（myRecord）；

//如果模式是无效的将抛出

avro：ValidSchema validComplexArray（complexArray）；

//这样建立好了模式

//输出到屏幕上

validComplexArray.toJson（std：cout）；

}

以上代码建立的模式可能是无效的，因此，为了使用模式，需要将它转化为ValidSchma对象。执行上述代码可以得到：

{

"type"："array"，

"items"：{

"type"："record"，

"name"："complex"，

"fields"：[

{

"name"："real"，

"type"："double"

}，

{

"name"："imaginary"，

"type"："double"

}

]

}

}

随着时间的变化，程序模式期望的数据可能与之前存储的数据不同，为了把一个模式转化为另一个模式，Avro提供了不完全一样的模式规则。这种情况下，代码生成工具就有用了，对于每个生成的结构都会建立一个用来读取数据的特别索引结构，即使数据是用不同的模式写的。在example.hh中的索引结构如下：

class complex_Layout：public avro：CompoundOffset{

public：

complex_Layout（size_t offset）：

CompoundOffset（offset）

{

add（new avro：Offset（offset+offsetof（complex, real）））；

add（new avro：Offset（offset+offsetof（complex, imaginary）））；

}

}；

数据前若是float类型而不是double类型，根据模式解决规则，floats可以升级为doubles，只要新旧模式都有用，就会建立一个动态的解析器来读取代码生成结构的数据。如下所示：

void dynamicParse（const avro：ValidSchema＆writerSchema，

const avro：ValidSchema＆readerSchema）{

//实例化布局对象

Math：complex_Layout layout；

//创建已知类型布局和模式的模式解析器

resolverSchema（writerSchema, readerSchema, layout）；

//设置reader

avro：ResolvingReader reader（resolverSchema, data）；

Math：complex c；

//执行解析

avro：parse（reader, c）；

//这时，c中存放的是反序列化后的数据

}

16.3　Avro的Java实现

本节主要介绍Avro在Java中的实现。Java API现在的版本是1.6.3，其中主要的包有如下几个。

org. apache.avro：Avro内核类。

org. apache.avro.file：存放Avro数据的文件容器相关类。

org. apache.avro.generic：Avro数据的一般表示类。

org. apache.avro.io：Avro输入/输出工具类。

org. apache.avro.io.parsing：Avro格式的LL（1）语法实现。

org. apache.avro.ipc：进程间调用支持类。

org. apache.avro.ipc.stats：收集和显示IPC统计数据的工具类。

org. apache.avro.ipc.trace：追踪RPC递归调用的相关类。

org. apache.avro.mapred：使用Avro数据运行Hadoop MapReduce，其Map和Reduce功能用Java实现。

org. apache.avro.mapred.tether：使用Avro数据运行Hadoop MapReduce，其Map和Reduce功能在子进程运行。

org. apache.avro..reflect：使用Java映射为存在的类生成格式和协议。

org. apache.avro.specific：为格式和协议生成特定的Java类。

org. apache.avro.tool：Avro命令行工具类。

org. apache.avro.util：普通工具类。

关于上面各包中包含的类的具体使用可参见Java API，下面通过简单的例子介绍各类的用法。下面是用Java实现学生信息的存储和读取：

package cn.edu.ruc.cloudcomputing.book.chapter16；

/*student.java*/

import java.io.File；

import java.io.IOException；

import org.apache.avro.Schema；

import org.apache.avro.file.DataFileReader；

import org.apache.avro.file.DataFileWriter；

import org.apache.avro.generic.GenericData；

import org.apache.avro.generic.GenericDatumReader；

import org.apache.avro.generic.GenericDatumWriter；

import org.apache.avro.generic.GenericData.Record；

import org.apache.avro.util.Utf8；

public class student{

String fileName="student.db"；

String prefix="{\"type\"：\"record\"，\"name\"：\"Student\"，\"fields\"：["；

String suffix="]}"；

String fieldSID="{\"name\"：\"SID\"，\"type\"：\"int\"}"；

String fieldName="{\"name\"：\"Name\"，\"type\"：\"string\"}"；

String fieldDept="{\"name\"：\"Dept\"，\"type\"：\"string\"}"；

String fieldPhone="{\"name\"：\"Phone\"，\"type\"：\"string\"}"；

String fieldAge="{\"name\"：\"Age\"，\"type\"：\"int\"}"；

Schema studentSchema=Schema.parse（prefix+fieldSID+"，"+fieldName+"，"+

fieldDept+"，"+fieldPhone+"，"+fieldAge+suffix）；

Schema extractSchema=Schema.parse（prefix+fieldName+"，"+fieldPhone+suffix）；

int SID=0；

public static void main（String[]args）throws IOException{

student st=new student（）；

st.init（）；

st.print（）；

st.printExtraction（）；

}

/**

*初始化添加学生记录

**/

public void init（）throws IOException{

DataFileWriter＜Record＞writer=new DataFileWriter＜Record＞（

new GenericDatumWriter＜Record＞（studentSchema））.create（

studentSchema, new File（fileName））；

try{

writer.append（createStudent（"Zhanghua"，"Law"，"15201161111"，25））；

writer.append（createStudent（"Lili"，"Economy"，"15201162222"，24））；

writer.append（createStudent（"Wangyu"，"Information"，

"15201163333"，25））；

writer.append（createStudent（"Zhaoxin"，"Art"，"15201164444"，23））；

writer.append（createStudent（"Sunqin"，"Physics"，"15201165555"，25））；

writer.append（createStudent（"Zhouping"，"Math"，"15201166666"，23））；

}finally{

writer.close（）；

}

}

/**

*将学生信息添加到记录中

**/

private Record createStudent（String name, String dept, String phone, int age）{

Record student=new GenericData.Record（studentSchema）；

student.put（"SID"，（++SID））；

student.put（"Name"，new Utf8（name））；

student.put（"Dept"，new Utf8（dept））；

student.put（"Phone"，new Utf8（phone））；

student.put（"Age"，age）；

System.out.println（"Successfully added"+name）；

return student；

}

/**

*输出学生信息

**/

public void print（）throws IOException{

GenericDatumReader＜Record＞dr=new GenericDatumReader＜Record＞（）；

dr.setExpected（studentSchema）；

DataFileReader＜Record＞reader=new DataFileReader＜Record＞（new

File（fileName），dr）；

System.out.println（"\nprint all the records from database"）；

try{

while（reader.hasNext（））{

Record student=reader.next（）；

System.out.println（student.get（"SID"）.toString（）+""+student.

get（"Name"）+""+student.get（"Dept"）+""+student.get（"Phone"）+"

"+student.get（"Age"）.toString（））；

}

}finally{

reader.close（）；

}

}

/**

*输出学生姓名和电话

**/

public void printExtraction（）throws IOException{

GenericDatumReader＜Record＞dr=new GenericDatumReader＜Record＞（）；

dr.setExpected（extractSchema）；

DataFileReader＜Record＞reader=new DataFileReader＜Record＞（new

File（fileName），dr）；

System.out.println（"\nExtract Name＆Phone of the records from database"）；

try{

while（reader.hasNext（））{

Record student=reader.next（）；

System.out.println（student.get（"Name"）.toString（）+""+student.

get（"Phone"）.toString（）+"\t"）；

}

}finally{

reader.close（）；

}

}

}

编译student.java不仅需要从网站http：//www.apache.org/dyn/closer.cgi/avro/下载avro-1.6.3.jar等相关类，还需要从网站http：//wiki.fasterxml.com/JacksonDownload下载jackson-core-asl-1.9.7.jar和jackson-mapper-asl-1.9.7.jar这些Java中JSON生成的解析相关类。编译后运行文件的结果如图16-6所示，同时生成student.db文件，可以通过查看该文件中的内容来了解对象容器文件的格式。



图　16-6　编译运行student文件

16.4　GenAvro（Avro IDL）语言

为了让开发者在声明模式时使用一种与诸如Java、C++、Python等普通编程语言相似的方法，Avro提供了GenAvro语言。GenAvro是声明Avro模式的高级语言（最新版本中称为Avro IDL），虽然它目前还没有完全确定下来，但不会有主要的变化。之前在其他构架如Thrift、Protocol、CORBA中使用过接口描述语言（IDL）的开发者可能会对Avro IDL语言有亲切感。

每个Avro IDL文件定义了单一的Avro协议，并产生一个JSON格式的Avro协议文件，其扩展名为.avpr。为了使Avro IDL（新版本中为.avdl）文件转化为.avpr文件，必须使用IDL工具进行处理，例如：

$java-jar avroj-tools.jar idl src/test/idl/input/namespaces.avdl/tmp/namespaces.avpr

$head/tmp/namespaces.avpr

{

"protocol"："TestNamespace"，

"namespace"："avro.test.protocol"，

……

这个IDL工具也可以处理从stdin输入的数据或输出到stdout的数据，更多的信息可以用idl--help命令查询。一个Avro IDL文件只包含一个协议定义，较小的协议可由以下代码定义：

protocol MyProtocol{

}

这相当于以下的JSON协议定义：

{

"protocol"："MyProtocol"，

"types"：[]，

"messages"：{

}

}

使用@namespace注解后，协议的命名空间可能会改变，代码如下：

@namespace（"mynamespace"）

protocol MyProtocol{

}

在Avro IDL中，可以通过使用@namespace为所注解的元素指定属性。Avro IDL中的协议包含以下项目：

指定模式的定义，包括记录、错误、枚举和固定型。

RPC消息的定义。

外部协议和模式文件的引用。

引入文件可以用以下三种方式之一：

引入IDL文件使用语句import idl“foo.avdl”。

引入JSON协议文件使用语句import protocol“foo.avpr”。

引入JSON模式文件使用语句import schema“foo.avsc”。

下面介绍各种类型的定义方法。

1）定义枚举。在Avro IDL中使用类似于C或Java的语法来定义枚举，代码如下：

enum Suit{

SPADES, DIAMONDS, CLUBS, HEARTS

}

需要注意的是，不像JSON格式，在Avro IDL中匿名的枚举是无法定义的。

2）定义固定长度的字段。定义一个固定长度的字段可以使用以下语法：

fixed MD5（16）；

该例子定义了一个包含16字节名称为MD5的固定长度类型。

3）定义记录和错误。在Avro IDL中定义记录的语法类似于C中的结构体定义，代码如下：

record Employee{

string name；

boolean active；

long salary；

}

以上例子定义了一个带有三个字段称为“Employee”的记录，错误类型的定义只需要将record改为error就可以了，代码如下：

error Kaboom{

string explanation；

int result_code；

}

记录和错误中的字段包括类型和名称，也可以有属性注解。Avro IDL语言中引用的类型必须为以下之一：

原始类型；

已命名的模式，该模式在同一协议中且使用前已经定义；

复杂类型（数据、映射或者联合）。

下面分别介绍它们。

1）Avro IDL支持的原始类型与Avro的JSON格式支持的类型一样，包括int、long、string、boolean、float、double、null和bytes。

2）如果相同的Avro IDL文件中已经定义了指定的模式且为原始类型，那么可以通过名称直接引用，代码如下：

record Card{

Suit suit；//引用之前定义的枚举类型Card

int number；

}

3）复杂类型。数组类型的定义方法与C++或Java中的定义方式类似。任何类型t的数组写为array＜t＞。例如，字符串的数组写为array＜string＞，记录Foo的多维数组写为array＜array＜Foo＞＞。映射类型和数组类型相似，包含类型t的数组写为map＜t＞，和JSON模式格式一样，所有的映射包含string类型的键。联合类型写为union{typeA, typeB, typeC，……}，例如，下面这个记录包含可选的字符串字段：

record RecordWithUnion{

union{null, string}optionalString；

}

需要注意的是，Avro IDL中联合的限制与JSON格式的一样，即记录不能包含相同类型的多种元素。

使用Avro IDL协议定义RPC消息的语法与C语言头文件或Java接口的方法声明相似。例如带有参数foo和bar且返回int值的RPC消息定义为：

int add（int foo, int bar）；

定义一个没有返回值的消息可以使用别名void，相当于Avro的null类型，如下所示：

void logMessage（string message）；

如果在相同的协议之前已经定义了一个错误类型，那么可以使用下面语法声明消息抛出这个错误：

void goKaboom（）throws Kaboom；

如果定义一个one-way的消息，只需在参数后面使用关键字oneway，代码如下：

void fireAndForget（string message）oneway；

最后介绍其他的Avro IDL语言特征。

（1）注释

Avro IDL语言支持所有的Java类型注释。每行//后面的内容将被忽略，用/*和*/可以注释多行内容。

（2）区别标识

当语言需要保留字来作为标识时，需要用符号“”来区别标识。例如，定义一个带有名称error的消息：

voiderror（）；

这个语法可以使用在任何有标识的地方。

（3）排序和命名空间的注释

在Avro IDL中Java风格的注释可以用来给类型增加额外的属性。例如，指定记录中字段的排序顺序可以使用@order，如下所示：

record MyRecord{

@order（"ascending"）myAscendingSortField；

@order（"descending"）myDescendingField；

@order（"ignore"）myIgnoredField；

}

当然注释也可以放在字段类型的前面，如：

record MyRecord{

@java-class（“java.util.ArrayList”）array string myStrings；

}

类似的，当定义一个指定模式时，使用@namespace可以修改命名空间，如：

@namespace（"org.apache.avro.firstNamespace"）

protocol MyProto{

@namespace（"org.apache.avro.someOtherNamespace"）

record Foo{}

record Bar{}

}

这里在firstNamespace命名空间中定义了一个协议，记录Foo定义在someOtherNamespace中，Bar定义在firstNamespace中，且从容器中继承了默认值。

对于类型和字段的别名可以用注释@aliases来指定，如下所示：

@aliases（["org.old.OldRecord"，"org.ancient.AncientRecord"]）

record MyRecord{

string@aliases（["oldField"，"ancientField"]）myNewField；

}

下面是Avro IDL文件的完整例子：

/**

*An example protocol in Avro IDL

*/

@namespace（"org.apache.avro.test"）

protocol Simple{

@aliases（["org.foo.KindOf"]）

enum Kind{

FOO，

BAR，//the bar enum value

BAZ

}

fixed MD5（16）；

record TestRecord{

@order（"ignore"）

string name；

@order（"descending"）

Kind kind；

MD5 hash；

union{MD5，null}@aliases（["hash"]）nullableHash；

array＜long＞arrayOfLongs；

}

error TestError{

string message；

}

string hello（string greeting）；

TestRecord echo（TestRecordrecord）；

int add（int arg1，int arg2）；

bytes echoBytes（bytes data）；

voiderror（）throws TestError；

void ping（）oneway；

}

16.5　Avro SASL概述

SASL（Simple Authentication and Security Layer，简单验证安全层）是网络协议中提供验证和安全的框架，它将验证机制从用户程序协议中分离出来，使得采用SASL的程序可以使用任何SASL所支持的验证机制，同样也支持代理验证。SASL提供的数据安全层能够提供数据完整性和数据加密服务，支持SASL的用户协议，也支持SASL服务所需的安全传输层协议，其中安全传输层协议是为因特网上通信提供安全性的加密协议。开发者可通过SASL对通用API进行编码，此方法避免了对特定机制的依赖。采用SASL的协议需要定义SASL profile，即如何使用SASL进行验证协商。下面对Avro RPC采用的SASL进行介绍。

SASL协商过程可以看成是客户端和服务器使用特定的SASL机制、在连接的基础上进行一系列消息的交互。客户端通过发送带有初始消息（可能为空）的机制名称（这里是SASL）来协商过程。协商过程一直伴随着消息的交换直到某一方表明协商成功或失败。消息的内容由具体的机制决定，如果协商成功就可以通过连接进行会话，否则将被抛弃。一些机制在协商之后会继续处理会话的数据（如对数据进行加密），而一些机制会指定会话数据传输不需修改。

Avro SASL协商使用4个单字节命令，分别是：

0：START（开始），使用于客户端初始消息中；

1：CONTINUE（继续），使用于协商进行中；

2：FAIL（失败），协商失败；

3：COMPLETE（完成），成功完成协商。

开始消息的格式是：

|0|4字节的机制名称的长度|机制名称|4字节的有效负载的长度|有效负载数据|

继续消息的格式是：

|1|4字节的有效负载的长度|有效负载数据|

失败消息的格式是：

|2|4字节的消息长度|UTF-8的消息|

完成消息的格式是：

|3|4字节的有效负载的长度|有效负载数据|

协商以客户端发送START命令开始，START命令中包含客户端选定的机制名称和指定机制的有效负载数据。然后，服务器和客户端交换一些CONTINUE消息，每个消息包含由安全机制生成的下个消息的有效负载数据。一旦客户端或者服务器发送FAIL消息，协商就会失败，失败消息中包含UTF-8编码的文本。只要接收到或发送了FAIL消息，或者在协商过程中发生了任何错误，基于此次连接的通信就必须结束。如果客户端或服务器发送COMPLETE消息，那么协商将成功完成，会话数据可以通过此次连接进行传输直到一方关闭。

如果SASL QOP（Quality of Protection，品质保证）没有进行协商，则基于此次连接的读/写无需修改，特别是传输的消息使用了Avro框架并采用了下面的形式：

|4字节的框架长度|框架数据|……|4个零字节|

如果SASL QOP协商且成功，则此次连接后的消息传输使用QOP。写数据时使用安全机制对非空的框架进行封装，读取数据时需要解开。完整的框架必须传送到安全机制进行解封装，之后传送到应用程序中。如果在封装、解封装或者框架处理时发生错误，那么此次连接的通信必须结束。

SASL的匿名机制很容易实现，特别之处在于，一个初始的匿名请求可以用以下静态序列作为前缀：

|0|009|ANONYMOUS|0000|

如果服务器使用匿名机制，则它应检查所接收到的请求前缀，即开始消息的机制名称是否为“ANONYMOUS”，然后对带有COMPLETE消息的初始响应前加上前缀：

|3|0000|

如果匿名服务器接收到带有其他机制名称的请求，那么它将发送FAIL消息：

|2|0000|

注意，匿名机制不会在客户端和服务器之间增加多余的往返，START消息附加在初始请求中，而COMPLETE和FAIL消息则附加在初始响应中。

16.6　本章小结

本章内容主要包括：16.1节首先将说明如何声明Avro模式，以及如何对数据进行序列化；然后介绍对象容器文件的具体格式和RPC中Avro的使用方法，包括协议的声明、协议传输的格式等；最后介绍如何解析获取的数据，重点说明如何处理写入模式和读取模式的不同。16.2节介绍了在C和C++中如何使用Avro，主要叙述函数的使用，其中引用关于学生模式的具体例子来详细介绍。16.3节首先介绍Java中使用Avro所需要的一些包，后面给出了上节中学生模式例子的Java实现程序。16.4节主要介绍了GenAvro语言，说明如何用类似高级语言的方法来声明一个Avro模式。16.5节简单介绍了Avro的简单验证安全层，具体说明了通信双方如何进行协商。

Avro作为一个数据序列化系统，为数据密集型动态应用程序提供了数据存储和交换的平台，它的最大特点就是模式和数据在一起，也就是在反序列化时写入的模式和读出的模式都是已知的，这为Avro带来了很多好处，如生成的数据文件很小等。

今后，Avro可能会替换Hadoop现有的RPC, Avro的很多特性是为Hadoop及相关项目准备的：容器文件中的同步器可以使MapReduce快速地分离文件；不需要生成代码，有利于Avro使用于Hive和Pig；对于大规模存储较小的数据文件有利于减少数据量等。Avro数据结构的特性和多语言支持的优势还会帮助Hadoop在跨版本、多语言等方面提高性能。










