---
layout: post
categories: [Kafka]
description: none
keywords: Kafka
---
# Kafka入门简介
Kafka是一个高吞吐的分布式的消息系统，是基于发布/订阅模式的消息队列。

## Kafka简介
Kafka是由LinkedIn公司开发的一款开源分布式消息流平台，由Scala和Java编写。主要作用是为处理实时数据提供一个统一、高吞吐、低延迟的平台，其本质是基于发布订阅模式的消息引擎系统。

Kafka具有以下特性：
- 高吞吐、低延迟：Kafka收发消息非常快，使用集群处理消息延迟可低至2ms。
- 高扩展性：Kafka可以弹性地扩展和收缩，可以扩展到上千个broker，数十万个partition，每天处理数万亿条消息。
- 永久存储：Kafka可以将数据安全地存储在分布式的，持久的，容错的群集中。
- 高可用性：Kafka在可用区上可以有效地扩展群集，某个节点宕机，集群照样能够正常工作。

## 术语
- Producer：消息生产者，就是向 Kafka broker 发消息的客户端。
- Consumer：消息消费者，向 Kafka broker 拉取消息的客户端。
- Consumer Group（CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。
- Broker：一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker 可以容纳多个 topic。
- Topic：可以理解为一个队列，生产者和消费者面向的都是一个 topic。
- Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，每个broker上的topic叫做一个partition（一个 topic 可以分为多个 partition），每个 partition 是一个有序的队列。
- Replica：副本。一个 topic 的每个分区都有若干个副本，即一个 Leader 和若干个Follower。
- Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。
- Follower：每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。
- ISR: in-sync replica set（ISR）, 意为和Leader保持同步的Follower+Leader集合(leader：0，isr:0,1,2)。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参数设定，默认30s。例如2超时，(leader:0, isr:0,1)。
- AR: Kafka分区中的所有副本统称。
- OSR ：表示 Follower 与 Leader副本同步时，延迟过多的副本。AR=ISR+OSR
- LEO（Log End Offset）：每个副本的最后一个offset，LEO其实就是最新的offset + 1。
- HW（High Watermark）：所有副本中最小的LEO 。

## 主题命令行操作
查看操作主题命令参数
```
bin/kafka-topics.sh
```

查看当前服务器中的所有 topic
```
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 –list
```

创建 first topic
```
bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 --create --partitions 1 --replication-factor 3 --topic first
选项说明：
--topic 定义 topic 名
--replication-factor 定义副本数
--partitions 定义分区数
```

查看 first 主题的详情
```
$ bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 --describe --topic first
```

修改分区数（注意：分区数只能增加，不能减少）
```
bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 --alter --topic first --partitions 3
```

再次查看 first 主题的详情
```
bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 --describe --topic first
```

删除 topic
```
bin/kafka-topics.sh --bootstrap-server 
hadoop102:9092 --delete --topic first
```

查看操作生产者命令参数
```
bin/kafka-console-producer.sh
```

发送消息
```
bin/kafka-console-producer.sh --
bootstrap-server hadoop102:9092 --topic first
```

查看操作消费者命令参数
```
bin/kafka-console-consumer.sh
```

消费 first 主题中的数据。
```
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first
```

把主题中所有的数据都读取出来（包括历史数据）。
```
[song@hadoop102 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic first
```































