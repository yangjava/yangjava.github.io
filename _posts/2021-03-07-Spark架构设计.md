---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# Spark架构设计

## Spark基本设计思想
Spark的模块按照重要程度可分为核心功能和扩展功能。核心功能是Spark设计理念的核心实现，也是Spark陆续加入新功能的基础。在核心功能之上，通过不断地将丰富的扩展功能持续集成到Spark中，使得Spark满足更多市场、应用和用户的需求，促使Spark生态圈更加繁荣。

Spark在编程模型方面没有采用Hadoop的MapReduce编程模型，而是封装了丰富的转换与执行的API。开发人员可以充分利用这些API编写自己的Spark应用程序，而不用拘泥于如何套用MapReduce编程模型中的Mapper或Reducer。Spark提供的转换API将会在底层将数据封装为RDD，并对这些RDD进行转换、构建血缘、构建DAG、分片划分等处理，这些过程都是透明的，使得开发人员能更加专注于自己的业务实现。

## Spark模块设计
整个Spark主要由Spark Coke、Spark SQL、Spark Streaming、GraphX、MLlib组成，而后四项的能力都是建立在核心引擎之上。

### Spark核心功能

Spark Core中提供了Spark最基础与最核心的功能，主要包括以下几项。

#### 基础设施
在Spark中有很多基础设施，被Spark中的各种组件广泛使用。这些基础设施包括Spark配置（SparkConf）、Spark内置的RPC框架（在早期Spark版本中Spark使用的是Akka）、事件总线（ListenerBus）、度量系统。

- SparkConf用于管理Spark应用程序的各种配置信息。
- Spark内置的RPC框架使用Netty实现，有同步和异步的多种实现，Spark各个组件间的通信都依赖于此RPC框架。
- 如果说RPC框架是跨机器节点不同组件间的通信设施，那么事件总线就是Spark Context内部各个组件间使用事件——监听器模式异步调用的实现。
- 度量系统由Spark中的多种度量源（Source）和多种度量输出（Sink）构成，完成对整个Spark集群中各个组件运行期状态的监控。

#### SparkContext
通常而言，用户开发的Spark应用程序的提交与执行都离不开SparkContext的支持。在正式提交应用程序之前，首先需要初始化SparkContext。SparkContext隐藏了网络通信、分布式部署、消息通信、存储体系、计算引擎、度量系统、文件服务、Web UI等内容，应用程序开发者只需要使用SparkContext提供的API完成功能开发。

#### SparkEnv
Spark执行环境SparkEnv是Spark中的Task运行所必需的组件。SparkEnv内部封装了RPC环境（RpcEnv）、序列化管理器、广播管理器（BroadcastManager）、map任务输出跟踪器（MapOutputTracker）、存储体系、度量系统（MetricsSystem）、输出提交协调器（OutputCommitCoordinator）等Task运行所需的各种组件。

#### 存储体系
Spark优先考虑使用各节点的内存作为存储，当内存不足时才会考虑使用磁盘，这极大地减少了磁盘I/O，提升了任务执行的效率，使得Spark适用于实时计算、迭代计算、流式计算等场景。

在实际场景中，有些Task是存储密集型的，有些则是计算密集型的，所以有时候会造成存储空间很空闲，而计算空间的资源又很紧张。Spark的内存存储空间与执行存储空间之间的边界可以是“软”边界，因此资源紧张的一方可以借用另一方的空间，这既可以有效利用资源，又可以提高Task的执行效率。此外，Spark的内存空间还提供了Tungsten的实现，直接操作操作系统的内存。由于Tungsten省去了在堆内分配Java对象，因此能更加有效地利用系统的内存资源，并且因为直接操作系统内存，空间的分配和释放也更迅速。在Spark早期版本还使用了以内存为中心的高容错的分布式文件系统Alluxio（Tachyon）供用户进行选择。Alluxio能够为Spark提供可靠的内存级的文件共享服务。

#### 调度系统
调度系统主要由DAGScheduler和TaskScheduler组成，它们都内置在SparkContext中。DAGScheduler负责创建Job、将DAG中的RDD划分到不同的Stage、给Stage创建对应的Task、批量提交Task等功能。TaskScheduler负责按照FIFO或者FAIR等调度算法对批量Task进行调度；为Task分配资源；将Task发送到集群管理器的当前应用的Executor上，由Executor负责执行等工作。现如今，Spark增加了SparkSession和DataFrame等新的API，SparkSession底层实际依然依赖于SparkContext。

#### 计算引擎
计算引擎由内存管理器（MemoryManager）、Tungsten、任务内存管理器（TaskMemory-Manager）、Task、外部排序器（ExternalSorter）、Shuffle管理器（ShuffleManager）等组成。MemoryManager除了对存储体系中的存储内存提供支持和管理外，还为计算引擎中的执行内存提供支持和管理。Tungsten除用于存储外，也可以用于计算或执行。TaskMemoryManager对分配给单个Task的内存资源进行更细粒度的管理和控制。ExternalSorter用于在map端或reduce端对ShuffleMapTask计算得到的中间结果进行排序、聚合等操作。ShuffleManager用于将各个分区对应的ShuffleMapTask产生的中间结果持久化到磁盘，并在reduce端按照分区远程拉取ShuffleMapTask产生的中间结果。

### Spark扩展功能
为了扩大应用范围，Spark陆续增加了一些扩展功能，主要包括以下几项。

#### Spark SQL
由于SQL具有普及率高、学习成本低等特点，为了扩大Spark的应用面，还增加了对SQL及Hive的支持。Spark SQL的过程可以总结为：首先使用SQL语句解析器（SqlParser）将SQL转换为语法树（Tree），并且使用规则执行器（RuleExecutor）将一系列规则（Rule）应用到语法树，最终生成物理执行计划并执行的过程。其中，规则包括语法分析器（Analyzer）和优化器（Optimizer）。Hive的执行过程与SQL类似。

#### Spark Streaming
Spark Streaming与Apache Storm类似，也用于流式计算。Spark Streaming支持Kafka、Flume、Kinesis和简单的TCP套接字等多种数据输入源。输入流接收器（Receiver）负责接入数据，是接入数据流的接口规范。Dstream是Spark Streaming中所有数据流的抽象，Dstream可以被组织为DStream Graph。Dstream本质上由一系列连续的RDD组成。

#### GraphX
Spark提供的分布式图计算框架。GraphX主要遵循整体同步并行计算模式（Bulk Synchronous Parallell，BSP）下的Pregel模型实现。GraphX提供了对图Graph的抽象，Graph由顶点（Vertex）、边（Edge）及继承了Edge的EdgeTriplet（添加了srcAttr和dstAttr，用来保存源顶点和目的顶点的属性）三种结构组成。GraphX目前已经封装了最短路径、网页排名、连接组件、三角关系统计等算法的实现，用户可以选择使用。

#### MLlib
Spark提供的机器学习框架。机器学习是一门涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多领域的交叉学科。MLlib目前已经提供了基础统计、分类、回归、决策树、随机森林、朴素贝叶斯、保序回归、协同过滤、聚类、维数缩减、特征提取与转型、频繁模式挖掘、预言模型标记语言、管道等多种数理统计、概率论、数据挖掘方面的数学算法。

## Spark基本架构
从集群部署的角度来看，Spark集群由集群管理器（Cluster Manager）、工作节点（Worker）、执行器（Executor）、驱动器（Driver）、应用程序（Application）等部分组成。

### Cluster Manager
Spark的集群管理器，主要负责对整个集群资源的分配与管理。Cluster Manager在YARN部署模式下为ResourceManager；在Mesos部署模式下为Mesos Master；在Standalone部署模式下为Master。Cluster Manager分配的资源属于一级分配，它将各个Worker上的内存、CPU等资源分配给Application，但是并不负责对Executor的资源分配。Standalone部署模式下的Master会直接给Application分配内存、CPU及Executor等资源。目前，Standalone、YARN、Mesos、EC2等都可以作为Spark的集群管理器。

### Worker
Spark的工作节点。在YARN部署模式下实际由NodeManager替代。Worker节点主要负责以下工作：将自己的内存、CPU等资源通过注册机制告知Cluster Manager；创建Executor；将资源和任务进一步分配给Executor；同步资源信息、Executor状态信息给Cluster Manager等。在Standalone部署模式下，Master将Worker上的内存、CPU及Executor等资源分配给Application后，将命令Worker启动CoarseGrainedExecutorBackend进程（此进程会创建Executor实例）。

### Executor
执行计算任务的一线组件。主要负责任务的执行及与Worker、Driver的信息同步。

### Driver
Application的驱动程序，Application通过Driver与Cluster Manager、Executor进行通信。Driver可以运行在Application中，也可以由Application提交给Cluster Manager并由Cluster Manager安排Worker运行。

### Application
用户使用Spark提供的API编写的应用程序，Application通过Spark API将进行RDD的转换和DAG的构建，并通过Driver将Application注册到Cluster Manager。Cluster Manager将会根据Application的资源需求，通过一级分配将Executor、内存、CPU等资源分配给Application。Driver通过二级分配将Executor等资源分配给每一个任务，Application最后通过Driver告诉Executor运行任务。
















