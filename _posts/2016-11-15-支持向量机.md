---
layout: post
categories: [Python,scikitlearn]
description: none
keywords: Python
---
# 支持向量机
支持向量机简称SVM，是Support Vector Machine的缩写。SVM是一种分类算法，在工业界和学术界都有广泛的应用。特别是针对数据集较小的情况下，往往其分类效果比神经网络好。

## 算法原理
SVM的最大特点是能构造出最大间距的决策边界，从而提高分类算法的鲁棒性。

### 大间距分类算法
假设要对一个数据集进行分类，可以构造一个分隔线把圆形的点和方形的点分开。这个分隔线称为分隔超平面（Separating hyperplane）。

实线的分隔线比虚线的分隔线更好，因为使用实线的分隔线进行分类时，离分隔线最近的点到分隔线上的距离更大，即margin2>margin1。这段距离的两倍，称为间距（margin）。那些离分隔超平面最近的点，称为支持向量（support vector）。为了达到最好的分类效果，SVM的算法原理就是要找到一个分隔超平面，它能把数据集正确地分类，并且间距最大。

## 乳腺癌检测

本章使用支持向量机来解决这个问题。首先，我们载入数据：
```python
# 载入数据
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
 
cancer = load_breast_cancer()
X = cancer.data
y = cancer.target
print('data shape: {0}; no. positive: {1}; no. negative: {2}'.format(
    X.shape, y[y==1].shape[0], y[y==0].shape[0]))
 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```
输出如下：
```python
data shape: (569, 30); no. positive: 357; no. negative: 212
```
可以看出，我们的数据集很小。高斯核函数太复杂，容易造成过拟合，模型效果应该不会很好。我们先用高斯核函数试一下看与我们猜测的是否一致：

```python
from sklearn.svm import SVC
 
clf = SVC(C=1.0, kernel='rbf', gamma=0.1)
clf.fit(X_train, y_train)
train_score = clf.score(X_train, y_train)
test_score = clf.score(X_test, y_test)
print('train score: {0}; test score: {1}'.format(train_score, test_score))
```