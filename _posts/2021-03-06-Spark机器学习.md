---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# Spark机器学习

## 数据清理与转换
绝大部分情况下，这些原始数据都需要经过预处理才能为模型所使用。预处理的情况可能包括以下几种。
- 数据过滤 ：比如我们想从原始数据的部分数据中创建一个模型，而所需数据只是最近几月的活动数据或是满足特定条件的事件数据。
- 处理数据缺失、不完整或有缺陷 ：许多现实中的数据集都存在某种程度上的不完整。这可能包括数据缺失（比如用户没有输入），数据存在错误或是缺陷（比如数据收集或存储时的错误，又或是技术问题或漏洞，以及软硬件故障）。可能要过滤掉非规整数据，或通过某种方式来填充缺失的数据点（比如选取数据集的平均值来作为缺失点的值）。
- 处理可能的异常、错误和异常值 ：错误或异常的数据可能不利于模型的训练，所以需要过滤掉，或是通过某些方法来处理。
- 合并多个数据源 ：比如可能要将各个用户的事件数据与不同的内部数据或是外部数据合并。内部数据如用户属性；外部数据如地理位置、天气和经济数据。
- 数据汇总 ：某些模型需要输入的数据进行过某种汇总，比如统计各用户经历过的事件类型的总数目。

## Spark上数据的获取、处理与准备

### 获取公开数据集
商业敏感数据虽然难以获取，但好在仍有相当多有用数据可公开访问。它们中的不少常用来作为特定机器学习问题的基准测试数据。常见的有以下几个。

- UCL机器学习知识库 ：包括近300个不同大小和类型的数据集，可用于分类、回归、聚类和推荐系统任务。数据集列表位于：http://archive.ics.uci.edu/ml/ 。
- Amazon AWS公开数据集 ：包含的通常是大型数据集，可通过Amazon S3访问。这些数据集包括人类基因组项目、Common Crawl网页语料库、维基百科数据和Google Books Ngrams。相关信息可参见：http://aws.amazon.com/publicdatasets/ 。
- Kaggle ：这里集合了Kaggle举行的各种机器学习竞赛所用的数据集。它们覆盖分类、回归、排名、推荐系统以及图像分析领域，可从Competitions区域下载：http://www.kaggle.com/competitions 。
- KDnuggets ：这里包含一个详细的公开数据集列表，其中一些上面提到过的。该列表位于：http://www.kdnuggets.com/datasets/index.html 。

## 从数据中提取有用特征
特征（feature） 指那些用于模型训练的变量。每一行数据包含可供提取到训练样本中的各种信息。从根本上说，几乎所有机器学习模型都是与用向量 表示的数值特征打交道；因此，我们需要将原始数据转换为数值。

特征可以概括地分为如下几种。
- 数值特征 （numerical feature）：这些特征通常为实数或整数，比如之前例子中提到的年龄。
- 类别特征 （categorical feature）：它们的取值只能是可能状态集合中的某一种。我们数据集中的用户性别、职业或电影类别便是这类。
- 文本特征 （text feature）：它们派生自数据中的文本内容，比如电影名、描述或是评论。
- 其他特征 ：大部分其他特征都最终表示为数值。比如图像、视频和音频可被表示为数值数据的集合。地理位置则可由经纬度或地理散列（geohash）表示。

### 文本特征
词袋法将一段文本视为由其中的文本或数字组成的集合，其处理过程如下。

- 分词 （tokenization）：首先会应用某些分词方法来将文本分隔为一个由词（一般如单词、数字等）组成的集合。可用的方法如空白分隔法。这种方法在空白处对文本分隔并可能还删除其他如标点符号和其他非字母或数字字符。
- 删除停用词 （stop words removal）：之后，它通常会删除常见的单词，比如the、and和but（这些词被称作停用词 ）。
- 提取词干 （stemming）：下一步则是词干的提取。这是指将各个词简化为其基本的形式或者干词。常见的例子如复数变为单数（比如dogs变为dog等）。提取的方法有很多种，文本处理算法库中常常会包括多种词干提取方法。
- 向量化 （vectorization）：最后一步就是用向量来表示处理好的词。二元向量可能是最为简单的表示方式。它用1和0来分别表示是否存在某个词。从根本上说，这与之前提到的 k 之1编码相同。与 k 之1相同，它需要一个词的字典来实现词到索引序号的映射。随着遇到的词增多，各种词可能达数百万。由此，使用稀疏矩阵来表示就很关键。这种表示只记录某个词是否出现过，从而节省内存和磁盘空间，以及计算时间。

## 