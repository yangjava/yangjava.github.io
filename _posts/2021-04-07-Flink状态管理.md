---
layout: post
categories: [Flink]
description: none
keywords: Flink
---
# Flink状态管理
Flink中定义了 State，用来保存中间计算结果或者缓存数据 。根据是否需要保存中间结果分为无状态计算和有状态计算。

## State状态 
Flink中定义了 State，用来保存中间计算结果或者缓存数据 。根据是否需要保存中间结果分为无状态计算和有状态计算。在批处理过程中，数据是划分为块分片去完成的，然后每一个Task去处理一个分片。当分片执行完成后，把输出聚合起来就是最终的结果。在这个过程当中，对于state的需求还是比较小的。
对于流计算而言，事件持续不断的产生，如果每次计算都是相互独立的，不依赖上下游的事件，则是无状态计算；如果计算需要依赖于之前或者后续的事件，则是有状态的计算。

在Flink中使用State的典型场景如下：
- 数据流中的数据有重复，想对数据去重，需要记录哪些数据已经流入应用，当新数据流入时，根据已流入数据来判断是否去重
- 检查输入流是否符合某个特定的模式，需要将之前流入的元素以状态的形式缓存下来。比如判断温度传感器中的数据流的温度是否在持续上升
- 对一个时间窗口内的数据进行聚合分析，使用增量计算方式计算当前窗口内的数值总和并保存为中间结果，当有新的窗口到来时只需要在中间结果的基础上求和即可
- 在线机器学习的场景下，需要根据新流入数据不断更新机器学习的模型参数

Flink中提供了对State操作的接口，用户在开发Flink应用的时候，可以将临时数据保存在State中，同时利用checkpoint机制对state进行备份，一旦出现异常能够从保存的State中恢复状态，实现Exactly- Once。另外，对state的管理还需要注意以下几点：
- 状态数据的存储和访问 ：在Task内部如何高效的保存状态数据以及使用状态数据
- 状态数据的备份和恢复 ：状态信息如何高效的备份，并且在异常时候能够恢复到Task之前的状态
- 状态数据的划分和动态扩容 ：在并行Task过程中如何对状态数据进行切分，并且在并行度修改的时候能够正确恢复到对应的Task
- 状态数据的清理 ：状态数据的保存和使用是有成本的，对于过期数据的清理是有必要的

## 什么是状态
首先来看看状态的一个官方的定义：当前计算流程需要依赖到之前计算的结果，那么之前计算的结果就是状态。
例如：计算最常见的 DAU 指标，那么必然需要做 id 去重，涉及到去重时，就要存储历史所有来过的的 id。
在去重场景下，我在程序中使用一个 Set存储 id，然后用于去重，算不算状态？ 答案：算，只要你的当前数据的处理计算依赖到之前的数据，就算做状态。
其实在实时计算中的状态的功能主要体现在任务可以做到失败重启后没有数据质量、时效问题。

## 状态到底在实时计算中解决了什么问题？
离线任务失败重启：重新读一遍输入数据，然后重新计算一遍，没有啥大问题，大不了产出慢一些。
实时任务失败重启：实时任务一般都是 7x24 小时 long run 的，挂了之后，就会有以下两个问题。首先给一个实际场景：一个消费上游 Kafka，使用 Set去重计算 DAU 的实时任务。
- 数据质量问题：当这个实时任务挂了之后恢复，Set空了，这时候任务再继续从上次失败的 Offset 消费 Kafka 产出数据，则产出的数据就是错误数据了。这时候小伙伴可能会提出疑问，计算 DAU 场景的话，这个任务挂了我重新从今天 0 点开始消费 Kafka 不就得了？这个观点没有错，其实这就是博主即将说的第二个问题。
- 数据时效问题：你要记得，你一定要记得，你是一个实时任务，产出的指标是有时效性（主要是时延）要求的。你可以从今天 0 点开始重新消费，但是你回溯数据也是需要时间的。举例：中午 12 点挂了，实时任务重新回溯 12 个小时的数据能在 1 分钟之内完成嘛？大多数场景下是不能的！一般都要回溯几个小时，这就是实时场景中的数据时效问题。
那当我们把状态给 "管理" 起来时，上面的两个问题就可以迎刃而解。还是相同的计算任务、相同的业务场景。当我们把 Set这个数据结构定期（每隔 1min）的给存储到 HDFS 上面时，任务挂了、恢复之后。我们的任务还可以从 HDFS 上面把这个数据给读回来，接着从最新的一个 Kafka Offset 继续计算就可以，这样即没有数据质量问题，也没有数据时效性问题。
在 Flink 中状态管理的模块就是我们所熟知的 Flink Checkpoint\Savepoint。

## 状态管理的概念
- 状态：指 Flink 程序中的状态数据，博主认为也能代指用户在使用 DataStream API 编写程序来操作 State 的接口。你在 Flink 中见到的 ValueState、MapState 等就是指状态接口。你可以通过 MapState.put(key, value) 去往 MapState 中存储数据，MapState.get(key) 去获取数据。这也是你能直接接触、操作状态的一层。
- 状态后端：做状态数据（持久化，restore）的工具就叫做状态后端。比如你在 Flink 中见到的 RocksDB、FileSystem 的概念就是指状态后端。这些状态后端就是实际存储上面的状态数据的。比如配置了 RocksDB 作为状态后端，MapState 的数据就会存储在 RocksDB 中。再引申一下，大家也可以理解为：应用中有一份状态数据，把这份状态数据存储到 MySQL 中，这个 MySQL 就能叫做状态后端。
- Checkpoint、Savepoint：协调整个任务 when，how 去将 Flink 任务本地机器中存储在状态后端的状态去同步到远程文件存储系统（比如 HDFS）的过程就叫 Checkpoint、Savepoint。

## 有状态计算
在Flink架构体系中，有状态计算可以说是Flink非常重要的特性之一。有状态计算是指在程序计算过程中，在Flink程序内部存储计算产生的中间结果，并提供给后续Function或算子计算结果使用。状态数据一致维系在本地存储中，这里的存储可以是Flink的堆内存或者堆外内存，也可以借助第三方的存储介质，例如Flink中已经实现的RocksDB，当然用户也可以自己实现相应的缓存系统去存储状态信息，以完成更加复杂的计算逻辑。和状态计算不同的是，无状态计算不会存储计算过程中产生的结果，也不会将结果用于下一步计算过程中，程序只会在当前的计算流程中实行计算，计算完成就输出结果，然后下一条数据接入，然后再处理。

无状态计算实现的复杂度相对较低，实现起来较容易，但是无法完成提到的比较复杂的业务场景，例如下面的例子：
- 用户想实现CEP（复杂事件处理），获取符合某一特定事件规则的事件，状态计算就可以将接入的事件进行存储，然后等待符合规则的事件触发；
- 用户想按照分钟、小时、天进行聚合计算，求取当前的最大值、均值等聚合指标，这就需要利用状态来维护当前计算过程中产生的结果，例如事件的总数、总和以及最大，最小值等； 
- 用户想在Stream上实现机器学习的模型训练，状态计算可以帮助用户维护当前版本模型使用的参数；
- 用户想使用历史的数据进行计算，状态计算可以帮助用户对数据进行缓存，使用户可以直接从状态中获取相应的历史数据。
以上场景充分说明了状态计算在整个流式计算过程中重要性，可以看出，在Flink引入状态这一特性，能够极大地提升流式计算过程中数据的使用范围以及指标计算的复杂度，而不再需要借助类似于Redis外部缓存存储中间结果数据，这种方式需要频繁地和外部系统交互，并造成大量系统性能开销，且不易保证数据在传输和计算过程中的可靠性，当外部存储发生变化，就可能会影响到Flink内部的计算结果。

## Flink状态类型及应用
Flink 中的状态分类有两大类，**Managed State**和**Raw State**。但是实际上生产开发中基本只会用到 Managed State，不会用到 Raw State。
对 Managed State 细分，在Flink中根据数据集是否根据Key进行分区，将状态分为Keyed State和Operator State（Non-keyed State）两种类型。


## Keyed State
表示和key相关的一种State，只能用于KeydStream类型数据集对应的Functions和Operators之上。Keyed State是Operator State的特例，区别在于Keyed State事先按照key对数据集进行了分区，每个Key State仅对应一个Operator和Key的组合。Keyed State可以通过Key Groups进行管理，主要用于当算子并行度发生变化时，自动重新分布Keyed Sate数据。在系统运行过程中，一个Keyed算子实例可能运行一个或者多个Key Groups的keys。

## Operator State
与Keyed State不同的是，Operator State只和并行的算子实例绑定，和数据元素中的key无关，每个算子实例中持有所有数据元素中的一部分状态数据。Operator State支持当算子实例并行度发生变化时自动重新分配状态数据。

同时在Flink中Keyed State和Operator State均具有两种形式，
- 其中一种为托管状态（Managed State）形式，由Flink Runtime中控制和管理状态数据，并将状态数据转换成为内存Hash tables或RocksDB的对象存储，然后将这些状态数据通过内部的接口持久化到Checkpoints中，任务异常时可以通过这些状态数据恢复任务。
- 另外一种是原生状态（Raw State）形式，由算子自己管理数据结构，当触发Checkpoint过程中，Flink并不知道状态数据内部的数据结构，只是将数据转换成bytes数据存储在Checkpoints中，当从Checkpoints恢复任务时，算子自己再反序列化出状态的数据结构。
DataStream API支持使用Managed State和Raw State两种状态形式，在Flink中推荐用户使用Managed State管理状态数据，主要原因是Managed State能够更好地支持状态数据的重平衡以及更加完善的内存管理。

## Managed Keyed State
Flink中有以下Managed Keyed State类型可以使用，每种状态都有相应的使用场景，用户可以根据实际需求选择使用。
- ValueState[T]：与Key对应单个值的状态，例如统计user_id对应的交易次数，每次用户交易都会在count状态值上进行更新。ValueState对应的更新方法是update(T)，取值方法是T value()；
- ListState[T]：与Key对应元素列表的状态，状态中存放元素的List列表。例如定义ListState存储用户经常访问的IP地址。在ListState中添加元素使用add(T)或者addAll(List[T])两个方法，获取元素使用Iterable get()方法，更新元素使用update(List[T])方法；
- ReducingState[T]：定义与Key相关的数据元素单个聚合值的状态，用于存储经过指定ReduceFucntion计算之后的指标，因此，ReducingState需要指定ReduceFucntion完成状态数据的聚合。ReducingState添加元素使用add(T)方法，获取元素使用T get()方法；
- AggregatingState[IN,OUT]:定义与Key对应的数据元素单个聚合值的状态，用于维护数据元素经过指定AggregateFunciton计算之后的指标。和ReducingState相比，AggregatingState输入类型和输出类型不一定是相同的，但ReducingState输入和输出必须是相同类型的。和ListState相似，AggregatingState需要指定AggregateFunciton完成状态数据的聚合操作。AggregatingState添加元素使用add(IN)方法，获取元素使用OUT get()方法。
- MapState[UK,UV]：定义与Key对应键值对的状态，用于维护具有key-value结构类型的状态数据，MapState添加元素使用put(UK,UV)或者putAll(Map[UK,UV]方法，获取元素使用get(UK)方法。和HashMap接口相似，MapState也可以通过entries()、keys()、values()获取对应的keys或values的集合。

在Flink中需要通过创建StateDescriptor来获取相应State的操作类。StateDescriptor主要定义了状态的名称、状态中数据的类型参数信息以及状态自定义函数。每种Managed Keyed State有相应的StateDescriptor，例如ValueStateDescriptor、ListStateDescriptor、ReducingState-Descriptor、FoldingStateDescriptor、MapStateDescriptor等。

## Stateful Funciton定义
接下来通过完整的实例来说明如何在RichFlatmapFunction中使用ValueState，完成对接入数据最小值的获取。如代码清单5-1所示，通过定义leastValueState存储系统中指标的最小值，并在每次计算时和当前接入的数据对比，如果当前元素的数值小于状态中的最小值，则更新状态。然后在输出操作中增加对应指标的最小值作为新的数据集的字段。
通过创建ValueState来获取指标的最小值
```java
val env = StreamExecutionEnvironment.getExecutionEnvironment
//创建元素数据集
val inputStream: DataStream[(Int, Long)] = env.fromElements((2, 21L), (4, 1L), (5, 4L))
inputStream.keyBy(_._1).flatMap {
  //定义和创建RichFlatMapFunction,第一个参数为输入数据类型，第二个参数为输出数据类型
  new RichFlatMapFunction[(Int, Long), (Int, Long, Long)] {
//
    private var leastValueState: ValueState[Long] = _
    override def open(parameters: Configuration): Unit = {
      //创建ValueStateDescriptor,定义状态名称为leastValue,并指定数据类型
      val leastValueStateDescriptor = new ValueStateDescriptor[Long]("leastValue", classOf[Long])
      //通过getRuntimeContext.getState获取State
      leastValueState = getRuntimeContext.getState(leastValueStateDescriptor)
    }
    override def flatMap(t: (Int, Long), collector: Collector[(Int, Long, Long)]): Unit = {
      //通过value方法从leastValueState中获取最小值
      val leastValue = leastValueState.value()
      //如果当前指标大于最小值，则直接输出数据元素和最小值
      if (t._2 > leastValue) {
        collector.collect((t._1, t._2, leastValue))
      } else {
        //如果当前指标小于最小值，则更新状态中的最小值
        leastValueState.update(t._2)
        //将当前数据中的指标作为最小值输出
        collector.collect((t._1, t._2, t._2))
      }}}}
```
从以上代码实例中可以看出，在定义的RichFlatMapFunction接口中，Flink提供了RuntimeContext用于获取状态数据，同时RuntimeContext提供了常用的Managed Keyd State的获取方式，可以通过创建相应的StateDescriptor并调用RuntimeContext方法来获取状态数据。例如获取ValueState可以调用ValueState[T] getState(ValueStateDescriptor[T])方法，获取ReducingState可以调用ReducingState[T] getReducingState(ReducingStateDescriptor[T])方法。

## State生命周期
对于任何类型Keyed State都可以设定状态的生命周期（TTL），以确保能够在规定时间内及时地清理状态数据。状态生命周期功能可以通过StateTtlConfig配置，然后将StateTtlConfig配置传入StateDescriptor中的enableTimeToLive方法中即可。
状态生命周期配置
```java
//创建StateTtlConfig
val stateTtlConfig = StateTtlConfig
  //指定TTL时长为10s
  .newBuilder(Time.seconds(10))
  //指定TTL刷新时只对创建和写入操作有效
  .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
  //指定状态可见性为永远不反悔过期数据
  .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
  .build
//创建ValueStateDescriptor
val valueStateDescriptor = new ValueStateDescriptor[String]("valueState", classOf[Long])
//指定创建好的stateTtlConfig
valueStateDescriptor.enableTimeToLive(stateTtlConfig)
```
在StateTtlConfig中除了通过newBuilder方法中设定过期时间的参数是必需的之外，其他参数都是可选的或使用默认值。其中setUpdateType方法中传入的类型有两种：
- StateTtlConfig.UpdateType.OnCreateAndWrite仅在创建和写入时更新TTL；
- StateTtlConfig.UpdateType. OnReadAndWrite所有读与写操作都更新TTL。

需要注意的是，过期的状态数据根据UpdateType参数进行配置，只有被写入或者读取的时间才会更新TTL，也就是说如果某个状态指标一直不被使用或者更新，则永远不会触发对该状态数据的清理操作，这种情况可能会导致系统中的状态数据越来越大。目前用户可以使用StateTtlConfig. cleanupFullSnapshot设定当触发State Snapshot的时候清理状态数据，需要注意这个配置不适合用于RocksDB做增量Checkpointing的操作。

另外可以通过setStateVisibility方法设定状态的可见性，根据过期数据是否被清理来确定是否返回状态数据。
- StateTtlConfig.StateVisibility.NeverReturnExpired：状态数据过期就不会返回（默认）；
- StateTtlConfig.StateVisibility.ReturnExpiredIfNotCleanedUp：状态数据即使过期但没有被清理依然返回。

## Scala DataStream API中直接使用状态
除了通过定义RichFlatMapFunction或者FichMapFunction操作状态之外，Flink Scala版本的DataStream API提供了快捷方式来创建和查询状态数据。在KeyedStream接口中提供了filterWithState、mapWithState、flatMapWithState三种方法来定义和操作状态数据，以mapWithState为例，可以在mapWithState指定输入参数类型和状态数据类型，系统会自动创建count对应的状态来存储每次更新的累加值，整个过程不需要像实现RichFunciton那样操作状态数据。
使用mapuwithState直接操作状态数据
```java
//创建元素数据集
val inputStream: DataStream[(Int, Long)] = env.fromElements((2, 21L), (4, 1L), (5, 4L))
val counts: DataStream[(Int, Int)] = inputStream
  .keyBy(_._1)
  //指定输入参数类型和状态参数类型
  .mapWithState((in: (Int, Long), count: Option[Int]) =>
    //判断count类型是否非空
    count match {
        //输出key,count,并在原来的count数据上累加
      case Some(c) => ((in._1, c), Some(c + in._2))
        //如果输入状态为空，则将指标填入
      case None => ((in._1, 0), Some(in._2))
    })
```
## Managed Operator State
Operator State是一种non-keyed state，与并行的操作算子实例相关联，例如在Kafka Connector中，每个Kafka消费端算子实例都对应到Kafka的一个分区中，维护Topic分区和Offsets偏移量作为算子的Operator State。在Flink中可以实现Checkpointed-Function或者ListCheckpointed<T extends Serializable>两个接口来定义操作Managed Operator State的函数。
- 通过CheckpointedFunction接口操作Operator State
CheckpointedFunction接口定义需要实现两个方法，当checkpoint触发时就会调用snapshotState()方法，当初始化自定义函数的时候会调用initializeState()方法，其中包括第一次初始化函数和从之前的checkpoints中恢复状态数据，同时initializeState()方法中需要包含两套逻辑，一个是不同类型状态数据初始化的逻辑，另外一个是从之前的状态中恢复数据的逻辑。
```java
// CheckpointedFunction接口定义
public interface CheckpointedFunction {
  //每当checkpoint触发时，调用此方法
void snapshotState(FunctionSnapshotContext context) throws Exception;
  //每次自定义函数初始化的时候，调用此方法初始化状态
void initializeState(FunctionInitializationContext context) throws Exception;}
```
在每个算子中Managed Operator State都是以List形式存储，算子和算子之间的状态数据相互独立，List存储比较适合于状态数据的重新分布，Flink目前支持对Managed Operator State两种重分布的策略，分别是Even-split Redistribution和Union Redistribution。
- Even-split Redistribution：每个算子实例中含有部分状态元素的List列表，整个状态数据是所有List列表的合集。当触发restore/redistribution动作时，通过将状态数据平均分配成与算子并行度相同数量的List列表，每个task实例中有一个List，其可以为空或者含有多个元素。
- Union Redistribution：每个算子实例中含有所有状态元素的List列表，当触发restore/redistribution动作时，每个算子都能够获取到完整的状态元素列表。
例如可以通过实现FlatMapFunction和CheckpointedFunction完成对输入数据中每个key的数据元素数量和算子的元素数量的统计。通过在initializeState()方法中分别创建keyedState和operatorState两种状态，存储基于Key相关的状态值以及基于算子的状态值。

## 实现CheckpointedFunction接口利用Operator State统计输入到算子的数据量
```java
private class CheckpointCount(val numElements: Int)
  extends FlatMapFunction[(Int, Long), (Int, Long, Long)] with CheckpointedFunction {
  //定义算子实例本地变量，存储Operator数据数量
  private var operatorCount: Long = _
  //定义keyedState，存储和Key相关的状态值
  private var keyedState: ValueState[Long] = _
  //定义operatorState，存储算子的状态值
  private var operatorState: ListState[Long] = _
  override def flatMap(t: (Int, Long), collector: Collector[(Int, Long, Long)]): Unit = {
    val keyedCount = keyedState.value() + 1
    //更新keyedState数量
    keyedState.update(keyedCount)
    //更新本地算子operatorCount值
    operatorCount = operatorCount + 1
    //输出结果，包括id,id对应的数量统计keyedCount，算子输入数据的数量统计operatorCount
    collector.collect((t._1, keyedCount, operatorCount))
  }

  //初始化状态数据
  override def initializeState(context: FunctionInitializationContext): Unit = {
    //定义并获取keyedState
    keyedState = context.getKeyedStateStore.getState(
      new ValueStateDescriptor[Long](
        "keyedState", createTypeInformation[Long]))
    //定义并获取operatorState
    operatorState = context.getOperatorStateStore.getListState(
      new ListStateDescriptor[Long](
        "operatorState", createTypeInformation[Long]))
    //定义在Restored过程中，从operatorState中恢复数据的逻辑
    if (context.isRestored) {
      operatorCount = operatorState.get().asScala.sum
    }
  }
    //当发生snapshot时，将operatorCount添加到operatorState中
  override def snapshotState(context: FunctionSnapshotContext): Unit = {
    operatorState.clear() 
    operatorState.add(operatorCount)
    }}
```
可以从上述代码中看到的是，在snapshotState()方法中清理掉上一次checkpoint中存储的operatorState的数据，然后再添加并更新本次算子中需要checkpoint的operatorCount状态变量。当系统重启时会调用initializeState方法，重新恢复keyedState和operatorState，其中operatorCount数据可以从最新的operatorState中恢复。

对于状态数据重分布策略的使用，可以在创建operatorState的过程中通过相应的方法指定：如果使用Even-split Redistribution策略，则通过context. getListState(descriptor)获取Operator State；如果使用Union Redistribution策略，则通过context. getUnionList State(descriptor)来获取。实例代码中默认使用的Even-split Redistribution策略。

## 通过ListCheckpointed接口定义Operator State

ListCheckpointed接口和CheckpointedFunction接口相比在灵活性上相对弱一些，只能支持List类型的状态，并且在数据恢复的时候仅支持even-redistribution策略。在ListCheckpointed接口中需要实现以下两个方法来操作Operator State：
```java
List<T> snapshotState(long checkpointId, long timestamp) throws Exception;
void restoreState(List<T> state) throws Exception;
```
其中snapshotState方法定义数据元素List存储到checkpoints的逻辑，restoreState方法则定义从checkpoints中恢复状态的逻辑。如果状态数据不支持List形式，则可以在snapshotState方法中返回Collections.singletonList(STATE)。如代码清单5-6所示，通过实现FlatMapFunction接口和ListCheckpointed接口完成对输入到FlatMapFunction算子中的数据量统计，同时在函数中实现了snapshotState方法，将本地定义的算子变量numberRecords写入Operator State中，并通过restoreState方法从状态中恢复numberRecords数据。
实现ListCheckpointed接口利用Operator State统计算子输入数据量
```java
class numberRecordsCount extends FlatMapFunction[(String, Long), (String, 
Long)] with ListCheckpointed[Long] {
  //定义算子中接入的numberRecords数量
  private var numberRecords: Long = 0L
  override def flatMap(t: (String, Long), collector: Collector[(String, Long)]): Unit = {
    //接入一条记录则进行统计，并输出
    numberRecords += 1
    collector.collect(t._1, numberRecords)
  }
  override def snapshotState(checkpointId: Long, ts: Long): util.List[Long] = {
    //Snapshot状态的过程中将numberRecords写入
    Collections.singletonList(numberRecords)
  }
  override def restoreState(list: util.List[Long]): Unit = {
    numberRecords = 0L
    for (count <- list) {
      //从状态中恢复numberRecords数据
      numberRecords += count }}}
```






