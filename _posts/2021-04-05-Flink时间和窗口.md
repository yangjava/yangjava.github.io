---
layout: post
categories: [Flink]
description: none
keywords: Flink
---
# Flink时间和窗口

## 时间概念类型
对于流式数据处理，最大的特点是数据上具有时间的属性特征，Flimk根据时间产生的位置不同，将时间区分为三种时间概念，分别为事件生成时间（Event Time）、事件接入时间（Ingestion Time）和事件处理时间（Processing Time）。 数据从终端产生，或者从系统中产生的过程中生成的时间为事件生成时间，当数据经过消息中间件传入到Flink系统中，在DataSource中接入的时候会生成事件接入时间，当数据在Flink系统中通过各个算子实例执行转换操作的过程中，算子实例所在系统的时间为数据处理时间。Flink已经支持这三种类型时间概念，用户能够根据需要选择时间类型作为对流式数据的依据，这种情况极大地增强了对事件数据处理的灵活性和准确性。

### 事件时间（Event Time）
事件时间（Event Time）是每个独立事件在产生它的设备上发生的时间，这个时间通常在事件进入Flink之前就已经嵌入到事件中，时间顺序取决于事件产生的地方，和下游数据处理系统的时间无关。事件数据具有不变的事件时间属性，该时间自事件元素产生就不会改变。通常情况下可以在Flink系统中指定事件时间属性或者设定时间提取器来提取事件时间。

所有进入到Flink流式系统处理的事件，其时间都是在外部系统中产生，经过网络进入到Flink系统内处理的，在理论情况下（所有系统都具有相同系统时钟），事件时间对应的时间戳一定会早于在Flink系统中处理的时间戳，但在实际情况中往往会出现数据记录乱序、延迟到达等问题。基于EventTime的时间概念，数据处理过程依赖于数据本身产生的时间，而不是Flink系统中Operator所在主机节点的系统时间，这样能够借助于事件产生时的时间信息来还原事件的先后关系。

### 接入时间（Ingestion Time）
接入时间（Ingestion Time）是数据进入Flink系统的时间，Ingestion Time依赖于Source Operator所在主机的系统时钟。Ingestion Time介于Event Time和Process Time之间，相对于Process Time，Ingestion Time生成的代价相对较高，Ingestion Time具有一定的可预见性，主要因为Ingestion Time在数据接入过程生成后，时间戳就不再发生变化，和后续数据处理Operator所在机器的时钟没有关系，从而不会因为某台机器时钟不同步或网络时延而导致计算结果不准确的问题。但是需要注意的是相比于Event Time，Ingestion Time不能处理乱序事件，所以也就不用生成对应的Watermarks。

### 处理时间（Processing Time）
处理时间（Processing Time）是指数据在操作算子计算过程中获取到的所在主机时间。当用户选择使用Processing Time时，所有和时间相关的计算算子，例如Windows计算，在当前的任务中所有的算子将直接使用其所在主机的系统时间。Processing Time是Flink系统中最简单的一种时间概念，基于Processing Time时间概念，Flink的程序性能相对较高，延时也相对较低，对接入到系统中的数据时间相关的计算完全交给算子内部决定，时间窗口计算依赖的时间都是在具体算子运行的过程中产生，不需要做任何时间上的对比和协调。但Processing Time时间概念虽然在性能和易用性的角度上具有优势，但考虑到对数据乱序处理的情况，Processing Time就不是最优的选择。同时在分布式系统中，数据本身不乱序，但每台机器的时间如果不同步，也可能导致数据处理过程中数据乱序的问题，从而影响计算结果。总之，Processing Time概念适用于时间计算精度要求不是特别高的计算场景，例如统计某些延时非常高的日志数据等。

## 时间概念指定
在Flink中默认情况下使用是Process Time时间概念，如果用户选择使用Event Time或者Ingestion Time概念，则需要在创建的StreamExecutionEnvironment中调用setStream-TimeCharacteristic()方法设定系统的时间概念，如下代码使用TimeCharacteristic.EventTime作为系统的时间概念，这样对当前的StreamExecutionEnvironment会全局生效。对应的，如果使用Ingestion Time概念，则通过传入TimeCharacteristic. IngestionTime参数指定。
```java
val env = StreamExecutionEnvironment.getExecutionEnvironment()
//在系统中指定EventTime概念
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
```

## EventTime和Watermark
通常情况下，由于网络或系统等外部因素影响，事件数据往往不能及时传输至Flink系统中，导致数据乱序到达或者延迟到达等问题，因此，需要有一种机制能够控制数据处理的过程和进度，比如基于事件时间的Window创建后，具体该如何确定属于该Window的数据元素已经全部到达。如果确定全部到达，就可以对Window的所有数据做窗口计算操作（如汇总、分组等），如果数据没有全部到达，则继续等待该窗口中的数据全部到达才开始处理。这种情况下就需要用到水位线（WaterMarks）机制，它能够衡量数据处理进度（表达数据到达的完整性），保证事件数据（全部）到达Flink系统，或者在乱序及延迟到达时，也能够像预期一样计算出正确并且连续的结果。Flink会将用读取进入系统的最新事件时间减去固定的时间间隔作为Watermark，该时间间隔为用户外部配置的支持最大延迟到达的时间长度，也就是说理论上认为不会有事件超过该间隔到达，否则就认为是迟到事件或异常事件。

简单来讲，当事件接入到Flink系统时，会在Sources Operator中根据当前最新事件时间产生Watermarks时间戳，记为X，进入到Flink系统中的数据事件时间，记为Y，如果Y < X，则代表Watermark X时间戳之前的所有事件均已到达，同时Window的End Time大于Watermark，则触发窗口计算结果并输出。从另一个角度讲，如果想触发对Window内的数据元素的计算，就必须保证对所有进入到窗口的数据元素满足其事件时间Y >= X，否则窗口会继续等待Watermark大于窗口结束时间的条件满足。可以看出当有了Watermarks机制后，对基于事件时间的流数据处理会变得特别灵活，可以有效地处理乱序事件的问题，保证数据在流式统计中的结果的正确性。

### 顺序事件中的Watermarks
如果数据元素的事件时间是有序的，Watermark时间戳会随着数据元素的事件时间按顺序生成，此时水位线的变化和事件时间保持一直，也就是理想状态下的水位线。当Watermark时间大于Windows结束时间就会触发对Windows的数据计算，并创建另一个新的Windows将事件时间Y < X的数据元素分配到新的Window中。事件按照其原本的顺序进入系统中，Watermark跟随着事件时间之后生成，可以看出Watermarks其实只是对Stream简单地进行周期性地标记，并没有特别大的意义，也就是说在顺序事件的数据处理过程中，Watermarks并不能发挥太大的价值，反而会因为设定了超期时间而导致延迟输出计算结果。

### 乱序事件中的Watermarks
现实情况下数据元素往往并不是按照其产生顺序接入到Flink系统中进行处理，而频繁出现乱序或迟到的情况，这种情况就需要使用Watermarks来应对。如图4-9所示。事件11和事件17进入到系统中，Flink系统根据设定的延时值分别计算出Watermark W(11)和W(17)，这两个Watermark到达一个Operator中后，便立即调整算子基于事件时间的虚拟时钟与当前的Watermark的值匹配，然后再触发相应的计算以及输出操作。

### 并行数据流中的Watermarks
Watermark在Source Operator中生成，并且在每个Source Operator的子Task中都会独立生成Watermark。在Source Operator的子任务中生成后就会更新该Task的Watermark，且会逐步更新下游算子中的Watermark水位线，随后一致保持在该并发之中，直到下一次Watermarks的生成，并对前面的Watermarks进行覆盖。如图4-10所示，W(17)水位线已经将Source算子和Map算子的子任务时钟的时间全部更新为值17，并且一直会随着事件向后移动更新下游算子中的事件时间。如果多个Watermark同时更新一个算子Task的当前事件时间，Flink会选择最小的水位线来更新，当一个Window算子Task中水位线大于了Window结束时间，就会立即触发窗口计算。

## 指定Timestamps与生成Watermarks
如果使用Event Time时间概念处理流式数据，除了在StreamExecationEviromment中指定TimeCharacteristic外，还需要在Flink程序中指定Event Time时间戳在数据中的字段信息，在Flink程序运行过程中会通过指定字段抽取出对应的事件时间，该过程叫作Timestamps Assigning。简单来讲，就是告诉系统需要用哪个字段作为事件时间的数据来源。另外Timestamps指定完毕后，下面就需要制定创建相应的Watermarks，需要用户定义根据Timestamps计算出Watermarks的生成策略。目前Flink支持两种方式指定Timestamps和生成Watermarks，一种方式在DataStream Source算子接口的Source Function中定义，另外一种方式是通过自定义Timestamp Assigner和Watermark Generator生成。

### 在Source Function中直接定义Timestamps和Watermarks
在DataStream Source算子中指定EventTime Timestamps，也就是说在数据进入到Flink系统中就直接指定分配EventTime和Watermark。用户需要复写SourceFunciton接口中run()方法实现数据生成逻辑，同时需要调用SourceContext的collectWithTimestamp()方法生成EventTime时间戳，调用emitWatermark()方法生成Watermarks。如代码清单4-6所示，在addSource中通过匿名类实现SourceFunction接口，将本地集合数据读取到系统中，并且分别调用collectWithTimestamp和emitWatermark方法指定EventTime和生成Watermark。
```java
//创建数组数据集
val input = List(("a", 1L, 1), ("b", 1L, 1), ("b", 3L, 1))
//添加DataSource数据源，实例化SourceFunction接口
val source: DataStream[(String, Long, Int)] = env.addSource(
  new SourceFunction[(String, Long, Int)]() {
    //复写run方法，调用SourceContext接口
    override def run(ctx: SourceContext[(String, Long, Int)]): Unit = {
      input.foreach(value => {
        //调用collectWithTimestamp增加Event Time抽取
        ctx.collectWithTimestamp(value, value._2)
        //调用emitWatermark,创建Watermark,最大延时设定为1
        ctx.emitWatermark(new Watermark(value._2 - 1))
      })
      //设定默认Watermark
      ctx.emitWatermark(new Watermark(Long.MaxValue))
    }
    override def cancel(): Unit = {}
  })
```

### 通过Flink自带的Timestamp Assigner指定Timestamp和生成Watermark
如果用户使用了Flink已经定义的外部数据源连接器，就不能再实现SourceFuncton接口来生成流式数据以及相应的Event Time和Watermark，这种情况下就需要借助Timestamp Assigner来管理数据流中的Timestamp元素和Watermark。Timestamp Assigner一般是跟在Data Source算子后面指定，也可以在后续的算子中指定，只要保证Timestamp Assigner在第一个时间相关的Operator之前即可。如果用户已经在SourceFunciton中定义Timestamps和Watermarks的生成逻辑，同时又使用了Timestamp Assigner，此时Assigner会覆盖Source Function中定义的逻辑。

Flink将Watermarks根据生成形式分为两种类型，分别是Periodic Watermarks和后者。Periodic Watermarks是根据设定时间间隔周期性地生成Watermarks，Punctuated Watermarks是根据接入数据的数量生成，例如数据流中特定数据元素的数量满足条件后触发生成Watermark。在Flink中两种生成Watermarks的逻辑分别借助于AssignerWithPeriodicWatermarks和AssignerWithPunctuatedWatermarks接口定义。

在Flink系统中实现了两种Periodic Watermark Assigner，一种为升序模式，会将数据中的Timestamp根据指定字段提取，并用当前的Timestamp作为最新的Watermark，这种Timestamp Assigner比较适合于事件按顺序生成，没有乱序事件的情况；另外一种是通过设定固定的时间间隔来指定Watermark落后于Timestamp的区间长度，也就是最长容忍迟到多长时间内的数据到达系统。

使用Ascending Timestamp Assigner指定Timestamps和Watermarks
如下代码所示，通过调用DataStream API中的assignAscendingTimestamps来指定Timestamp字段，不需要显示地指定Watermark，因为已经在系统中默认使用Timestamp创建Watermark。
```java
//指定系统时间概念为EventTime
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
val input = env.fromCollection(List(("a", 1L, 1), ("b", 1L, 1), ("b", 3L, 1)))
//使用系统默认Ascending分配时间信息和Watermark
val withTimestampsAndWatermarks = input.assignAscendingTimestamps(t => t._3)
//对数据集进行窗口运算
val result = withTimestampsAndWatermarks.keyBy(0).timeWindow(Time.seconds(10)).sum("_2")
```

使用固定时延间隔的Timestamp Assigner指定Timestamps和Watermarks
如下代码所示，通过创建BoundedOutOfOrdernessTimestampExtractor实现类来定义Timestamp Assigner，其中第一个参数Time.seconds(10)代表了最长的时延为10s，第二个参数为extractTimestamp抽取逻辑。在代码中选择使用input数据集中第三个元素作为Event Timestamp，其中Watermarks的创建是根据Timestamp减去固定时间长度生成，如果当前数据中的时间大于Watermarks的时间，则会被认为是迟到事件，具体迟到事件处理策略可以参考后续章节。
```java
val withTimestampsAndWatermarks = input.assignTimestampsAndWatermarks(new 
BoundedOutOfOrdernessTimestampExtractor[(String,Long,Int)](Time.seconds(10)){
//定义抽取EventTime Timestamp逻辑
  override def extractTimestamp(t: (String, Long, Int)): Long = t._2
})
```

自定义Timestamp Assigner和Watermark Generator

前面使用Flink系统中已经定义好的两种Timestamp Assigner，用户也可以自定义实现AssignerWithPeriodicWatermarks和AssignerWithPunctuatedWatermarks两个接口来分别生成Periodic Watermarks和Punctuated Watermarks。

1）Periodic Watermarks自定义生成

Periodic Watermarks根据固定的时间间隔，周期性地在Flink系统中分配Timestamps和生成Watermarks，在定义和实现AssignerWithPeriodicWatermarks接口之前，需要先在ExecutionConfig中调用setAutoWatermarkInterval()方法设定Watermarks产生的时间周期。
```java
ExecutionConfig.setAutoWatermarkInterval(...)

```
如代码清单4-7所示，通过创建Class实现AssignerWithPeriodicWatermarks接口，复写extractTimestamp和getCurrentWatermark两个方法，其中extractTimestamp定义了抽取TimeStamps的逻辑，getCurrentWatermark定义了生成Watermark的逻辑。其中getCurrentWatermark生成Watermark依赖于currentMaxTimestamp，getCurrentWatermark()方法每次都会被调用时，如果新产生的Watermark比现在的大，就会覆盖掉现有的Watermark，从而实现对Watermarks数据的更新。

代码清单4-7　通过实现AssignerWithPeriodicWatermarks接口自定义生成Watermark
```java
class PeriodicAssigner extends 
      AssignerWithPeriodicWatermarks[(String,Long,Int)] {
  val maxOutOfOrderness = 1000L // 1秒时延设定，表示在1秒以内的数据延时有效，超过一秒的数据被认定为迟到事件
  var currentMaxTimestamp: Long = _
  override def extractTimestamp(event: (String,Long,Int), previousEventTimestamp: Long): Long = {
    //复写currentTimestamp方法，获取当前事件时间
    val currentTimestamp = event._2
    //对比当前的事件时间和历史最大事件时间，将最新的时间赋值给currentMaxTimestamp变量
    currentMaxTimestamp = max(currentTimestamp, currentMaxTimestamp)
    currentTimestamp
  }
    //复写getCurrentWatermark方法，生成Watermark
  override def getCurrentWatermark(): Watermark = {
    // 根据最大事件时间减去最大的乱序时延长度，然后得到Watermark
    new Watermark(currentMaxTimestamp - maxOutOfOrderness)
  }
}
```
Punctuated Watermarks自定义生成
除了根据时间周期生成Periodic Watermark，用户也可以根据某些特殊条件生成Punctuated Watermarks，例如判断某个数据元素的当前状态，如果接入事件中状态为0则触发生成Watermarks，如果状态不为0，则不触发生成Watermarks的逻辑。生成Punctuated Watermark的逻辑需要通过实现AssignerWithPunctuatedWatermarks接口定义，然后分别复写extractTimestamp方法和checkAndGetNextWatermark方法，完成抽取Event Time和生成Watermark逻辑的定义，具体实现如代码清单4-8所示。

代码清单4-8　通过实现AssignerWithPunctuatedWatermarks接口自定义生成Watermark
```java
class PunctuatedAssigner extends AssignerWithPunctuatedWatermarks[(String, 
Long, Int)] {
  //复写extractTimestamp方法，定义抽取Timestamp逻辑
  override def extractTimestamp(element: (String, Long, Int), previousElementTimestamp: Long): Long = {
    element._2
  }
  //复写checkAndGetNextWatermark方法，定义Watermark生成逻辑
  override def checkAndGetNextWatermark(lastElement: (String, Long, Int), extractedTimestamp: Long): Watermark = {
    //根据元素中第三位字段状态是否为0生成Watermark
    if (lastElement._3 == 0) new Watermark(extractedTimestamp) else null
  }
}
```

# Flink窗口

## Windows窗口计算
Windows计算是流式计算中非常常用的数据计算方式之一，通过按照固定时间或长度将数据流切分成不同的窗口，然后对数据进行相应的聚合运算，从而得到一定时间范围内的统计结果。例如统计最近5分钟内某网站的点击数，此时点击的数据在不断地产生，但是通过5分钟的窗口将数据限定在固定时间范围内，就可以对该范围内的有界数据执行聚合处理，得出最近5分钟的网站点击数。

Flink DataStream API将窗口抽象成独立的Operator，且在Flink DataStream API中已经內建了大多数窗口算子。如下代码展示了如何定义Keyed Windows算子，在每个窗口算子中包含了Windows Assigner、Windows Trigger（窗口触发器）、Evictor（数据剔除器）、Lateness（时延设定）、Output Tag（输出标签）以及Windows Funciton等组成部分，其中Windows Assigner和Windows Funciton是所有窗口算子必须指定的属性，其余的属性都是根据实际情况选择指定。
```java
stream.keyBy(...) // 是Keyed类型数据集
.window(...)  //指定窗口分配器类型
[.trigger(...)] //指定触发器类型（可选）
[.evictor(...)]    //指定evictor或者不指定（可选）
[.allowedLateness(...)]   //指定是否延迟处理数据（可选）
[.sideOutputLateData(...)] //指定Output Lag（可选）
.reduce/aggregate/fold/apply()   //指定窗口计算函数
[.getSideOutput(...)]    //根据Tag输出数据（可选）
```
- Windows Assigner：指定窗口的类型，定义如何将数据流分配到一个或多个窗口；
- Windows Trigger：指定窗口触发的时机，定义窗口满足什么样的条件触发计算；
- Evictor：用于数据剔除；
- Lateness：标记是否处理迟到数据，当迟到数据到达窗口中是否触发计算；
- Output Tag：标记输出标签，然后在通过getSideOutput将窗口中的数据根据标签输出；
- Windows Funciton：定义窗口上数据处理的逻辑，例如对数据进行sum操作。





