---
layout: post
categories: [MySQL]
description: none
keywords: MySQL
---
# MySQL源码磁盘存储

## 磁盘结构
InnoDB磁盘结构主要包含表空间，数据字典，双写缓冲区、日志（重做日志和撤销日志）。说起内存结构和磁盘结构，很多人可能有点晕，确实，刚刚接触的或者没有搞清楚是什么问题的，一定会有些晕。

其实这个如果搞过内存数据写物理文件的，就容易理解了。 在内存中，会有一套数据结构，然后会把这些数据最终整理成一套易于和硬盘交互的结构，这样，就更容易程序的编写和维护。

如果单纯是为了实现功能，写代码其实并不会有多么复杂。优秀的框架代码之所以为初学者感觉到复杂的原因，正是因为弹性扩展和高度的抽象，主要的目的就是为了适应性尽可能大一些，维护更方便一些。

## 表空间
说起表空间，其实很多人，包括许多用了数据库多年的人，也说不出这玩意儿到底是个啥。什么是表空间呢？如果用过Oracle，就会知道Oracle搞的表空间。表空间是一个逻辑概念，什么是逻辑概念呢，其实就是前面提到的这是一个抽象的数据管理概念。

之所以很多人对表空间觉得似是而非，主要原因也在于这个空间的抽象。一个表空间只能归属于一个数据库，但是数据库对象都要存放在指定的表空间中。之所以叫表空间，是因为在数据库中，最常见，最多，最为人熟知的就是表，而这个空间中存放的主要也是表，所以叫做表空间。

在MySql中主要分为以下几类：
### 系统表空间
Change Buffer相关数据就是存储在系统表空间。包括一些辅助索引的变化，当数据库Crash时，这些变更会Flush磁盘的相关Change Buffer中。除此之外，它还可以存储某些表和索引的数据；不同的版本中系统 表空间对存放的数据字典也有不同，老版本中直接包含InnoDB的数据字典；系统表空间在MySql8之后开始使用SDI（Serialized Dictionary Information）来存储相关元数据信息。

### 独立表空间
独立表空间是一个单表表空间，其创建于本身的数据文件，而不是上面提到的系统表空间。其支持动态和压缩行格式。此表空间默认是开启的。

### 通用表空间
CREATE TABLESPACE创建的表空间为通用表空间，是一个共享的表空间，一个文件可以存储多个表。

### Undo表空间
这个就好理解了，用来回滚表的空间，即存储回滚日志。

- 临时表空间
这个不用多说吧，就是一个暂时使用的表空间。会话临时表空间和全局临时表空间是比较常见的两种。

## 数据字典
数据字典是描述数据的信息集合是对数据库中所有数据元素定义的集合。在MySql的InnoDB中，数据字典由内部的系统表组成。这些系统表的主要作用就是对表和索引等的元数据的描述。换句话说，元数据在位于InnoDB的系统表空间中（由于版本延革的不同，导致元数据文件与其信息出现重合）。

数据字典的和元数据关系密切，其实说句不太贴切的话，就是配置的数据和根据配置生成的相关的数据库的信息的数据，它的代码主要在inlude/dict0dd.h dict0dd.ic中。
```
/** Hard-coded data dictionary information */
struct innodb_dd_table_t {
  /** Data dictionary table name */
  const char *name;
  /** Number of indexes */
  const uint n_indexes;
};
/** The hard-coded data dictionary tables. */
const innodb_dd_table_t innodb_dd_table[] = {
    INNODB_DD_TABLE("dd_properties", 1),

    INNODB_DD_TABLE("innodb_dynamic_metadata", 1),
    INNODB_DD_TABLE("innodb_table_stats", 1),
    INNODB_DD_TABLE("innodb_index_stats", 1),
    INNODB_DD_TABLE("innodb_ddl_log", 2),

    INNODB_DD_TABLE("catalogs", 2),
    INNODB_DD_TABLE("character_sets", 3),
    INNODB_DD_TABLE("check_constraints", 3),
    INNODB_DD_TABLE("collations", 3),
    INNODB_DD_TABLE("column_statistics", 3),
    INNODB_DD_TABLE("column_type_elements", 1),
    INNODB_DD_TABLE("columns", 5),
    INNODB_DD_TABLE("events", 6),
    INNODB_DD_TABLE("foreign_key_column_usage", 3),
    INNODB_DD_TABLE("foreign_keys", 4),
    INNODB_DD_TABLE("index_column_usage", 3),
    INNODB_DD_TABLE("index_partitions", 3),
    INNODB_DD_TABLE("index_stats", 1),
    INNODB_DD_TABLE("indexes", 3),
    INNODB_DD_TABLE("parameter_type_elements", 1),
    INNODB_DD_TABLE("parameters", 3),
    INNODB_DD_TABLE("resource_groups", 2),
    INNODB_DD_TABLE("routines", 7),
    INNODB_DD_TABLE("schemata", 3),
    INNODB_DD_TABLE("st_spatial_reference_systems", 3),
    INNODB_DD_TABLE("table_partition_values", 1),
    INNODB_DD_TABLE("table_partitions", 7),
    INNODB_DD_TABLE("table_stats", 1),
    INNODB_DD_TABLE("tables", 10),
    INNODB_DD_TABLE("tablespace_files", 2),
    INNODB_DD_TABLE("tablespaces", 2),
    INNODB_DD_TABLE("triggers", 7),
    INNODB_DD_TABLE("view_routine_usage", 2),
    INNODB_DD_TABLE("view_table_usage", 2)};


    /** Data structure for a database table.  Most fields will be
    initialized to 0, NULL or FALSE in dict_mem_table_create(). */
    struct dict_table_t {
      /** Check if the table is compressed.
      @return true if compressed, false otherwise. */
      bool is_compressed() const { return (DICT_TF_GET_ZIP_SSIZE(flags) != 0); }

      /** Get reference count.
      @return current value of n_ref_count */
      inline uint64_t get_ref_count() const;

      /** Acquire the table handle. */
      inline void acquire();

      /** Acquire the table handle, with lock() and unlock() the table.
      This function needs to be called for opening table when the table
      is in memory and later the stats information would be initialized */
      inline void acquire_with_lock();

      /** Release the table handle. */
      inline void release();

      /** Lock the table handle. */
      inline void lock();

      /** Unlock the table handle. */
      inline void unlock();

    #ifndef UNIV_HOTBACKUP
      /** Get schema and table name in system character set.
      @param[out]	schema	schema name
      @param[out]	table	table name */
      void get_table_name(std::string &schema, std::string &table);

      /** Mutex of the table for concurrency access. */
      ib_mutex_t *mutex;

      /** Creation state of mutex. */
      std::atomic<os_once::state_t> mutex_created;
    #endif /* !UNIV_HOTBACKUP */

      /** Id of the table. */
      table_id_t id;

      /** Memory heap. If you allocate from this heap after the table has
      been created then be sure to account the allocation into
      dict_sys->size. When closing the table we do something like
      dict_sys->size -= mem_heap_get_size(table->heap) and if that is going
      to become negative then we would assert. Something like this should do:
      old_size = mem_heap_get_size()
      mem_heap_alloc()
      new_size = mem_heap_get_size()
      dict_sys->size += new_size - old_size. */
      mem_heap_t *heap;

      /** Table name. */
      table_name_t name;

      /** Truncate name. */
      table_name_t trunc_name;

      /** NULL or the directory path specified by DATA DIRECTORY. */
      char *data_dir_path;

      /** NULL or the tablespace name that this table is assigned to,
      specified by the TABLESPACE option.*/
      id_name_t tablespace;

      /** Space where the clustered index of the table is placed. */
      space_id_t space;

      /** dd::Tablespace::id of the table */
      dd::Object_id dd_space_id;

      /** Stores information about:
      1 row format (redundant or compact),
      2 compressed page size (zip shift size),
      3 whether using atomic blobs,
      4 whether the table has been created with the option DATA DIRECTORY.
      Use DICT_TF_GET_COMPACT(), DICT_TF_GET_ZIP_SSIZE(),
      DICT_TF_HAS_ATOMIC_BLOBS() and DICT_TF_HAS_DATA_DIR() to parse this
      flag. */
      unsigned flags : DICT_TF_BITS;

      /** Stores information about:
      1 whether the table has been created using CREATE TEMPORARY TABLE,
      2 whether the table has an internally defined DOC ID column,
      3 whether the table has a FTS index,
      4 whether DOC ID column need to be added to the FTS index,
      5 whether the table is being created its own tablespace,
      6 whether the table has been DISCARDed,
      7 whether the aux FTS tables names are in hex.
      8 whether the table is instinc table.
      9 whether the table has encryption setting.
      Use DICT_TF2_FLAG_IS_SET() to parse this flag. */
      unsigned flags2 : DICT_TF2_BITS;

      /** TRUE if the table is an intermediate table during copy alter
      operation or a partition/subpartition which is required for copying
      data and skip the undo log for insertion of row in the table.
      This variable will be set and unset during extra(), or during the
      process of altering partitions */
      unsigned skip_alter_undo : 1;

      /** TRUE if this is in a single-table tablespace and the .ibd file is
      missing. Then we must return in ha_innodb.cc an error if the user
      tries to query such an orphaned table. */
      unsigned ibd_file_missing : 1;

      /** TRUE if the table object has been added to the dictionary cache. */
      unsigned cached : 1;

      /** TRUE if the table is to be dropped, but not yet actually dropped
      (could in the background drop list). It is turned on at the beginning
      of row_drop_table_for_mysql() and turned off just before we start to
      update system tables for the drop. It is protected by
      dict_operation_lock. */
      unsigned to_be_dropped : 1;

      /** Number of non-virtual columns defined so far. */
      unsigned n_def : 10;

      /** Number of non-virtual columns. */
      unsigned n_cols : 10;

      /** Number of non-virtual columns before first instant ADD COLUMN,
      including the system columns like n_cols. */
      unsigned n_instant_cols : 10;

      /** Number of total columns (inlcude virtual and non-virtual) */
      unsigned n_t_cols : 10;

      /** Number of total columns defined so far. */
      unsigned n_t_def : 10;

      /** Number of virtual columns defined so far. */
      unsigned n_v_def : 10;

      /** Number of virtual columns. */
      unsigned n_v_cols : 10;

      /** Number of multi-value virtual columns. */
      unsigned n_m_v_cols : 10;

      /** TRUE if this table is expected to be kept in memory. This table
      could be a table that has FK relationships or is undergoing DDL */
      unsigned can_be_evicted : 1;

      /** TRUE if this table is not evictable(can_be_evicted) and this is
      because of DDL operation */
      unsigned ddl_not_evictable : 1;

      /** TRUE if some indexes should be dropped after ONLINE_INDEX_ABORTED
      or ONLINE_INDEX_ABORTED_DROPPED. */
      unsigned drop_aborted : 1;

      /** Array of column descriptions. */
      dict_col_t *cols;

      /** Array of virtual column descriptions. */
      dict_v_col_t *v_cols;

      /** List of stored column descriptions. It is used only for foreign key
      check during create table and copy alter operations.
      During copy alter, s_cols list is filled during create table operation
      and need to preserve till rename table operation. That is the
      reason s_cols is a part of dict_table_t */
      dict_s_col_list *s_cols;

      /** Column names packed in a character string
      "name1\0name2\0...nameN\0". Until the string contains n_cols, it will
      be allocated from a temporary heap. The final string will be allocated
      from table->heap. */
      const char *col_names;

      /** Virtual column names */
      const char *v_col_names;

      /** True if the table belongs to a system database (mysql, information_schema
      or performance_schema) */
      bool is_system_table;

      /** Hash chain node. */
      hash_node_t name_hash;

      /** Hash chain node. */
      hash_node_t id_hash;

      /** The FTS_DOC_ID_INDEX, or NULL if no fulltext indexes exist */
      dict_index_t *fts_doc_id_index;

      /** List of indexes of the table. */
      UT_LIST_BASE_NODE_T(dict_index_t) indexes;

      /** List of foreign key constraints in the table. These refer to
      columns in other tables. */
      UT_LIST_BASE_NODE_T(dict_foreign_t) foreign_list;

      /** List of foreign key constraints which refer to this table. */
      UT_LIST_BASE_NODE_T(dict_foreign_t) referenced_list;

      /** Node of the LRU list of tables. */
      UT_LIST_NODE_T(dict_table_t) table_LRU;

      /** metadata version number of dd::Table::se_private_data() */
      uint64_t version;

      /** table dynamic metadata status, protected by dict_persist->mutex */
      std::atomic<table_dirty_status> dirty_status;

    #ifndef UNIV_HOTBACKUP
      /** Node of the dirty table list of tables, which is protected
      by dict_persist->mutex */
      UT_LIST_NODE_T(dict_table_t) dirty_dict_tables;
    #endif /* !UNIV_HOTBACKUP */

    #ifdef UNIV_DEBUG
      /** This field is used to mark if a table is in the
      dirty_dict_tables_list. if the dirty_status is not of
      METADATA_CLEAN, the table should be in the list, otherwise not.
      This field should be protected by dict_persist->mutex too. */
      bool in_dirty_dict_tables_list;
    #endif /* UNIV_DEBUG */

      /** Maximum recursive level we support when loading tables chained
      together with FK constraints. If exceeds this level, we will stop
      loading child table into memory along with its parent table. */
      unsigned fk_max_recusive_level : 8;

      /** Count of how many foreign key check operations are currently being
      performed on the table. We cannot drop the table while there are
      foreign key checks running on it. */
      std::atomic<ulint> n_foreign_key_checks_running;

      /** Transaction id that last touched the table definition. Either when
      loading the definition or CREATE TABLE, or ALTER TABLE (prepare,
      commit, and rollback phases). */
      trx_id_t def_trx_id;

      /*!< set of foreign key constraints in the table; these refer to
      columns in other tables */
      dict_foreign_set foreign_set;

      /*!< set of foreign key constraints which refer to this table */
      dict_foreign_set referenced_set;

    #ifdef UNIV_DEBUG
      /** This field is used to specify in simulations tables which are so
      big that disk should be accessed. Disk access is simulated by putting
      the thread to sleep for a while. NOTE that this flag is not stored to
      the data dictionary on disk, and the database will forget about value
      TRUE if it has to reload the table definition from disk. */
      ibool does_not_fit_in_memory;
    #endif /* UNIV_DEBUG */

      /** TRUE if the maximum length of a single row exceeds BIG_ROW_SIZE.
      Initialized in dict_table_add_to_cache(). */
      unsigned big_rows : 1;

    #ifndef UNIV_HOTBACKUP
      /** Statistics for query optimization. @{ */

      /** Creation state of 'stats_latch'. */
      std::atomic<os_once::state_t> stats_latch_created;

      /** This latch protects:
      "dict_table_t::stat_initialized",
      "dict_table_t::stat_n_rows (*)",
      "dict_table_t::stat_clustered_index_size",
      "dict_table_t::stat_sum_of_other_index_sizes",
      "dict_table_t::stat_modified_counter (*)",
      "dict_table_t::indexes*::stat_n_diff_key_vals[]",
      "dict_table_t::indexes*::stat_index_size",
      "dict_table_t::indexes*::stat_n_leaf_pages".
      (*) Those are not always protected for
      performance reasons. */
      rw_lock_t *stats_latch;

      /** TRUE if statistics have been calculated the first time after
      database startup or table creation. */
      unsigned stat_initialized : 1;

      /** Timestamp of last recalc of the stats. */
      ib_time_monotonic_t stats_last_recalc;

    /** The two bits below are set in the 'stat_persistent' member. They
    have the following meaning:
    1. _ON=0, _OFF=0, no explicit persistent stats setting for this table,
    the value of the global srv_stats_persistent is used to determine
    whether the table has persistent stats enabled or not
    2. _ON=0, _OFF=1, persistent stats are explicitly disabled for this
    table, regardless of the value of the global srv_stats_persistent
    3. _ON=1, _OFF=0, persistent stats are explicitly enabled for this
    table, regardless of the value of the global srv_stats_persistent
    4. _ON=1, _OFF=1, not allowed, we assert if this ever happens. */
    #define DICT_STATS_PERSISTENT_ON (1 << 1)
    #define DICT_STATS_PERSISTENT_OFF (1 << 2)

      /** Indicates whether the table uses persistent stats or not. See
      DICT_STATS_PERSISTENT_ON and DICT_STATS_PERSISTENT_OFF. */
      ib_uint32_t stat_persistent;

    /** The two bits below are set in the 'stats_auto_recalc' member. They
    have the following meaning:
    1. _ON=0, _OFF=0, no explicit auto recalc setting for this table, the
    value of the global srv_stats_persistent_auto_recalc is used to
    determine whether the table has auto recalc enabled or not
    2. _ON=0, _OFF=1, auto recalc is explicitly disabled for this table,
    regardless of the value of the global srv_stats_persistent_auto_recalc
    3. _ON=1, _OFF=0, auto recalc is explicitly enabled for this table,
    regardless of the value of the global srv_stats_persistent_auto_recalc
    4. _ON=1, _OFF=1, not allowed, we assert if this ever happens. */
    #define DICT_STATS_AUTO_RECALC_ON (1 << 1)
    #define DICT_STATS_AUTO_RECALC_OFF (1 << 2)

      /** Indicates whether the table uses automatic recalc for persistent
      stats or not. See DICT_STATS_AUTO_RECALC_ON and
      DICT_STATS_AUTO_RECALC_OFF. */
      ib_uint32_t stats_auto_recalc;

      /** The number of pages to sample for this table during persistent
      stats estimation. If this is 0, then the value of the global
      srv_stats_persistent_sample_pages will be used instead. */
      ulint stats_sample_pages;

      /** Approximate number of rows in the table. We periodically calculate
      new estimates. */
      ib_uint64_t stat_n_rows;

      /** Approximate clustered index size in database pages. */
      ulint stat_clustered_index_size;

      /** Approximate size of other indexes in database pages. */
      ulint stat_sum_of_other_index_sizes;

      /** If FTS AUX table, parent table id */
      table_id_t parent_id;

      /** How many rows are modified since last stats recalc. When a row is
      inserted, updated, or deleted, we add 1 to this number; we calculate
      new estimates for the table and the indexes if the table has changed
      too much, see row_update_statistics_if_needed(). The counter is reset
      to zero at statistics calculation. This counter is not protected by
      any latch, because this is only used for heuristics. */
      ib_uint64_t stat_modified_counter;

    /** Background stats thread is not working on this table. */
    #define BG_STAT_NONE 0

    /** Set in 'stats_bg_flag' when the background stats code is working
    on this table. The DROP TABLE code waits for this to be cleared before
    proceeding. */
    #define BG_STAT_IN_PROGRESS (1 << 0)

    /** Set in 'stats_bg_flag' when DROP TABLE starts waiting on
    BG_STAT_IN_PROGRESS to be cleared. The background stats thread will
    detect this and will eventually quit sooner. */
    #define BG_STAT_SHOULD_QUIT (1 << 1)

      /** The state of the background stats thread wrt this table.
      See BG_STAT_NONE, BG_STAT_IN_PROGRESS and BG_STAT_SHOULD_QUIT.
      Writes are covered by dict_sys->mutex. Dirty reads are possible. */
      byte stats_bg_flag;

      /** @} */
    #endif /* !UNIV_HOTBACKUP */

      /** AUTOINC related members. @{ */

      /* The actual collection of tables locked during AUTOINC read/write is
      kept in trx_t. In order to quickly determine whether a transaction has
      locked the AUTOINC lock we keep a pointer to the transaction here in
      the 'autoinc_trx' member. This is to avoid acquiring lock_sys latches and
      scanning the vector in trx_t.
      When an AUTOINC lock has to wait, the corresponding lock instance is
      created on the trx lock heap rather than use the pre-allocated instance
      in autoinc_lock below. */

      /** A buffer for an AUTOINC lock for this table. We allocate the
      memory here so that individual transactions can get it and release it
      without a need to allocate space from the lock heap of the trx:
      otherwise the lock heap would grow rapidly if we do a large insert
      from a select. */
    #ifndef UNIV_HOTBACKUP
      lock_t *autoinc_lock;

      /** Creation state of autoinc_mutex member */
      std::atomic<os_once::state_t> autoinc_mutex_created;
    #endif /* !UNIV_HOTBACKUP */

      /** Mutex protecting the autoincrement counter. */
      ib_mutex_t *autoinc_mutex;

      /** Autoinc counter value to give to the next inserted row. */
      ib_uint64_t autoinc;

      /** Mutex protecting the persisted autoincrement counter. */
      ib_mutex_t *autoinc_persisted_mutex;

      /** Autoinc counter value that has been persisted in redo logs or
      DDTableBuffer. It's mainly used when we want to write counter back
      to DDTableBuffer.
      This is different from the 'autoinc' above, which could be bigger
      than this one, because 'autoinc' will get updated right after
      some counters are allocated, but we will write the counter to redo
      logs and update this counter later. Once all allocated counters
      have been written to redo logs, 'autoinc' should be exact the next
      counter of this persisted one.
      We want this counter because when we need to write the counter back
      to DDTableBuffer, we had better keep it consistency with the counter
      that has been written to redo logs. Besides, we can't read the 'autoinc'
      directly easily, because the autoinc_lock is required and there could
      be a deadlock.
      This variable is protected by autoinc_persisted_mutex. */
      ib_uint64_t autoinc_persisted;

      /** The position of autoinc counter field in clustered index. This would
      be set when CREATE/ALTER/OPEN TABLE and IMPORT TABLESPACE, and used in
      modifications to clustered index, such as INSERT/UPDATE. There should
      be no conflict to access it, so no protection is needed. */
      ulint autoinc_field_no;

      /** The transaction that currently holds the the AUTOINC lock on this table.
      Protected by lock_sys table shard latch. To "peek" the current value one
      can read it without any latch, understanding that in general it may change.
      Such access pattern is correct if trx thread wants to check if it has the lock
      granted, as the field can only change to other value when lock is released,
      which can not happen concurrently to thread executing the trx. */
      std::atomic<const trx_t *> autoinc_trx;

      /** @} */

    #ifndef UNIV_HOTBACKUP
      /** FTS specific state variables. */
      fts_t *fts;
    #endif /* !UNIV_HOTBACKUP */

      /** Quiescing states, protected by the dict_index_t::lock. ie. we can
      only change the state if we acquire all the latches (dict_index_t::lock)
      in X mode of this table's indexes. */
      ib_quiesce_t quiesce;

      /** Count of the number of record locks on this table. We use this to
      determine whether we can evict the table from the dictionary cache.
      Writes (atomic increments and decrements) are performed when holding a shared
      latch on lock_sys. (Note that this the table's shard latch is NOT required,
      as this is field counts *record* locks, so a page shard is latched instead)
      Reads should be performed when holding exclusive lock_sys latch, however:
      - Some places assert this field is zero without holding any latch.
      - Some places assert this field is positive holding only shared latch. */
      std::atomic<size_t> n_rec_locks;

    #ifndef UNIV_DEBUG
     private:
    #endif
      /** Count of how many handles are opened to this table. Dropping of the
      table is NOT allowed until this count gets to zero. MySQL does NOT
      itself check the number of open handles at DROP. */
      std::atomic<uint64_t> n_ref_count;

     public:
    #ifndef UNIV_HOTBACKUP
      /** List of locks on the table. Protected by lock_sys shard latch. */
      table_lock_list_t locks;
      /** count_by_mode[M] = number of locks in this->locks with
      lock->type_mode&LOCK_MODE_MASK == M.
      Used to quickly verify that there are no LOCK_S or LOCK_X, which are the only
      modes incompatible with LOCK_IS and LOCK_IX, to avoid costly iteration over
      this->locks when adding LOCK_IS or LOCK_IX.
      We use count_by_mode[LOCK_AUTO_INC] to track the number of granted and pending
      autoinc locks on this table. This value is set after acquiring the lock_sys
      table shard latch, but we peek the contents to determine whether other
      transactions have acquired the AUTOINC lock or not. Of course only one
      transaction can be granted the lock but there can be multiple
      waiters.
      Protected by lock_sys table shard latch. */
      ulong count_by_mode[LOCK_NUM];
    #endif /* !UNIV_HOTBACKUP */

      /** Timestamp of the last modification of this table. */
      time_t update_time;

      /** row-id counter for use by intrinsic table for getting row-id.
      Given intrinsic table semantics, row-id can be locally maintained
      instead of getting it from central generator which involves mutex
      locking. */
      ib_uint64_t sess_row_id;

      /** trx_id counter for use by intrinsic table for getting trx-id.
      Intrinsic table are not shared so don't need a central trx-id
      but just need a increased counter to track consistent view while
      proceeding SELECT as part of UPDATE. */
      ib_uint64_t sess_trx_id;

    #ifdef UNIV_DEBUG
    /** Value of 'magic_n'. */
    #define DICT_TABLE_MAGIC_N 76333786

      /** Magic number. */
      ulint magic_n;
    #endif /* UNIV_DEBUG */
      /** mysql_row_templ_t for base columns used for compute the virtual
      columns */
      dict_vcol_templ_t *vc_templ;

      /** encryption key, it's only for export/import */
      byte *encryption_key;

      /** encryption iv, it's only for export/import */
      byte *encryption_iv;

      /** remove the dict_table_t from cache after DDL operation */
      bool discard_after_ddl;

      /** refresh/reload FK info */
      bool refresh_fk;

    #ifndef UNIV_HOTBACKUP
      /** multiple cursors can be active on this temporary table */
      temp_prebuilt_vec *temp_prebuilt;
    #endif /* !UNIV_HOTBACKUP */

      /** TRUE only for dictionary tables like mysql/tables,
      mysql/columns, mysql/tablespaces, etc. This flag is used
      to do non-locking reads on DD tables. */
      bool is_dd_table;

      /** true if this table is explicitly put to non-LRU list
      during table creation */
      bool explicitly_non_lru;

      /** @return the clustered index */
      const dict_index_t *first_index() const {
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);
        const dict_index_t *first = UT_LIST_GET_FIRST(indexes);
        return (first);
      }
      /** @return the clustered index */
      dict_index_t *first_index() {
        return (const_cast<dict_index_t *>(
            const_cast<const dict_table_t *>(this)->first_index()));
      }

      /** @return if there was any instantly added column.
      This will be true after one or more instant ADD COLUMN, however,
      it would become false after ALTER TABLE which rebuilds or copies
      the old table.
      If this is true, all instantly added columns should have default
      values, and records in the table may have REC_INFO_INSTANT_FLAG set. */
      bool has_instant_cols() const {
        ut_ad(n_instant_cols <= n_cols);

        return (n_instant_cols < n_cols);
      }

      /** Set the number of columns when the first instant ADD COLUMN happens.
      @param[in]	instant_cols	number of fields when first instant
                                      ADD COLUMN happens, without system
                                      columns */
      void set_instant_cols(uint16_t instant_cols) {
        n_instant_cols = static_cast<unsigned>(instant_cols) + get_n_sys_cols();
      }

      /** Get the number of user columns when the first instant ADD COLUMN
      happens.
      @return	the number of user columns as described above */
      uint16_t get_instant_cols() const {
        return static_cast<uint16_t>(n_instant_cols - get_n_sys_cols());
      }

      /** Check whether the table is corrupted.
      @return true if the table is corrupted, otherwise false */
      bool is_corrupted() const {
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);

        const dict_index_t *index = first_index();

        /* It is possible that this table is only half created, in which case
        the clustered index may be NULL.  If the clustered index is corrupted,
        the table is corrupt.  We do not consider the table corrupt if only
        a secondary index is corrupt. */
        ut_ad(index == nullptr || index->is_clustered());

        return (index != nullptr && index->type & DICT_CORRUPT);
      }

      /** Returns a column's name.
      @param[in] col_nr	column number
      @return column name. NOTE: not guaranteed to stay valid if table is
      modified in any way (columns added, etc.). */
      const char *get_col_name(ulint col_nr) const {
        ut_ad(col_nr < n_def);
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);

        const char *s = col_names;
        if (s) {
          for (ulint i = 0; i < col_nr; i++) {
            s += strlen(s) + 1;
          }
        }

        return (s);
      }

      /**Gets the nth column of a table.
      @param[in] pos	position of column
      @return pointer to column object */
      dict_col_t *get_col(ulint pos) const {
        ut_ad(pos < n_def);
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);

        return (cols + pos);
      }

      /** Gets the number of user-defined non-virtual columns in a table
      in the dictionary cache.
      @return number of user-defined (e.g., not ROW_ID) non-virtual columns
      of a table */
      uint16_t get_n_user_cols() const {
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);

        return (static_cast<uint16_t>(n_cols) - get_n_sys_cols());
      }

      /** Gets the number of system columns in a table.
      For intrinsic table on ROW_ID column is added for all other
      tables TRX_ID and ROLL_PTR are all also appeneded.
      @return number of system (e.g., ROW_ID) columns of a table */
      uint16_t get_n_sys_cols() const {
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);

        return (is_intrinsic() ? DATA_ITT_N_SYS_COLS : DATA_N_SYS_COLS);
      }

      /** Gets the number of all non-virtual columns (also system) in a table
      in the dictionary cache.
      @return number of non-virtual columns of a table */
      ulint get_n_cols() const {
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);

        return (n_cols);
      }

      /** Gets the given system column of a table.
      @param[in] sys DATA_ROW_ID, ...
      @return pointer to column object */
      dict_col_t *get_sys_col(ulint sys) const {
        dict_col_t *col;

        ut_ad(sys < get_n_sys_cols());
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);

        col = get_col(n_cols - get_n_sys_cols() + sys);
        ut_ad(col->mtype == DATA_SYS);
        ut_ad(col->prtype == (sys | DATA_NOT_NULL));

        return (col);
      }

      /** Determine if this is a temporary table. */
      bool is_temporary() const {
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);
        return (flags2 & DICT_TF2_TEMPORARY);
      }

      /** Determine if this is a FTS AUX table. */
      bool is_fts_aux() const {
        ut_ad(magic_n == DICT_TABLE_MAGIC_N);
        return (flags2 & DICT_TF2_AUX);
      }

      /** Determine whether the table is intrinsic.
      An intrinsic table is a special kind of temporary table that
      is invisible to the end user. It can be created internally by InnoDB,
      the MySQL server layer or other modules connected to InnoDB in order
      to gather and use data as part of a larger task. Since access to it
      must be as fast as possible, it does not need UNDO semantics, system
      fields DB_TRX_ID & DB_ROLL_PTR, doublewrite, checksum, insert buffer,
      use of the shared data dictionary, locking, or even a transaction.
      In short, these are not ACID tables at all, just temporary data stored
      and manipulated during a larger process.*/
      bool is_intrinsic() const {
        if (flags2 & DICT_TF2_INTRINSIC) {
          ut_ad(is_temporary());
          return (true);
        }

        return (false);
      }

      /* GAP locks are skipped for DD tables and SDI tables
      @return true if table is DD table or SDI table, else false */
      inline bool skip_gap_locks() const;

      /** Determine if the table can support instant ADD COLUMN */
      inline bool support_instant_add() const;
    };
    struct dict_vcol_templ_t {
      /** number of regular columns */
      ulint n_col;

      /** number of virtual columns */
      ulint n_v_col;

      /** array of templates for virtual col and their base columns */
      mysql_row_templ_t **vtempl;

      /** table's database name */
      std::string db_name;

      /** table name */
      std::string tb_name;

      /** share->table_name */
      std::string share_name;

      /** MySQL record length */
      ulint rec_len;

      /** default column value if any */
      byte *default_rec;
    };

```

## 双写缓冲区
Doublewrite Buffer，双写缓冲区，想想也知道，就是写两次。为什么要写两次呢，这不是更浪费空间和时间么？在数据库中，反复提到，数据的安全性和速度是一个要平衡的条件。而双写主要是为了实现安全性。在数据库实际使用的过程中，有可能遇到意外断电、数据库意外崩溃或系统宕机等风险。这时，有可能出现数据写了部分的情况，这样，数据库在重启后如何处理是个很重要的问题。其实双写缓冲区就是解决了数据原子性问题。要么全写到硬盘，要么全写不到。在全写不到的情况下可以去DB缓冲区查找是否有，如果没有，则可以通过Redo Log搞定。

一定要明白，在MySql中，Redo Log可以解决整页数据的找回，但无法解决页内数据不完整的情况，即保持页内数据的原子性或者说完整性。（数据库刷新数据是按照页大小来刷新的，一个页默认大小 是16K，所以刷新的过程无法保证原子性，即可能刷新了一半，掉电，也即无法保证页内数据的完整性）当然，为了提高效率可以通过innodb_doublewrite=0或者1来关闭或者打开此选项。

在MySql8之间其在系统表空间中，但之后，则写入了DobuleWrite的文件中。

双写缓冲区，一定得有一个缓冲的字样：
```
struct Buffer {
  /** Constructor
  @param[in]	n_pages		        Number of pages to create */
  explicit Buffer(size_t n_pages) noexcept
      : m_n_bytes(n_pages * univ_page_size.physical()) {
    ut_a(n_pages > 0);

    auto n_bytes = m_n_bytes + univ_page_size.physical();

    m_ptr_unaligned = static_cast<byte *>(ut_zalloc_nokey(n_bytes));

    m_ptr = static_cast<byte *>(ut_align(m_ptr_unaligned, UNIV_PAGE_SIZE));

    ut_a(ptrdiff_t(m_ptr - m_ptr_unaligned) <=
         (ssize_t)univ_page_size.physical());

    m_next = m_ptr;
  }

  /** Destructor */
  ~Buffer() noexcept {
    if (m_ptr_unaligned != nullptr) {
      ut_free(m_ptr_unaligned);
    }
    m_ptr_unaligned = nullptr;
  }

  /** Add the contents of ptr upto n_bytes to the buffer.
  @return false if it won't fit. Nothing is copied if it won't fit. */
  bool append(const void *ptr, size_t n_bytes) noexcept {
    ut_a(m_next >= m_ptr && m_next <= m_ptr + m_n_bytes);

    if (m_next + univ_page_size.physical() > m_ptr + m_n_bytes) {
      return false;
    }

    memcpy(m_next, ptr, n_bytes);
    m_next += univ_page_size.physical();

    return true;
  }

  /** @return the start of the buffer to write from. */
  byte *begin() noexcept { return m_ptr; }

  /** @return the start of the buffer to write from. */
  const byte *begin() const noexcept { return m_ptr; }

  /** @return the size of of the buffer to write. */
  size_t size() const noexcept {
    ut_a(m_next >= m_ptr);
    return std::ptrdiff_t(m_next - m_ptr);
  }

  /** @return the capacity of the buffer in bytes. */
  size_t capacity() const noexcept { return m_n_bytes; }

  /** @return true if the buffer is empty. */
  bool empty() const noexcept { return size() == 0; }

  /** Empty the buffer. */
  void clear() noexcept { m_next = m_ptr; }

  /** Write buffer used in writing to the doublewrite buffer,
  aligned to an address divisible by UNIV_PAGE_SIZE (which is
  required by Windows AIO) */
  byte *m_ptr{};

  /** Start of  next write to the buffer. */
  byte *m_next{};

  /** Pointer to m_ptr, but unaligned */
  byte *m_ptr_unaligned{};

  /** Size of the unaligned (raw) buffer. * /
  const size_t m_n_bytes{};

  // Disable copying
  Buffer(const Buffer &) = delete;
  Buffer(const Buffer &&) = delete;
  Buffer &operator=(Buffer &&) = delete;
  Buffer &operator=(const Buffer &) = delete;
};

// Forward declaration.
class Segment;
class Batch_segment;

/** Doublewrite implementation. Assumes it can use DBLWR_PAGES. */
class Double_write {
  /** Maximum wait in micro-seconds for new write events. */
  static constexpr auto MAX_WAIT_FOR_EVENTS = 10000000;

 public:
  /** Number of instances. */
  static uint32_t s_n_instances;

  /** For collecting pages to write. */
  struct Buf_pages {
    /** Constructor.
    @param[in] size             Number of pages to reserve. */
    explicit Buf_pages(uint32_t size) : m_pages(size) {
      ut_a(size > 0);
      ut_a(m_pages.capacity() == size);
      ut_a(m_pages.size() == m_pages.capacity());
    }

    /** Add a page to the collection.
    @param[in] bpage     Page to write.
    @param[in] e_block   encrypted block.
    @param[in] e_len     length of data in e_block. */
    void push_back(buf_page_t *bpage, const file::Block *e_block,
                   uint32_t e_len) noexcept {
      ut_a(m_size < m_pages.capacity());
#ifdef UNIV_DEBUG
      {
        byte *e_frame =
            (e_block == nullptr) ? nullptr : os_block_get_frame(e_block);
        if (e_frame != nullptr) {
          ut_ad(mach_read_from_4(e_frame + FIL_PAGE_OFFSET) ==
                bpage->page_no());
          ut_ad(mach_read_from_4(e_frame + FIL_PAGE_SPACE_ID) ==
                bpage->space());
        }
      }
#endif /* UNIV_DEBUG */
      m_pages[m_size++] = std::make_tuple(bpage, e_block, e_len);
    }

    /** Clear the collection. */
    void clear() noexcept { m_size = 0; }

    /** @return check if collection is empty. */
    bool empty() const noexcept { return size() == 0; }

    /** @return number of active elements. */
    uint32_t size() const noexcept { return m_size; }

    /** @return the capacity of the collection. */
    uint32_t capacity() const noexcept MY_ATTRIBUTE((warn_unused_result)) {
      return m_pages.capacity();
    }

    typedef std::tuple<buf_page_t *, const file::Block *, uint32_t> Dblwr_tuple;
    using Pages = std::vector<Dblwr_tuple, ut_allocator<Dblwr_tuple>>;

    /** Collection of pages. */
    Pages m_pages{};

    /** Number of live elements. */
    uint32_t m_size{};
  };

  /** Constructor
  @param[in] id                 Instance ID
  @param[in] n_pages            Number of pages handled by this instance. */
  Double_write(uint16_t id, uint32_t n_pages) noexcept;

  /** Destructor */
  ~Double_write() noexcept;

  /** @return instance ID */
  uint16_t id() const noexcept MY_ATTRIBUTE((warn_unused_result)) {
    return m_id;
  }

  /** Process the requests in the flush queue, write the blocks to the
  double write file, sync the file if required and then write to the
  data files. */
  void write(buf_flush_t flush_type) noexcept;

  /** @return the double write instance to use for flushing.
  @param[in] buf_pool_index     Buffer pool instance number.
  @param[in] flush_type         LRU or Flush list write.
  @return instance that will handle the flush to disk. */
  static Double_write *instance(buf_flush_t flush_type,
                                uint32_t buf_pool_index) noexcept
      MY_ATTRIBUTE((warn_unused_result)) {
    ut_a(buf_pool_index < srv_buf_pool_instances);

    auto midpoint = s_instances->size() / 2;
    auto i = midpoint > 0 ? buf_pool_index % midpoint : 0;

    if (flush_type == BUF_FLUSH_LIST) {
      i += midpoint;
    }

    return s_instances->at(i);
  }

  /** Wait for any pending batch to complete.
  @return true if the thread had to wait for another batch. */
  bool wait_for_pending_batch() noexcept {
    ut_ad(mutex_own(&m_mutex));

    auto sig_count = os_event_reset(m_event);

    std::atomic_thread_fence(std::memory_order_acquire);

    if (m_batch_running.load(std::memory_order_acquire)) {
      mutex_exit(&m_mutex);

      MONITOR_INC(MONITOR_DBLWR_FLUSH_WAIT_EVENTS);
      os_event_wait_low(m_event, sig_count);
      sig_count = os_event_reset(m_event);
      return true;
    }

    return false;
  }

  /** Flush buffered pages to disk, clear the buffers.
  @param[in] flush_type           FLUSH LIST or LRU LIST flush.
  @return false if there was a write batch already in progress. */
  bool flush_to_disk(buf_flush_t flush_type) noexcept {
    ut_ad(mutex_own(&m_mutex));

    /* Wait for any batch writes that are in progress. */
    if (wait_for_pending_batch()) {
      ut_ad(!mutex_own(&m_mutex));
      return false;
    }

    MONITOR_INC(MONITOR_DBLWR_FLUSH_REQUESTS);

    /* Write the pages to disk and free up the buffer. */
    write_pages(flush_type);

    ut_a(m_buffer.empty());
    ut_a(m_buf_pages.empty());

    return true;
  }

  /** Process the requests in the flush queue, write the blocks to the
  double write file, sync the file if required and then write to the
  data files.
  @param[in] flush_type         LRU or FLUSH request. */
  void write_pages(buf_flush_t flush_type) noexcept;

  /** Force a flush of the page queue.
  @param[in] flush_type           FLUSH LIST or LRU LIST flush. */
  void force_flush(buf_flush_t flush_type) noexcept {
    for (;;) {
      mutex_enter(&m_mutex);
      if (!m_buf_pages.empty() && !flush_to_disk(flush_type)) {
        ut_ad(!mutex_own(&m_mutex));
        continue;
      }
      break;
    }
    mutex_exit(&m_mutex);
  }

  /** Add a page to the flush batch. If the flush batch is full then write
  the batch to disk.
  @param[in] flush_type     Flush type.
  @param[in] bpage          Page to flush to disk.
  @param[in] e_block        Encrypted block frame or nullptr.
  @param[in] e_len          Encrypted data length if e_block is valid. */
  void enqueue(buf_flush_t flush_type, buf_page_t *bpage,
               const file::Block *e_block, uint32_t e_len) noexcept {
    ut_ad(buf_page_in_file(bpage));

    void *frame{};
    uint32_t len{};
    byte *e_frame =
        (e_block == nullptr) ? nullptr : os_block_get_frame(e_block);

    if (e_frame != nullptr) {
      frame = e_frame;
      len = e_len;
    } else {
      prepare(bpage, &frame, &len);
    }

    ut_a(len <= univ_page_size.physical());

    for (;;) {
      mutex_enter(&m_mutex);

      if (m_buffer.append(frame, len)) {
        break;
      }

      if (flush_to_disk(flush_type)) {
        auto success = m_buffer.append(frame, len);
        ut_a(success);
        break;
      }

      ut_ad(!mutex_own(&m_mutex));
    }

    m_buf_pages.push_back(bpage, e_block, e_len);

    mutex_exit(&m_mutex);
  }

  /** Note that the IO batch has started. */
  void batch_started() noexcept {
    m_batch_running.store(true, std::memory_order_release);
  }

  /** Wake up all the threads that were waiting for the batch to complete. */
  void batch_completed() noexcept {
    m_batch_running.store(false, std::memory_order_release);
    std::atomic_thread_fence(std::memory_order_release);
    os_event_set(m_event);
  }

  /** Create the batch write segments.
  @param[in] segments_per_file  Number of configured segments per file.
  @return DB_SUCCESS or error code. */
  static dberr_t create_batch_segments(uint32_t segments_per_file) noexcept
      MY_ATTRIBUTE((warn_unused_result));

  /** Create the single page flush segments.
  @param[in] segments_per_file  Number of configured segments per file.
  @return DB_SUCCESS or error code. */
  static dberr_t create_single_segments(uint32_t segments_per_file) noexcept
      MY_ATTRIBUTE((warn_unused_result));

  /** Get the instance that handles a particular page's IO. Submit the
  write request to the a double write queue that is empty.
  @param[in]  flush_type        Flush type.
  @param[in]	bpage             Page from the buffer pool.
  @param[in]  e_block    compressed + encrypted frame contents or nullptr.
  @param[in]  e_len      encrypted data length. */
  static void submit(buf_flush_t flush_type, buf_page_t *bpage,
                     const file::Block *e_block, uint32_t e_len) noexcept {
    if (s_instances == nullptr) {
      return;
    }

    auto dblwr = instance(flush_type, bpage);
    dblwr->enqueue(flush_type, bpage, e_block, e_len);
  }

  /** Writes a single page to the doublewrite buffer on disk, syncs it,
  then writes the page to the datafile.
  @param[in]	bpage             Data page to write to disk.
  @param[in]	e_block           Encrypted data block.
  @param[in]	e_len             Encrypted data length.
  @return DB_SUCCESS or error code */
  static dberr_t sync_page_flush(buf_page_t *bpage, file::Block *e_block,
                                 uint32_t e_len) noexcept
      MY_ATTRIBUTE((warn_unused_result));

  // clang-format off
  /** @return the double write instance to use for flushing.
  @param[in] flush_type         LRU or Flush list write.
  @param[in] bpage              Page to write to disk.
  @return instance that will handle the flush to disk. */
  static Double_write *instance(buf_flush_t flush_type, const buf_page_t *bpage)
      noexcept MY_ATTRIBUTE((warn_unused_result)) {
    return instance(flush_type, buf_pool_index(buf_pool_from_bpage(bpage)));
  }

  /** Updates the double write buffer when a write request is completed.
  @param[in,out] bpage          Block that has just been written to disk.
  @param[in] flush_type         Flush type that triggered the write. */
  static void write_complete(buf_page_t *bpage, buf_flush_t flush_type)
      noexcept;

  /** REad the V1 doublewrite buffer extents boundaries.
  @param[in,out] block1         Starting block number for the first extent.
  @param[in,out] block2         Starting block number for the second extent.
  @return true if successful, false if not. */
  static bool init_v1(page_no_t &block1, page_no_t &block2) noexcept
      MY_ATTRIBUTE((warn_unused_result));

  /** Creates the V1 doublewrite buffer extents. The header of the
  doublewrite buffer is placed on the trx system header page.
  @param[in,out] block1         Starting block number for the first extent.
  @param[in,out] block2         Starting block number for the second extent.
  @return true if successful, false if not. */
  static bool create_v1(page_no_t &block1, page_no_t &block2) noexcept
      MY_ATTRIBUTE((warn_unused_result));

  /** Writes a page that has already been written to the
  doublewrite buffer to the data file. It is the job of the
  caller to sync the datafile.
  @param[in]  in_bpage          Page to write.
  @param[in]  sync              true if it's a synchronous write.
  @param[in]  e_block           block containing encrypted data frame.
  @param[in]  e_len             encrypted data length.
  @return DB_SUCCESS or error code */
  static dberr_t write_to_datafile(const buf_page_t *in_bpage, bool sync,
      const file::Block* e_block, uint32_t e_len)
      noexcept MY_ATTRIBUTE((warn_unused_result));

  /** Force a flush of the page queue.
  @param[in] flush_type           FLUSH LIST or LRU LIST flush.
  @param[in] buf_pool_index       Buffer pool instance for which called. */
  static void force_flush(buf_flush_t flush_type, uint32_t buf_pool_index)
      noexcept {
    if (s_instances == nullptr) {
      return;
    }
    auto dblwr = instance(flush_type, buf_pool_index);

    dblwr->force_flush(flush_type);
  }

  /** Load the doublewrite buffer pages from an external file.
  @param[in,out]	file		      File handle
  @param[in,out]	pages		      For storing the doublewrite pages
                                read from the file
  @return DB_SUCCESS or error code */
  static dberr_t load(dblwr::File &file, recv::Pages *pages) noexcept
      MY_ATTRIBUTE((warn_unused_result));

  /** Write zeros to the file if it is "empty"
  @param[in]	file		          File instance.
  @param[in]	n_pages           Size in physical pages.
  @return DB_SUCCESS or error code */
  static dberr_t init_file(dblwr::File &file, uint32_t n_pages) noexcept
      MY_ATTRIBUTE((warn_unused_result));

  /** Reset the size in bytes to the configured size.
  @param[in,out] file						File to reset.
  @param[in] truncate           Truncate the file to configured size if true. */
  static void reset_file(dblwr::File &file, bool truncate) noexcept;

  /** Reset the size in bytes to the configured size of all files. */
  static void reset_files() noexcept {
    for (auto &file : Double_write::s_files) {
      /* Physically truncate the file: true. */
      Double_write::reset_file(file, true);
    }
  }

  /** Create the v2 data structures
  @return DB_SUCCESS or error code */
  static dberr_t create_v2() noexcept MY_ATTRIBUTE((warn_unused_result));

#ifndef _WIN32
  /** @return true if we need to fsync to disk */
  static bool is_fsync_required() noexcept MY_ATTRIBUTE((warn_unused_result)) {
    /* srv_unix_file_flush_method is a dynamic variable. */
    return srv_unix_file_flush_method != SRV_UNIX_O_DIRECT &&
           srv_unix_file_flush_method != SRV_UNIX_O_DIRECT_NO_FSYNC;
  }
#endif /* _WIN32 */

  /** Extract the data and length to write to the doublewrite file
  @param[in]	bpage		          Page to write
  @param[out]	ptr		            Start of buffer to write
  @param[out]	len		            Length of the data to write */
  static void prepare(const buf_page_t *bpage, void **ptr, uint32_t *len)
      noexcept;

  /** Free the data structures. */
  static void shutdown() noexcept;

  /** Toggle the doublewrite buffer dynamically
  @param[in]	value		          Current value */
  static void toggle(bool value) noexcept {
    if (s_instances == nullptr) {
      return;
    }

    if (value) {
      ib::info(ER_IB_MSG_DBLWR_1304) << "Atomic write enabled";
    } else {
      ib::info(ER_IB_MSG_DBLWR_1305) << "Atomic write disabled";
    }
  }

  // clang-format on

  /** Write the data to disk synchronously.
  @param[in]    segment      Segment to write to.
  @param[in]	bpage        Page to write.
  @param[in]    e_block      Encrypted block.  Can be nullptr.
  @param[in]    e_len        Encrypted data length in e_block. */
  static void single_write(Segment *segment, const buf_page_t *bpage,
                           file::Block *e_block, uint32_t e_len) noexcept;

 private:
  /** Create the singleton instance, start the flush thread
  @return DB_SUCCESS or error code */
  static dberr_t start() noexcept MY_ATTRIBUTE((warn_unused_result));

  /** Asserts when a corrupt block is found during writing out
  data to the disk.
  @param[in]	block		          Block that was corrupt */
  static void croak(const buf_block_t *block) noexcept;

  /** Check the LSN values on the page with which this block
  is associated.  Also validate the page if the option is set.
  @param[in]	block		          Block to check */
  static void check_block(const buf_block_t *block) noexcept;

  /** Check the LSN values on the page.
  @param[in]	page		          Page to check */
  static void check_page_lsn(const page_t *page) noexcept;

  /** Calls buf_page_get() on the TRX_SYS_PAGE and returns
  a pointer to the doublewrite buffer within it.
  @param[in,out]	mtr		        To manage the page latches
  @return pointer to the doublewrite buffer within the filespace
          header page. */
  static byte *get(mtr_t *mtr) noexcept MY_ATTRIBUTE((warn_unused_result));

 private:
  using Segments = mpmc_bq<Segment *>;
  using Instances = std::vector<Double_write *>;
  using Batch_segments = mpmc_bq<Batch_segment *>;

  /** Instance ID */
  uint16_t m_id{};

  /** Protects m_buf_pages. */
  ib_mutex_t m_mutex;

  /** Wait for IO batch to complete. */
  os_event_t m_event;

  /** true if the the batch hasn't completed yet. */
  std::atomic_bool m_batch_running{false};

  /** The copy of the page frame, the page must be in in m_buf_pages. */
  Buffer m_buffer;

  /** Pages that should be written to the data files. */
  Buf_pages m_buf_pages;

  /** File segments to use for LRU batched writes. */
  static Batch_segments *s_LRU_batch_segments;

  /** File segments to use for flush list batched writes. */
  static Batch_segments *s_flush_list_batch_segments;

  /** File segments to use for single page writes. */
  static Segments *s_single_segments;

  /** For indexing batch segments by ID. */
  static std::vector<Batch_segment *> s_segments;

 public:
  /** Files to use for atomic writes. * /
  static std::vector<dblwr::File> s_files;

  /** The global instances */
  static Instances *s_instances;

  // Disable copying
  Double_write(const Double_write &) = delete;
  Double_write(const Double_write &&) = delete;
  Double_write &operator=(Double_write &&) = delete;
  Double_write &operator=(const Double_write &) = delete;
};

/** File segment of a double write file. */
class Segment {
 public:
  /** Constructor.
  @param[in] file               File that owns the segment.
  @param[in] start              Offset (page number) of segment in the file.
  @param[in] n_pages            Number of pages in the segment. */
  Segment(dblwr::File &file, page_no_t start, uint32_t n_pages)
      : m_file(file),
        m_start(start * univ_page_size.physical()),
        m_end(m_start + (n_pages * univ_page_size.physical())) {}

  /** Destructor. */
  virtual ~Segment() {}

  /** Write to the segment.
  @param[in] ptr                Start writing from here.
  @param[in] len                Number of bytes to write. */
  void write(const void *ptr, uint32_t len) noexcept {
    ut_a(len <= m_end - m_start);
    IORequest req(IORequest::WRITE | IORequest::DO_NOT_WAKE);

    req.dblwr();

    auto err = os_file_write_retry(req, m_file.m_name.c_str(), m_file.m_pfs,
                                   ptr, m_start, len);
    ut_a(err == DB_SUCCESS);
  }

  /** Flush the segment to disk. */
  void flush() noexcept { os_file_flush(m_file.m_pfs); }

  /** File that owns the segment. */
  dblwr::File &m_file;

  /** Physical offset in the file for the segment. */
  os_offset_t m_start{};

  /** Physical offset up to which this segment is responsible for. */
  os_offset_t m_end{};

  // Disable copying
  Segment(Segment &&) = delete;
  Segment(const Segment &) = delete;
  Segment &operator=(Segment &&) = delete;
  Segment &operator=(const Segment &) = delete;
};

struct File {
  /** ID of the file. */
  uint32_t m_id{};

  /** File name. */
  std::string m_name{};

  /** File handle. */
  pfs_os_file_t m_pfs{};

  /** Number of batched pages per doublwrite file. */
  static uint32_t s_n_pages;

  /** Serialize the object into JSON format.
  @return the object in JSON format. */
  std::string to_json() const noexcept MY_ATTRIBUTE((warn_unused_result)) {
    std::ostringstream out;
    out << "{";
    out << "\"className\": \"dblwr::File\",";
    out << "\"m_id\": \"" << m_id << "\",";
    out << "\"m_name\": \"" << m_name << "\",";
    out << "\"s_n_pages\": \"" << s_n_pages << "\"";
    out << "}";

    return out.str();
  }

  /** Print this object into the given stream.
  @param[in]  out  output stream into which the current object is printed.
  @return the output stream. */
  std::ostream &print(std::ostream &out) const noexcept {
    out << to_json();
    return out;
  }
};

/** Pages recovered from the doublewrite buffer */
class Pages {
 public:
  using Buffers = std::vector<Page *, ut_allocator<Page *>>;

  /** Default constructor */
  Pages() : m_pages() {}

  /** Destructor */
  ~Pages() noexcept {
    for (auto &page : m_pages) {
      UT_DELETE(page);
    }

    m_pages.clear();
  }

  /** Add a page frame to the doublewrite recovery buffer.
  @param[in]	page_no		        Page number in the doublewrite buffer
  @param[in]	page		          Page contents
  @param[in]	n_bytes		        Size in bytes */
  void add(page_no_t page_no, const byte *page, uint32_t n_bytes) noexcept;

  /** Find a doublewrite copy of a page.
  @param[in]	page_id		        Page number to lookup
  @return	page frame
  @retval nullptr if no page was found */
  const byte *find(const page_id_t &page_id) const noexcept;

  /** Recover double write buffer pages
  @param[in]	space		          Tablespace pages to recover, if set
                                to nullptr then try and recovery all. */
  void recover(fil_space_t *space) noexcept;

  /** Check if some pages could be restored because of missing
  tablespace IDs */
  void check_missing_tablespaces() const noexcept;

  /** Object the vector of pages.
  @return the vector of pages. */
  Buffers &get_pages() noexcept MY_ATTRIBUTE((warn_unused_result)) {
    return m_pages;
  }

 private:
  /** Recovered doublewrite buffer page frames */
  Buffers m_pages;

  // Disable copying
  Pages(const Pages &) = delete;
  Pages(const Pages &&) = delete;
  Pages &operator=(Pages &&) = delete;
  Pages &operator=(const Pages &) = delete;
};


```

## 日志

### 重做日志
此日志是InnoDB自己的日志，就是对数据库表数据的请求进行编码记录，它会随着事务操作进行产生，然后等待脏数据Flush到磁盘后，Redo Log的空间就可以重复使用。其主要的作用就是用于修复不完整事务引起的数据的不完整。Redo Log的持久化特事特办可以通过Innodb_flush_log_at_trx_commit来设置。其有三个值：
0：最佳性能，每隔一秒刷入FSP，MySql主动Fsync，有可能丢失1秒的数据。
1：强一致性，默认，即来即刷。MySql主动Fsync性能较差
2：中间，即来即刷，但MySql隔一秒主动刷盘。但它最多也会丢失一秒的数据。

### Binlog日志
MySql Server的二进制日志，主要是记录数据库表结构变更及数据修改的二进制日志。它不会会记录查找和显示这类操作，它以事件方式记录，主要应用于主从复制和数据恢复。

### 回滚日志
回滚日志就是为了保持事务性。它是在事务之间保存的的修改数据的备份，当出现意外时，可以将数据安全恢复到原样。它在事务开始时前生产，在事务提交后将其扔到删除列表中，由后强线程进行回收。其采用段的方式来管理记录数据。其重要作用有两点，一是实现事务的原子性，另外可以实现MVCC，即多版本并发控制。

































