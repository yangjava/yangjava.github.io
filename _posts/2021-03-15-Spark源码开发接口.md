---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# Spark源码开发接口

## Spark API
Spark早期版本只提供了基于SparkContext的API。现在Spark又增加了SparkSession和DataFrame相关的API，熟练使用它们，可以使大数据的开发工作变得更加简单。

Spark的word count例子，也是为了能够把之前的内容串联起来。Spark的任务运行在存储体系、调度系统及计算引擎之上。Spark Application、Application的配置信息、Application依赖的Jar包、map任务的输出缓存、reduce任务的缓存等都基于存储体系；程序转换为RDD构成的DAG后，RDD的阶段划分、提交Task、资源申请等都离不开调度系统；Task在执行时对数据的缓存、聚合、Shuffle管理等都由计算引擎支撑。

## 基本概念
基本概念，包括数据类型（DataType）、结构类型（StructType）、结构字段（StructField）及元数据（Metadata）。

### DataType简介
DataType是Spark SQL的所有数据类型的基本类型，Spark SQL的所有数据类型都继承自DataType。Spark SQL中定义的数据类型与Java的基本数据类型大部分都是一致的。

### Metadata简介
Metadata用来保存StructField的元数据信息，其本质是底层的`Map[String，Any]`。Meta-data可以对Boolean、Long、Double、String、Metadata、Array[Boolean]、Array[Long]、Array[Double]、Array[String]和Array[Metadata]等类型的元数据进行存储或读取。Metadata属于Spark SQL中的内容。

### StructType与StructField
StructField中共定义了4个属性：字段名称（name）、数据类型（dataType）、是否允许为null（nullable）、元数据（metadata）。

StructField的定义如下。
```
case class StructField(
  name: String,
  dataType: DataType,
  nullable: Boolean = true,
  metadata: Metadata = Metadata.empty)
```
StructType的属性中最为重要的是类型为Array[StructField]的fields，由此可以看出一个StructType中可以包括零到多个StructField。为了便于理解，下面定义了一个简单的StructType。
```
val struct =
   StructType(
     StructField("a", IntegerType, true) ::
     StructField("b", LongType, false) ::
     StructField("c", BooleanType, false) :: Nil)
```
对于构建的struct，可以用以下语句获取名称为b的StructField。
```
val singleField = struct("b")
```
如果要获取struct中不存在的StructField，就像下面这样。
```
val nonExisting = struct("d")
```
























