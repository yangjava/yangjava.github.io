---
layout: post
categories: Kubernetes
description: none
keywords: Kubernetes
---
# Kubernetes深入Service
Service是Kubernetes的核心概念，通过创建Service，可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。

## Service定义详解
YAML格式的Service定义文件的完整内容如下：
```
apiVersion: v1			// Required
kind: Service			// Required
metadata:
	name: string		// Required
	namespace: string	// Required
	labels:
		- name: string
	annotations:
		- name: string
spec:					// Required
	selector: []		// Required
	type: string		// Required
	clusterIP: string
	sessionAffinity: string
	ports:
		- name: string
		  protocol: string
		  port: int
		  targetPort: int
		  nodePort: int
    status:
    	loadBalancer:
    		ingress:
    			ip: string
    			hostname: string
```
下表对Service的定义文件模板的各属性的说明：
- apiVersion	string	Required	v1
kind	string	Required	Service
metadata	object	Required	元数据
metadata.name	string	Required	Service名称，需符合RFC1035规范
metadata.namespace	string	Required	命名空间，不指定系统时将使用名为default的命名空间
metadata.labels[]	list	-	自定义标签属性列表
metadata.annotations[]	list	-	自定义注解属性列表
spec	object	Required	详细描述
spec.selector[]	list	Required	Label Selector配置，将选择具有指定Label标签的Pod作为管理范围
spec.type	string	Required	Service的类型，指定Service的访问方式，默认值为ClusterIP。
1. ClusterIP：虚拟的服务IP地址，该地址用于Kubernetes集群内部的Pod访问，在Node上kube-proxy通过设置的iptables规则进行转发。
2. NodePort：使用宿主机的端口，使能够访问各Node的外部客户端通过Node的IP地址和端口号就能访问服务。
3. LoadBalancer：使用外接负载均衡器完成到服务的负载分发，需要在spec.status.loadBalancer字段指定外部负载均衡器的IP地址，并同时定义nodePort和clusterIP，用于公有云环境。
   spec.clusterIP	string	-	虚拟服务IP地址，当type=ClusterIP时，如果不指定，则系统进行自动分配，也可以手工指定；当type=LoadBalancer时，则需要指定
   spec.sessionAffinity	string	-	是否支持Session，可选值为ClusterIP,默认值为空。
   ClientIP：表示将同一个客户端的访问请求都转发到同一个后端Pod
   spec.ports[]	list	-	Service 需要暴露的端口列表
   spec.ports[].name	string	-	端口名称
   spec.ports[].protocol	string	-	端口协议，支持TCP和UDP，默认值为TCP
   spec.ports[].port	int	-	服务监听的端口号
   spec.ports[].targetPort	int	-	需要转发到后端 Pod 的端口号
   spec.ports[].nodePort	int	-	当spec.type=NodePort时，需要指定映射到物理机的端口号
   Status	object	-	当spec.type=LoadBalancer时，设置外部服负载均衡器的地址，用于公有云环境
   staus.loadBalancer	object	-	外部负载均衡器
   status.loadBalancer.ingress	object	-	外部负载均衡器
   status.loadBalancer.ingress.ip	string	-	外部负载均衡器
   status.loadBalancer.ingress.hostname	string	-	外部负载均衡器

## Service的基本用法
一般来说，对外提供服务的应用程序需要通过某种机制来实现，对于容器应用最简便的方式就是通过TCP/IP机制及监听IP和端口号来实现。例如，定义一个提供Web服务的RC，由两个Tomcat容器副本组成，每个容器都通过containerPort设置提供服务的端口号为8080：
```yaml
# cat > webapp-rc.yaml 
apiVersion: v1
kind: ReplicationController
metadata:
	name: webapp
spec:
	replicas: 2
	template:
		metadata:
			name: webapp
			labels:
				app: webapp
		spec:
			containers:
				- name: webapp
				  image: tomcat
				  ports:
				  	- containerPort: 8080
```
创建该RC：
```
# kubectl create -f webapp-rc.yaml
```
获取 Pod 的 IP 地址：
```
# kubectl get pods -l app=webapp -o yaml | grep podIP
```
那么就可以直接通过这两个Pod的IP地址和端口号访问Tomcat服务。

直接通过Pod的IP地址和端口号可以访问到容器应用内的服务，但是Pod的IP地址是不可靠的，例如当Pod所在的Node发生故障时，Pod将被Kubernetes重新调度到另一个Node，Pod的IP地址将发生变化。更重要的是，如果容器应用本身是分布式的部署方式，通过多个实例共同提供服务，就需要在这些实例的前端设置一个负载均衡器来实现请求的分发。Kubernetes中的Service就是用于解决这些问题的核心组件。

### 通过kubectl expose命令来创建Service
以前面创建的webapp应用为例，为了让客户端应用访问到两个Tomcat Pod实例，需要创建一个Service来提供服务。Kubernetes提供了一种快速的方法，即通过kubectl expose命令来创建Service：
```
# kubectl expose rc webapp
service "webapp" exposed

# kubectl get svc
```
接下来就可以通过Service的IP地址和Service的端口号访问该Service了。

### 通过配置文件定义Service
除了使用kubectl expose命令创建Service，我们也可以通过配置文件定义Service，再通过kubectl create命令进行创建。例如对于前面的webapp应用，我们可以设置一个Service，代码如下：
```
apiVersion:v1
kind: Service
metadata:
    name: webapp
spec:
    ports:
        - port: 8081
          targetPort: 8080
    selector:
        app: webapp
```
Service定义中的关键字段是ports和selector。本例中ports定义部分指定了Service所需的虚拟端口号为8081，由于与Pod容器端口号8080不一样，所以需要再通过targetPort来指定后端Pod的端口号。selector定义部分设置的是后端Pod所拥有的label：app=webapp。

创建该Service并查看其ClusterIP地址。通过Service的IP地址和Service的端口号进行访问。

目前 Kubernetes 提供了两种负载分发策略：RoundRobin和SessionAffinity，具体说明如下：
- RoundRobin
轮询模式，即轮询将请求转发到后端的各个Pod上。 默认策略
- SessionAffinity
基于客户端IP地址进行会话保持的模式，相同的客户端发起的请求都将被转发到后端相同的Pod上。

在默认情况下，Kubernetes采用RoundRobin模式对客户端请求进行负载分发，但我们也可以通过设置service.spec.sessionAffinity=ClientIP来启用SessionAffinity策略。这样，同一个客户端IP发来的请求就会被转发到后端固定的某个Pod上了。

通过Service的定义，Kubernetes实现了一种分布式应用统一入口的定义和负载均衡机制。Service还可以进行其他类型的设置，例如设置多个端口号、直接设置为集群外部服务，或实现为Headless Service（无头服务）模式。

## 多端口Service
有时一个容器应用也可能提供多个端口的服务，那么在Service的定义中也可以相应地设置为将多个端口对应到多个应用服务。在下面的例子中，Service设置了两个端口号，并且为每个端口号都进行了命名：
```yaml
    ports:
        - port: 8081
          targetPort: 8080
          name: web
        - port: 8005
          targetPort: 8005
          name: management
```

## 外部服务Service

## Ingress：HTTP 7层路由机制
根据前面对Service的使用说明，我们知道Service的表现形式为IP:Port，即工作在TCP/IP层。而对于基于HTTP的服务来说，不同的URL地址经常对应到不同的后端服务或者虚拟服务器（Virtual Host），这些应用层的转发机制仅通过Kubernetes的Service机制是无法实现的。从Kubernetes 1.1版本开始新增Ingress资源对象，用于将不同URL的访问请求转发到后端不同的Service，以实现HTTP层的业务路由机制。Kubernetes使用了一个Ingress策略定义和一个具体的Ingress Controller，两者结合并实现了一个完整的Ingress负载均衡器。

使用Ingress进行负载分发时，Ingress Controller基于Ingress规则将客户端请求直接转发到Service对应的后端Endpoint（Pod）上，这样会跳过kube-proxy的转发功能，kube-proxy不再起作用。如果Ingress Controller提供的是对外服务，则实际上实现的是边缘路由器的功能。

一个典型的HTTP层路由的例子。
- 对http://mywebsite.com/api的访问将被路由到后端名为api的Service；
- 对http://mywebsite.com/web的访问将被路由到后端名为web的Service；
- 对http://mywebsite.com/docs的访问将被路由到后端名为docs的Service。

为使用Ingress，需要创建Ingress Controller（带一个默认backend服务）和Ingress策略设置来共同完成。下面通过一个例子分三步说明Ingress Controller和Ingress策略的配置方法，以及客户端如何访问Ingress提供的服务。

### 创建Ingress Controller和默认的backend服务
在定义Ingress策略之前，需要先部署Ingress Controller，以实现为所有后端Service都提供一个统一的入口。Ingress Controller需要实现基于不同HTTP URL向后转发的负载分发规则，并可以灵活设置7层负载分发策略。如果公有云服务商能够提供该类型的HTTP路由LoadBalancer，则也可设置其为Ingress Controller。

在Kubernetes中，Ingress Controller将以Pod的形式运行，监控API Server的/ingress接口后端的backend services，如果Service发生变化，则Ingress Controller应自动更新其转发规则。

下面的例子使用Nginx来实现一个Ingress Controller，需要实现的基本逻辑如下。
- 监听API Server，获取全部Ingress的定义。
- 基于Ingress的定义，生成Nginx所需的配置文件/etc/nginx/nginx.conf。
- 执行nginx -s reload命令，重新加载nginx.conf配置文件的内容。

这里使用谷歌提供的nginx-ingress-controller镜像来创建Ingress Controller。 该Ingress Controller以 DaemonSet 的形式进行创建，在每个 Node 上都将启动一个 Nginx 服务。

这里为Nginx容器设置了hostPort，将容器应用监听的80和443端口号映射到物理机上，使得客户端应用可以通过URL地址“http://物理机IP:80”或“https://物理机IP:443”来访问该Ingress Controller。这使得Nginx类似于通过NodePort映射到物理机的Service，成为代替kube-proxy的HTTP层的Load Balancer。
















