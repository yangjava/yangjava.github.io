---
layout: post
categories: [Hadoop]
description: none
keywords: Hadoop
---
# Hadoop源码任务提交

## hadoop提交流程源码
```
//进入Job类的waitForCompletion()方法
waitForCompletion()

submit();

// 1建立连接
	connect();	
		// 1）创建提交Job的代理
		new Cluster(getConfiguration());
			// （1）判断是本地运行环境还是yarn集群运行环境
			initialize(jobTrackAddr, conf); 

// 2 提交job
submitter.submitJobInternal(Job.this, cluster)

	// 1）创建给集群提交数据的Stag路径
	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);

	// 2）获取jobid ，并创建Job路径
	JobID jobId = submitClient.getNewJobID();

	// 3）拷贝jar包到集群
copyAndConfigureFiles(job, submitJobDir);	
	rUploader.uploadFiles(job, jobSubmitDir);

	// 4）计算切片，生成切片规划文件
writeSplits(job, submitJobDir);
		maps = writeNewSplits(job, jobSubmitDir);
		input.getSplits(job);

	// 5）向Stag路径写XML配置文件
writeConf(conf, submitJobFile);
	conf.writeXml(out);

	// 6）提交Job,返回提交状态
status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());

```

## 提交任务过程中主要事项
在connect方法中，主要通过cluster对象提供一种进入访问mr集群的方式。进入Cluster中，再进入initialize(jobTrackAddr,conf)中包含initProviderList()；ProviderList中有YarnClient和LocalClient；通过for循环遍历initProviderList()，并验证参数。

通过参数mapreduce.framework.name来决定是由什么环境运行
如果值为yarn 那就是yarn环境
如果值为local 那就是local环境

通过当前环境去获取提交器，

验证输出路径是否存在；

提供一个staging临时目录；产生jobID；准备创建staging临时目录+jobID路径

在staging临时目录+jobID的临时目录中上传Job.xml配置文件、切片信息、（jar包–yarn模式）

集群模式：提交jar包

本地模式：不提交jar包

在客户端，我们进行Job相关属性设定后，最后使用job.waitForCompletion(true);提交任务到集群中，并等待集群作业完成
public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
Configuration conf = new Configuration();
Job job = Job.getInstance(conf);

            job.setJarByClass(DataCount.class);
            job.setMapperClass(DCMapper.class);
            // k2 v2 and k3 v3
            // job.setMapOutputKeyClass(Text.class);
            // job.setMapOutputValueClass(DataBean.class);
            FileInputFormat.setInputPaths(job, new Path(args[0]));
            
            job.setReducerClass(DCReducer.class);
            job.setOutputKeyClass(Text.class);
            job.setOutputValueClass(DataBean.class);
            FileOutputFormat.setOutputPath(job, new Path(args[1]));
            job.waitForCompletion(true);
      }
2.核心是job.waitForCompletion(true);过程分析，下面我们重点分析此过程。
1）此过程检查Job状态后，状态OK则提交作业submit()
2）提交作业先，需要建立连接connect(),此连接过程会创建Cluster对象，并生成cluster的引用
3）Job类持有Cluster的引用，而Cluster持用ResourceManager进程的引用，Cluster也持有RPC代理对象client
说明：客户端持有服务端的引用，这样就可以建立RPC通信
4）Cluster的构造方法 initialize(jobTrackAddr, conf);会创建如下对象 ClientProtocol clientProtocol，而这一个对象就是一个接口，最后再将这一个代理对象赋值给 client = clientProtocol;  而client 就是Cluster的成员变量
5）上述就是Job建立连接的过程，完成连接后需要得到一个提交器，Job创建一个提交器JobSubmitter submitter
6）通过提交器将Job，cluster传入submitter.submitJobInternal(Job.this, cluster);
7）submitter 检查输出目录是否有异常，接着得到一个存储Jar包路径jobStagingArea ，再得到一个JobID，JobID是通过submitter里的RPC引用得到，实际JobID是在服务端实现
8）submitter提交器将提交jar地址是通过jobStagingArea和JobID拼接而成
9）submitter提交器copyAndConfigureFiles接口将Jar包和配置信息提交到hdfs里，默认向hdfs写10份（也可以通过配置mapreduce.client.submit.file.replication，当然提交的份数也可以通过读取配置文件获得mapreduce.client.submit.file.replication（mapred-default.xml 682行））
10）submitter提交器通过copyAndConfigureFiles拷贝Jar信息到hdfs
11）submitter提交器通过服务端代理对象submitClient.submitJob提交Job信息，服务端最终将信息提交给ResourceManager


## 流程源码
Mapper和Reducer暂时略过，看Driver提交Job(waitForCompletion)
```
public class WordCountDriver {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        //获取job对象,设置jar存放路径,关联Map和Reduce类,设置mapper阶段输出数据类型,设置最终数据输出的数据类型,设置输入路径和输出路径
        ...
        //提交job
        boolean result =  job.waitForCompletion(true);
        System.out.println(result ? 0 : 1);
    }
}
```
waitForCompletion如下
```
 public boolean waitForCompletion(boolean verbose
                                   ) throws IOException, InterruptedException,
                                            ClassNotFoundException {
    if (state == JobState.DEFINE) {  //判断JobState，也就是常见的RUNNING，ACCEPT，KILLED等等
      submit(); //然后提交
    }
    if (verbose) {
      monitorAndPrintJob();
    } else {
      // get the completion poll interval from the client.
      int completionPollIntervalMillis = 
        Job.getCompletionPollInterval(cluster.getConf());
      while (!isComplete()) {
        try {
          Thread.sleep(completionPollIntervalMillis);
        } catch (InterruptedException ie) {
        }
      }
    }
    return isSuccessful();
  }
```
进入submit之后如下：
```
  public void submit() 
         throws IOException, InterruptedException, ClassNotFoundException {
    ensureState(JobState.DEFINE);  //判断任务状态，若状态错误则抛出异常
    setUseNewAPI();   //这个是由于很多API过时了，需要用新的API来代替，主要是提高兼容性的作用
    connect();   //重点，下面讲
    final JobSubmitter submitter = 
        getJobSubmitter(cluster.getFileSystem(), cluster.getClient());
    status = ugi.doAs(new PrivilegedExceptionAction<JobStatus>() {
      public JobStatus run() throws IOException, InterruptedException, 
      ClassNotFoundException {
        return submitter.submitJobInternal(Job.this, cluster);
      }
    });
    state = JobState.RUNNING;
    LOG.info("The url to track the job: " + getTrackingURL());
   }
```
connect()
```
 private synchronized void connect()
          throws IOException, InterruptedException, ClassNotFoundException {
    if (cluster == null) {    //判断cluster是否为空，若为空，则往下，因为本地提交
      cluster = 
        ugi.doAs(new PrivilegedExceptionAction<Cluster>() {
                   public Cluster run()
                          throws IOException, InterruptedException, 
                                 ClassNotFoundException {
                     return new Cluster(getConfiguration());
                   }
                 });
    }
  }


这里看源码的话比较晦涩，doAs进去之后建议直接StepOut，直接return new Cluster(getConfiguration())，这样对于流程的理解会好一些，否则doAs里面的步骤太多，容易走丢
```
Cluster(getConfiguration())返回cluster集群信息
```
  public Cluster(InetSocketAddress jobTrackAddr, Configuration conf) 
      throws IOException {
    this.conf = conf;
    this.ugi = UserGroupInformation.getCurrentUser();
    initialize(jobTrackAddr, conf);    //在这里，初始化了集群的信息，包括配置文件，
  }

这里面的conf，返回的就是各种${HADOOP_HOME}/etc/hadoop里面的配置文件，最后是以XML的集合形式存放
```
initialize(jobTrackAddr, conf)执行初始化集群配置相关信息
```
private void initialize(InetSocketAddress jobTrackAddr, Configuration conf)
      throws IOException {

    initProviderList();
    .......  //这里开始其实就是初始化之后的一系列动作，包括判断初始化是否成功，初始化JobTracker等等相关的返回信息，有兴趣可以去Hadoop-3.1.2源码里面查看Cluster.java的116~150行
　}
```
紧接着initProviderList()里面，开始初始化各种信息
```
  private void initProviderList() {
    if (providerList == null) {
      synchronized (frameworkLoader) {
        if (providerList == null) {   //如果用户提交没有配置信息，则下面开始初始化LocalProviderList，
　　　　　　　　　　　　　　　　　　　　　　 //这也就是如果本地测试运行时，clientProtocol为什么会返回org.apache.hadoop.LocalJobRunner@XXX的原因
          List<ClientProtocolProvider> localProviderList =
              new ArrayList<ClientProtocolProvider>();
          try {
            for (ClientProtocolProvider provider : frameworkLoader) {
              localProviderList.add(provider);
            }
          } catch(ServiceConfigurationError e) {
            LOG.info("Failed to instantiate ClientProtocolProvider, please "
                         + "check the /META-INF/services/org.apache."
                         + "hadoop.mapreduce.protocol.ClientProtocolProvider "
                         + "files on the classpath", e);
          }
          providerList = localProviderList;
        }
      }
    }  //当然，若providerList有东西，说明是提交到集群上，并且拿到了相关配置信息，就直接退出这个方法了
  }
```
走出上面这里，就返回doAs里面了，里面已经拿到了集群的信息了，然后走出connect()，往下走，final阶段提交之前会获取一些job提交者(submitter)的相关信息，然后设置state = JobState.RUNNING;  在这之后任务就开始运行了，任务运行过程中还有很多监控和任务信息的实时获取，比如循环获取map和reduce的任务进度，提交者信息获取等等很多信息，后面有机会在挖一下，提交的流程就在这里了，有兴趣的可以自己更详细的看一下 