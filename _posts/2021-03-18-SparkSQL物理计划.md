---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# SparkSQL物理计划
物理计划阶段是Spark SQL整个查询处理流程的最后一步。不同于逻辑计划（LogicalPlan）的平台无关性，物理计划（PhysicalPlan）是与底层平台紧密相关的。在此阶段，Spark SQL会对生成的逻辑算子树进行进一步处理，得到物理算子树，并将LogicalPlan节点及其所包含的各种信息映射成Spark Core计算模型的元素，如RDD、Transformation和Action等，以支持其提交执行。

## Spark SQL物理计划概述
在Spark SQL中，物理计划用SparkPlan表示，从Optimized LogicalPlan传入到Spark SQL物理计划提交并执行，主要经过3个阶段。这3个阶段分别产生Iterator[PhysicalPlan]、SparkPlan和Prepared SparkPlan，其中Prepared SparkPlan可以直接提交并执行（注：这里的“PhysicalPlan”和“SparkPlan”均表示物理计划）。

具体来讲，这3个阶段所做的工作分别如下。
- 由SparkPlanner将各种物理计划策略（Strategy）作用于对应的LogicalPlan节点上，生成SparkPlan列表（注：一个LogicalPlan可能产生多种SparkPlan）。
- 选取最佳的SparkPlan，在Spark 2.1版本中的实现较为简单，在候选列表中直接用next()方法获取第一个。
- 提交前进行准备工作，进行一些分区排序方面的处理，确保SparkPlan各节点能够正确执行，这一步通过prepareForExecution()方法调用若干规则（Rule）进行转换。

对SparkPlan所涉及的内容进行全面介绍，包括SparkPlan的分类和各种体系的概述；接下来，会重点分析Metadata与Metric体系，以及Partitioning与Ordering体系；详细分析SparkPlanner生成SparkPlan的过程与策略；最后，选取若干规则阐述执行前准备的相关处理工作。

## SparkPlan简介
Spark SQL最终将SQL语句经过逻辑算子树转换成物理算子树。在物理算子树中，叶子类型的SparkPlan节点负责“从无到有”地创建RDD，每个非叶子类型的SparkPlan节点等价于在RDD上进行一次Transformation，即通过调用execute()函数转换成新的RDD，最终执行collect()操作触发计算，返回结果给用户。

SparkPlan在对RDD做Transformation的过程中除对数据进行操作外，还可能对RDD的分区做调整。此外，SparkPlan除实现execute方法外，还有一种情况是直接执行executeBroadcast方法，将数据广播到集群上。

具体来看，SparkPlan的主要功能可以划分为3大块。首先，每个SparkPlan节点必不可少地会记录其元数据（Metadata）与指标（Metric）信息，这些信息以Key-Value的形式保存在Map数据结构中，统称为SparkPlan的Metadata与Metric体系。其次，在对RDD进行Transformation操作时，会涉及数据分区（Partitioning）与排序（Ordering）的处理，称为SparkPlan的Partitioning与Ordering体系；最后，SparkPlan作为物理计划，支持提交到Spark Core去执行，即SparkPlan的执行操作部分，以execute和executeBroadcast方法为主。此外，SparkPlan中还定义了一些辅助函数，如创建新谓词的newPredicate等，这些细节本章不再专门讲解。

在Spark 2.1版本中，Spark SQL大约包含65种具体的SparkPlan实现，涉及数据源RDD的创建和各种数据处理等。根据SparkPlan的子节点数目，可以大致将其分为4类。分别为LeafExecNode、UnaryExecNode、BinaryExecNode和其他不属于这3种子节点的类型，下面分别对这几种类型进行简要介绍。