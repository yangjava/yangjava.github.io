---
layout: post
categories: [Docker]
description: none
keywords: Docker
---
# Docker集群管理
介绍Docker社区中提供的三大编排工具：Compose、Machine和Swarm，以及如何利用这三大工具进行Docker的集群管理。

## Docker集群管理工具
- Docker Compose是用来组装多容器应用的工具，可以在Swarm集群中部署分布式应用。
- Docker Machine是支持多平台安装Docker的工具，使用Docker Machine，可以很方便地在笔记本、云平台及数据中心里安装Docker。
- Docker Swarm是Docker社区原生提供的容器集群管理工具。

## Compose

### Compose概述
在实际的生产环境中，一个应用往往由许多组件构成，而Docker的最佳实践是一个容器只运行一个进程，因此要运行多个组件则必须运行多个容器。在一个由多容器构成的应用里，我们需要一个有效的工具来定义一个应用由哪些容器组成，以及定义这些容器之间如何关联。为了解决以上问题，Compose便应运而生。

简单来讲，Compose是用来定义和运行一个或多个容器应用的工具。使用Compose可以简化容器镜像的建立及容器的运行。Compose使用Python语言开发，非常适合在单机环境里部署一个或多个容器，并自动把多个容器互相关联起来。

Compose是使用YML文件来定义多容器应用的，它还会用docker-compose up命令把完整的应用运行起来。docker-compose up命令为应用的运行做了所有的准备工作。从本质上来讲，Compose把YML文件解析成docker命令的参数，然后调用相应的docker命令行接口，从而把应用以容器化的方式管理起来。它通过解析容器间的依赖关系来顺序地启动容器。而容器间的依赖关系则可以通过在docker-compose.yml文件中使用“links”标记来指定。

对开发环境的搭建、应用服务的部署和CI环境的搭建来说，Compose非常不错。

Compose的使用基本上遵循以下三步：
- 用Dockerfile文件定义应用的运行环境，以便应用在任何地方都可以复制；基于这个Dockerfile，可以构建出一个Docker镜像。
- 用docker-compose.yml文件定义应用的各个服务，以便这些服务可以作为此应用的组件一起运行。
- 最后，执行docker-compose up命令，这样Compose就会创建和运行整个应用了。

### Compose配置简介
Compose是对docker命令的封装，默认使用docker-compose.yml文件来指定docker各个命令中所需的参数。

以下是一个docker-compose.yml文件的简单示例，大致展示了docker-compose.yml文件的构成。
```yaml
web:
    build: ./web
    ports:
    - "5000:5000"
    volumes:
    - .:/code
    links:
    - redis
redis:
    image: redis
```
此docker-compose.yml文件定义了两个服务：Web和Redis，服务的名称是由用户定义的。提供Web服务的镜像是通过在Web子目录下调用docker build命令得到的。Web服务运行后的监听端口是5000，并且把容器里的5000端口映射到了主机上的5000端口；其所使用的“/code”目录是通过挂载当前目录得到的。Web服务通过链接Redis容器来访问后台Redis数据库，而Redis数据库服务则是通过运行Redis镜像来提供的。

在docker-compose.yml文件中，每个定义的服务都至少要包含build或image两个命令中的一个，其他的命令都是可选的。build命令指定了包含Dockerfile的目录，可以是绝对目录也可以是相对目录，相对目录指的是相对于docker-compose.yml文件所在位置的目录。docker-compose.yml文件中的build命令对应的是docker build命令。build命令中的“dockerfile”选项对应docker build命令中的“-f”选项，可以通过指定build命令中的“dockerfile”选项来设置所需的Dockerfile。

docker-compose.yml文件中的“ports”标记对应docker run命令中的“-p”选项；“volumes”标记对应docker run命令中的“-v”选项；“links”标记对应docker run命令中的“--links”选项。

此外，docker-compose.yml文件中的image命令用于指定提供服务的镜像。

通过运行docker-compose build和docker-compose up命令，上述docker-compose.yml文件中定义的Web和Redis服务都会成功运行起来。

常用参数
```
    version           # 指定 compose 文件的版本
    services          # 定义所有的 service 信息, services 下面的第一级别的 key 既是一个 service 的名称

        build                 # 指定包含构建上下文的路径, 或作为一个对象，该对象具有 context 和指定的 dockerfile 文件以及 args 参数值
            context               # context: 指定 Dockerfile 文件所在的路径
            dockerfile            # dockerfile: 指定 context 指定的目录下面的 Dockerfile 的名称(默认为 Dockerfile)
            args                  # args: Dockerfile 在 build 过程中需要的参数 (等同于 docker container build --build-arg 的作用)
            cache_from            # v3.2中新增的参数, 指定缓存的镜像列表 (等同于 docker container build --cache_from 的作用)
            labels                # v3.3中新增的参数, 设置镜像的元数据 (等同于 docker container build --labels 的作用)
            shm_size              # v3.5中新增的参数, 设置容器 /dev/shm 分区的大小 (等同于 docker container build --shm-size 的作用)

        command               # 覆盖容器启动后默认执行的命令, 支持 shell 格式和 [] 格式

        configs               # 不知道怎么用

        cgroup_parent         # 不知道怎么用

        container_name        # 指定容器的名称 (等同于 docker run --name 的作用)

        credential_spec       # 不知道怎么用

        deploy                # v3 版本以上, 指定与部署和运行服务相关的配置, deploy 部分是 docker stack 使用的, docker stack 依赖 docker swarm
            endpoint_mode         # v3.3 版本中新增的功能, 指定服务暴露的方式
                vip                   # Docker 为该服务分配了一个虚拟 IP(VIP), 作为客户端的访问服务的地址
                dnsrr                 # DNS轮询, Docker 为该服务设置 DNS 条目, 使得服务名称的 DNS 查询返回一个 IP 地址列表, 客户端直接访问其中的一个地址
            labels                # 指定服务的标签，这些标签仅在服务上设置
            mode                  # 指定 deploy 的模式
                global                # 每个集群节点都只有一个容器
                replicated            # 用户可以指定集群中容器的数量(默认)
            placement             # 不知道怎么用
            replicas              # deploy 的 mode 为 replicated 时, 指定容器副本的数量
            resources             # 资源限制
                limits                # 设置容器的资源限制
                    cpus: "0.5"           # 设置该容器最多只能使用 50% 的 CPU 
                    memory: 50M           # 设置该容器最多只能使用 50M 的内存空间 
                reservations          # 设置为容器预留的系统资源(随时可用)
                    cpus: "0.2"           # 为该容器保留 20% 的 CPU
                    memory: 20M           # 为该容器保留 20M 的内存空间
            restart_policy        # 定义容器重启策略, 用于代替 restart 参数
                condition             # 定义容器重启策略(接受三个参数)
                    none                  # 不尝试重启
                    on-failure            # 只有当容器内部应用程序出现问题才会重启
                    any                   # 无论如何都会尝试重启(默认)
                delay                 # 尝试重启的间隔时间(默认为 0s)
                max_attempts          # 尝试重启次数(默认一直尝试重启)
                window                # 检查重启是否成功之前的等待时间(即如果容器启动了, 隔多少秒之后去检测容器是否正常, 默认 0s)
            update_config         # 用于配置滚动更新配置
                parallelism           # 一次性更新的容器数量
                delay                 # 更新一组容器之间的间隔时间
                failure_action        # 定义更新失败的策略
                    continue              # 继续更新
                    rollback              # 回滚更新
                    pause                 # 暂停更新(默认)
                monitor               # 每次更新后的持续时间以监视更新是否失败(单位: ns|us|ms|s|m|h) (默认为0)
                max_failure_ratio     # 回滚期间容忍的失败率(默认值为0)
                order                 # v3.4 版本中新增的参数, 回滚期间的操作顺序
                    stop-first            #旧任务在启动新任务之前停止(默认)
                    start-first           #首先启动新任务, 并且正在运行的任务暂时重叠
            rollback_config       # v3.7 版本中新增的参数, 用于定义在 update_config 更新失败的回滚策略
                parallelism           # 一次回滚的容器数, 如果设置为0, 则所有容器同时回滚
                delay                 # 每个组回滚之间的时间间隔(默认为0)
                failure_action        # 定义回滚失败的策略
                    continue              # 继续回滚
                    pause                 # 暂停回滚
                monitor               # 每次回滚任务后的持续时间以监视失败(单位: ns|us|ms|s|m|h) (默认为0)
                max_failure_ratio     # 回滚期间容忍的失败率(默认值0)
                order                 # 回滚期间的操作顺序
                    stop-first            # 旧任务在启动新任务之前停止(默认)
                    start-first           # 首先启动新任务, 并且正在运行的任务暂时重叠

            注意：
                支持 docker-compose up 和 docker-compose run 但不支持 docker stack deploy 的子选项
                security_opt  container_name  devices  tmpfs  stop_signal  links    cgroup_parent
                network_mode  external_links  restart  build  userns_mode  sysctls

        devices               # 指定设备映射列表 (等同于 docker run --device 的作用)

        depends_on            # 定义容器启动顺序 (此选项解决了容器之间的依赖关系， 此选项在 v3 版本中 使用 swarm 部署时将忽略该选项)
            示例：
                docker-compose up 以依赖顺序启动服务，下面例子中 redis 和 db 服务在 web 启动前启动
                默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系

                version: '3'
                services:
                    web:
                        build: .
                        depends_on:
                            - db      
                            - redis  
                    redis:
                        image: redis
                    db:
                        image: postgres                             

        dns                   # 设置 DNS 地址(等同于 docker run --dns 的作用)

        dns_search            # 设置 DNS 搜索域(等同于 docker run --dns-search 的作用)

        tmpfs                 # v2 版本以上, 挂载目录到容器中, 作为容器的临时文件系统(等同于 docker run --tmpfs 的作用, 在使用 swarm 部署时将忽略该选项)

        entrypoint            # 覆盖容器的默认 entrypoint 指令 (等同于 docker run --entrypoint 的作用)

        env_file              # 从指定文件中读取变量设置为容器中的环境变量, 可以是单个值或者一个文件列表, 如果多个文件中的变量重名则后面的变量覆盖前面的变量, environment 的值覆盖 env_file 的值
            文件格式：
                RACK_ENV=development 

        environment           # 设置环境变量， environment 的值可以覆盖 env_file 的值 (等同于 docker run --env 的作用)

        expose                # 暴露端口, 但是不能和宿主机建立映射关系, 类似于 Dockerfile 的 EXPOSE 指令

        external_links        # 连接不在 docker-compose.yml 中定义的容器或者不在 compose 管理的容器(docker run 启动的容器, 在 v3 版本中使用 swarm 部署时将忽略该选项)

        extra_hosts           # 添加 host 记录到容器中的 /etc/hosts 中 (等同于 docker run --add-host 的作用)

        healthcheck           # v2.1 以上版本, 定义容器健康状态检查, 类似于 Dockerfile 的 HEALTHCHECK 指令
            test                  # 检查容器检查状态的命令, 该选项必须是一个字符串或者列表, 第一项必须是 NONE, CMD 或 CMD-SHELL, 如果其是一个字符串则相当于 CMD-SHELL 加该字符串
                NONE                  # 禁用容器的健康状态检测
                CMD                   # test: ["CMD", "curl", "-f", "http://localhost"]
                CMD-SHELL             # test: ["CMD-SHELL", "curl -f http://localhost || exit 1"] 或者　test: curl -f https://localhost || exit 1
            interval: 1m30s       # 每次检查之间的间隔时间
            timeout: 10s          # 运行命令的超时时间
            retries: 3            # 重试次数
            start_period: 40s     # v3.4 以上新增的选项, 定义容器启动时间间隔
            disable: true         # true 或 false, 表示是否禁用健康状态检测和　test: NONE 相同

        image                 # 指定 docker 镜像, 可以是远程仓库镜像、本地镜像

        init                  # v3.7 中新增的参数, true 或 false 表示是否在容器中运行一个 init, 它接收信号并传递给进程

        isolation             # 隔离容器技术, 在 Linux 中仅支持 default 值

        labels                # 使用 Docker 标签将元数据添加到容器, 与 Dockerfile 中的 LABELS 类似

        links                 # 链接到其它服务中的容器, 该选项是 docker 历史遗留的选项, 目前已被用户自定义网络名称空间取代, 最终有可能被废弃 (在使用 swarm 部署时将忽略该选项)

        logging               # 设置容器日志服务
            driver                # 指定日志记录驱动程序, 默认 json-file (等同于 docker run --log-driver 的作用)
            options               # 指定日志的相关参数 (等同于 docker run --log-opt 的作用)
                max-size              # 设置单个日志文件的大小, 当到达这个值后会进行日志滚动操作
                max-file              # 日志文件保留的数量

        network_mode          # 指定网络模式 (等同于 docker run --net 的作用, 在使用 swarm 部署时将忽略该选项，主机模式如 network_mode: "host" )         

        networks              # 将容器加入指定网络 (等同于 docker network connect 的作用), networks 可以位于 compose 文件顶级键和 services 键的二级键
            aliases               # 同一网络上的容器可以使用服务名称或别名连接到其中一个服务的容器
            ipv4_address      # IP V4 格式
            ipv6_address      # IP V6 格式

            示例:
                version: '3.7'
                services: 
                    test: 
                        image: nginx:1.14-alpine
                        container_name: mynginx
                        command: ifconfig
                        networks: 
                            app_net:                                # 调用下面 networks 定义的 app_net 网络
                            ipv4_address: 172.16.238.10
                networks:
                    app_net:
                        driver: bridge
                        ipam:
                            driver: default
                            config:
                                - subnet: 172.16.238.0/24

        pid: 'host'           # 共享宿主机的 进程空间(PID)

        ports                 # 建立宿主机和容器之间的端口映射关系, ports 支持两种语法格式
            SHORT 语法格式示例:
                - "3000"                            # 暴露容器的 3000 端口, 宿主机的端口由 docker 随机映射一个没有被占用的端口
                - "3000-3005"                       # 暴露容器的 3000 到 3005 端口, 宿主机的端口由 docker 随机映射没有被占用的端口
                - "8000:8000"                       # 容器的 8000 端口和宿主机的 8000 端口建立映射关系
                - "9090-9091:8080-8081"
                - "127.0.0.1:8001:8001"             # 指定映射宿主机的指定地址的
                - "127.0.0.1:5000-5010:5000-5010"   
                - "6060:6060/udp"                   # 指定协议

            LONG 语法格式示例:(v3.2 新增的语法格式)
                ports:
                    - target: 80                    # 容器端口
                      published: 8080               # 宿主机端口
                      protocol: tcp                 # 协议类型
                      mode: host                    # host 在每个节点上发布主机端口,  ingress 对于群模式端口进行负载均衡

        secrets               # 不知道怎么用

        security_opt          # 为每个容器覆盖默认的标签 (在使用 swarm 部署时将忽略该选项)

        stop_grace_period     # 指定在发送了 SIGTERM 信号之后, 容器等待多少秒之后退出(默认 10s)

        stop_signal           # 指定停止容器发送的信号 (默认为 SIGTERM 相当于 kill PID; SIGKILL 相当于 kill -9 PID; 在使用 swarm 部署时将忽略该选项)

        sysctls               # 设置容器中的内核参数 (在使用 swarm 部署时将忽略该选项)

        ulimits               # 设置容器的 limit

        userns_mode           # 如果Docker守护程序配置了用户名称空间, 则禁用此服务的用户名称空间 (在使用 swarm 部署时将忽略该选项)

        volumes               # 定义容器和宿主机的卷映射关系, 其和 networks 一样可以位于 services 键的二级键和 compose 顶级键, 如果需要跨服务间使用则在顶级键定义, 在 services 中引用
            SHORT 语法格式示例:
                volumes:
                    - /var/lib/mysql                # 映射容器内的 /var/lib/mysql 到宿主机的一个随机目录中
                    - /opt/data:/var/lib/mysql      # 映射容器内的 /var/lib/mysql 到宿主机的 /opt/data
                    - ./cache:/tmp/cache            # 映射容器内的 /var/lib/mysql 到宿主机 compose 文件所在的位置
                    - ~/configs:/etc/configs/:ro    # 映射容器宿主机的目录到容器中去, 权限只读
                    - datavolume:/var/lib/mysql     # datavolume 为 volumes 顶级键定义的目录, 在此处直接调用

            LONG 语法格式示例:(v3.2 新增的语法格式)
                version: "3.2"
                services:
                    web:
                        image: nginx:alpine
                        ports:
                            - "80:80"
                        volumes:
                            - type: volume                  # mount 的类型, 必须是 bind、volume 或 tmpfs
                                source: mydata              # 宿主机目录
                                target: /data               # 容器目录
                                volume:                     # 配置额外的选项, 其 key 必须和 type 的值相同
                                    nocopy: true                # volume 额外的选项, 在创建卷时禁用从容器复制数据
                            - type: bind                    # volume 模式只指定容器路径即可, 宿主机路径随机生成; bind 需要指定容器和数据机的映射路径
                                source: ./static
                                target: /opt/app/static
                                read_only: true             # 设置文件系统为只读文件系统
                volumes:
                    mydata:                                 # 定义在 volume, 可在所有服务中调用

        restart               # 定义容器重启策略(在使用 swarm 部署时将忽略该选项, 在 swarm 使用 restart_policy 代替 restart)
            no                    # 禁止自动重启容器(默认)
            always                # 无论如何容器都会重启
            on-failure            # 当出现 on-failure 报错时, 容器重新启动

        其他选项：
            domainname, hostname, ipc, mac_address, privileged, read_only, shm_size, stdin_open, tty, user, working_dir
            上面这些选项都只接受单个值和 docker run 的对应参数类似

        对于值为时间的可接受的值：
            2.5s
            10s
            1m30s
            2h32m
            5h34m56s
            时间单位: us, ms, s, m， h
        对于值为大小的可接受的值：
            2b
            1024kb
            2048k
            300m
            1gb
            单位: b, k, m, g 或者 kb, mb, gb
    networks          # 定义 networks 信息
        driver                # 指定网络模式, 大多数情况下, 它 bridge 于单个主机和 overlay Swarm 上
            bridge                # Docker 默认使用 bridge 连接单个主机上的网络
            overlay               # overlay 驱动程序创建一个跨多个节点命名的网络
            host                  # 共享主机网络名称空间(等同于 docker run --net=host)
            none                  # 等同于 docker run --net=none
        driver_opts           # v3.2以上版本, 传递给驱动程序的参数, 这些参数取决于驱动程序
        attachable            # driver 为 overlay 时使用, 如果设置为 true 则除了服务之外，独立容器也可以附加到该网络; 如果独立容器连接到该网络，则它可以与其他 Docker 守护进程连接到的该网络的服务和独立容器进行通信
        ipam                  # 自定义 IPAM 配置. 这是一个具有多个属性的对象, 每个属性都是可选的
            driver                # IPAM 驱动程序, bridge 或者 default
            config                # 配置项
                subnet                # CIDR格式的子网，表示该网络的网段
        external              # 外部网络, 如果设置为 true 则 docker-compose up 不会尝试创建它, 如果它不存在则引发错误
        name                  # v3.5 以上版本, 为此网络设置名称
```

文件格式示例
```yaml
    version: "3"
    services:
      redis:
        image: redis:alpine
        ports:
          - "6379"
        networks:
          - frontend
        deploy:
          replicas: 2
          update_config:
            parallelism: 2
            delay: 10s
          restart_policy:
            condition: on-failure
      db:
        image: postgres:9.4
        volumes:
          - db-data:/var/lib/postgresql/data
        networks:
          - backend
        deploy:
          placement:
            constraints: [node.role == manager]
```

## Machine概述
Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，为用户提供了灵活的功能，使得用户可以在任意主机（不管是笔记本、数据中心中的主机，还是云主机）上运行Docker容器。这大幅度减少了开发者手动设置、编写自定义脚本的时间，而且还可以控制Machine创建的Docker主机。目前Docker Machine也支持Swarm集群。简单来讲，一个Docker Machine就是一个Docker host主机和经过配置的Docker client的结合体。

从技术上来讲，Docker Machine是一个框架，比较开放。对于任何提供虚拟机服务的平台，只要在这个框架下开发针对该平台的驱动，Docker Machine就可以与其交互，可在该平台上执行创建、删除Machine等操作，并且可控制Machine的行为如停止、启动等。

### Machine的基本概念及运行流程
Docker Machine首先会创建一个虚拟机并在其上创建一个Docker host，然后使用Docker client和Docker host通信，从而在Docker host上创建镜像，启动容器。

用Docker Machine创建虚拟机的时候需要指定相应的驱动，目前支持本机的驱动有Oracle的VirtualBox驱动、Vmware的驱动及Windows下的Hyper-V驱动。除此之外，Docker Machine还支持云主机的创建（比如在AWS中）。只要开发了相应的驱动插件，Docker Machine就可以支持相应的平台。

每一个Docker Machine创建的虚拟机都要有一个操作系统，默认情况下，VirtualBox驱动创建的虚拟机所使用的操作系统是boot2docker，这是一个可以运行Docker容器的轻量级Linux操作系统。对于云平台的驱动所创建的虚拟机，其默认的操作系统是Ubuntu 12.04+。

Docker Machine创建的Docker host的IP地址是所创建的虚拟机的IP地址。

使用Docker Machine及VirtualBox驱动创建本地虚拟机并搭建Docker Host的运行流程如下：
- 运行“docker-machine create--driver virtualbox dev”命令。此命令首先创建用于Docker client和Docker host通信的CA证书。其次创建VirtualBox虚拟机，并配置用于通信的TLS参数及配置网络，最后部署Docker的运行环境即Docker host。
- 在Docker client里运行“eval"$（docker-machine env dev）"”命令，配置用于和Docker Host通信的环境变量。
- 使用docker相关命令创建或启动相应的容器，例如使用“docker run busybox echo hello world”命令可运行busybox工具集。


## Swarm

### Swarm概述
Swarm是Docker社区提供的原生支持Docker集群的工具。它可以把多个Docker主机组成的系统转换成为单一的虚拟Docker主机。Swarm对外提供两种API，一种是标准的Docker API，比如Dokku、Compose、Krane、Flynn、Deis、DockerUI、Shipyard、Drone、Jenkins等，当然也包括Docker Client，它们都可以通过Swarm和Docker集群进行通信；另一种是Swarm的集群管理API，用于集群的管理。

Swarm从设计之初就遵循“swap，plug and play”的原则。比如，你可以使用喜欢的调度系统来替换Swarm中原生的调度系统。这种设计原则使Swarm的扩展变得非常容易。

### Swarm内部架构
Swarm的目标是使用同Docker引擎一样的API，将Docker客户端对API Endpoint的请求，在发往Swarm管理下的Docker引擎节点组成的集群的过程中，可根据配置好的调度策略、约束规则，分发到集群中的某个引擎节点上去处理。而对客户端来说，这些完全透明。这样实现的主要优势体现在既有的工具和API可以像单机版一样继续在Swarm集群上工作和使用。Swarm由Discovery Service模块、Scheduler模块和Leadership模块组成。

### Discovery Service
Discovery Scheduler模块用来发现Swarm集群中的节点。该模块采用即插即用的模式，目前它支持三种类型的服务发现后端：
- Docker Hub提供的服务发现后端；
- 分布式的KV存储系统，现已支持Consul、Etcd和Zookeeper；
- 静态描述文件和静态IP地址列表。

此外，任何服务发现的后端模块只要满足服务发现标准接口定义的功能，Swarm都可以支持。

### Scheduler
Swarm的Sheduler模块主要负责给用户新创建的容器分配最优的节点。它通过两个阶段来选择最优的节点：首先根据用户的过滤条件筛选出符合要求的节点，然后通过调度策略选择最优的节点。

Scheduler的过滤器包括Constraint、Affinity、Dependency、Health filter和Ports filter这几种。其中Constraint过滤器中定义的约束是附加在Swarm节点上的一组键值对，可以认为这些约束就是Swarm节点的标签。Constraint过滤器中提供的标准约束有节点的ID、节点的名称，以及存储驱动、执行驱动、内核的版本和操作系统的信息。用户可根据自己的需求选择相应的过滤器。

Scheduler支持Random、Spread和Binpack这三种调度策略。Spread和Binpack策略是根据节点可利用的CPU、内存资源和当前已有的容器数量来做调度决策，Spread会把容器调度到负载低的节点上，而Binpack则是把容器调度到负载最高的节点上。至于Random，它根本不做计算，不管节点上的资源情况和容器数量如何，只做随机调度。

Spread调度策略使得系统中各个节点的负载比较均衡，即便某个节点出现故障，对系统的影响也不会很大，而Binpack则让容器部署在尽量少的节点上，提高节点承载容器的密度。它们各自的缺点也是显而易见的，需要根据要部署应用的特殊需求来选择相应的调度策略。

### Leadership
Swarm的Leadership模块主要提供搭建Swarm HA Cluster的功能。




