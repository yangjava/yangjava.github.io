---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# SparkSQL基础
从大数据概念产生以来10多年的技术发展轨迹讲起，简要回顾Spark SQL的演化历程。

## 大数据
大数据一词，最早出现于20世纪90年代，由数据仓库之父Bill Inmon所提及。2008年，Nature杂志出版了大数据专刊“Big Data”，专门讨论海量数据对互联网、经济、环境和生物等各方面的影响与挑战。

2011年，Science出版了如何应对数据洪流（Data deluge）的专刊“Dealing w ith Data”，指出如何利用大数据中宝贵的数据价值来推动人类社会的发展。

迄今为止，大数据并没有统一的标准定义，业界和学术界通常用5个方面的属性（5V）来描述大数据的特点：Volume（体量大）、Velocity（时效高）、Variety（类型多）、Veracity（真实性）、Value（价值大）。

大数据一方面意味着巨大的信息价值，另一方面也带来了技术上的挑战，使得传统的计算机技术难以在合理的时间内达到数据存储、处理和分析的目的。大数据应用的爆发性增长，已经衍生出独特的架构，并直接推动了存储、网络和计算技术的研究。

Google公司于2003年在SOSP会议上发表论文介绍分布式文件系统GFS，于2004年在OSDI会议上发表论文介绍分布式大数据编程模型与处理框架MapReduce，于2006年再次在OSDI会议上发表论文介绍分布式数据库BigTable的实现。以上三者统称为Google公司初期大数据技术的“三驾马车”，自此各种大数据存储与处理技术开始蓬勃发展。

## Spark系统
Spark分布式计算框架是大数据处理领域的佼佼者，由美国加州大学伯克利分校的AMP实验室开发。相比于流行的Hadoop系统，Spark优势明显。Spark一方面提供了更加灵活丰富的数据操作方式，有些需要分解成几轮MapReduce作业的操作，可以在Spark里一轮实现；另一方面，每轮的计算结果都可以分布式地存放在内存中，下一轮作业直接从内存中读取上一轮的数据，节省了大量的磁盘IO开销。

因此，对于机器学习、模式识别等迭代型计算，Spark在计算速度上通常可以获得几倍到几十倍的提升。得益于Spark对Hadoop计算的兼容，以及对迭代型计算的优异表现，成熟之后的Spark系统得到了广泛的应用。例如，在大部分公司中，典型的场景是将Hadoop（HDFS）作为大数据存储的标准，而将Spark作为计算引擎的核心。

经过多年的发展，Spark已成为目前大数据处理领域炙手可热的顶级开源项目。屈指一算，Spark从诞生到2018年，已经走过了整整9个年头。第一个版本的Spark诞生在2009年，代码量仅有3900行左右，其中还包含600行的例子和300多行的测试代码。当时，Hadoop在国外已经开始流行，但是其MapReduce编程模型较为笨拙和烦琐，Matei借鉴Scala的Collection灵感，希望开发出一套能像操作本地集合一样简捷、高效操作远程大数据的框架，并能运行于Mesos平台上，于是就有了Spark最初的0.1版本和0.2版本。

后来，Reynold Xin加入这个项目，在协助对Core模块进行开发的同时，在其之上启动了Shark项目，希望能够让Spark更好地处理SQL任务，替代当时流行的Hive（基于Hadoop的数据仓库解决方案）。当然，这个版本的Shark在多个方面都存在先天的不足，Spark在后来的发展过程中将其废弃，另起炉灶，从头来过，这也就是众所周知的Spark SQL

在此期间，Spark经历了一个蓬勃的生长期，从2012年的0.6版本开始，Core模块开始趋于稳定，接近生产级别，不再是实验室的产物。我国的阿里巴巴团队开始将其用于线上正式作业，并取得了比使用MapReduce更好的效果。同时，Intel公司也开始投入力量到该项目的开发中。在0.7版本中，Tathagata Das开始加入Stream ing模块，使得Spark具备准实时的流处理能力。

到了0.8版本，Spark正式支持在YARN上的部署运行，Yahoo公司贡献了重要的代码，国内的阿里巴巴团队也开始将其正式部署到内部的云梯集群，搭建了300台专用Spark集群。在0.9版本中，图处理系统GraphX正式成为独立模块，同年，Apache接受Spark成为顶级项目，从孵化期到正式项目，只经历了短短半年时间，这种速度在Apache开源社区是非常难得的。到了1.0版本，孟祥瑞等人加入DataBricks公司，主导的MLLib也成为正式模块。至此，各个主要模块形成了较完整的Spark技术栈（生态系统）。

在2012—2014年，Spark经历了一个高速的发展过程，各个模块快速演进，各大公司和全球顶尖开发人员的加入，使得整个项目充满生命力和活力。DataBricks公司成立后，多数客户的需求集中在常用的数据处理方面，而这需要Spark系统有完善且强大的SQL能力。因此，在2014—2017年，Spark技术栈重点关注Spark SQL子项目，在钨丝计划（Tungsten）的基础上，开始了DataFrame和DataSet为用户接口核心的SQL功能开发，使得Spark SQL项目发展迅速，整体内核也针对SQL做了很多优化。从1.6版本开始，社区的发展一步一个脚印，到如今功能完善的2.x版本，Spark SQL已经非常成熟，完全达到了商用的程度。

## 关系模型与SQL语言
计算机软件系统离不开底层的数据，而数据的存储管理需求促进了数据库技术的发展。早期的数据库包含网状数据库和层次数据库等不同类型。在20世纪70年代，IBM的研究员E.F.Codd提出关系模型[13]。因为具有严格的数学理论基础、较高的抽象级别，而且便于理解和使用，所以关系模型成为现代数据库产品的主流，并占据统治地位40多年。此外，IBM公司研究人员将关系模型中的数学准则以关键字语法表现出来，于1974年里程碑式地提出了SQL（Structured Query Language）语言。SQL语言是一种声明式的语言，提供了查询、操纵、定义和控制等数据库生命周期中的全部操作。另外，建立在关系模型之上并提供SQL语言支持的关系数据库管理系统（如Oracle、DB2、SQLServer等），已经成为企业通用的数据存储解决方案。对数据管理人员和应用开发人员来说，关系模型和SQL语言一直是必不可少的技术基础。

尽管非结构化数据和半结构化数据在数据量上占有绝大部分比例，但结构化数据和SQL需求仍旧具有举足轻重的作用。当Hadoop生态系统进入企业时（注：广义上Spark也可以看作是Hadoop生态系统中的一员），必须面对的一个问题就是怎样解决和应对传统成熟的信息架构。在企业内部，如何处理原有的结构化数据是企业进入大数据领域所面临的难题。Hadoop生态系统的初衷在于解决日志文件分析、互联网点击流、倒排索引和大文件存储等非结构化数据的问题。在此背景的驱动下，面向Hadoop生态系统的SQL查询处理技术及框架（统称为“SQL-on-Hadoop”应运而生。SQL-on-Hadoop解决方案为用户提供关系模型和SQL查询接口，并透明地将存储与查询转换为Hadoop生态系统的对应技术来管理海量结构化数据。

作为数据分析领域重要的支撑，SQL-on-Hadoop成为近几年来广受关注的热点，并涌现出大量的产品，如典型的Hive、Impala和Presto等。所以，从横向来看，Spark SQL算是SQL-on-Hadoop解决方案大家庭中的重要一员。SQL-on-Hadoop并非专指某一个特定的系统，而是借助于Hadoop生态系统完成SQL功能的解决方案的总称。因此，一个具体的SQL-on-Hadoop系统往往依赖于Hadoop生态系统中的分布式存储技术（如HDFS、HBase等），或者利用分布式计算框架（如MapReduce、Tez、Spark等），具有高度的灵活性。例如，Hive既可以转换为MapReduce计算框架，也能够转换为Tez这种DAG的计算方式。此外，对于关系数据表的访问，Spark SQL既支持直接存储在HDFS上，又可以通过连接器（Connector）连接存储在类似HBase这种具有特定数据模型的系统中。而Impala则将SQL语言转换为自定义的分布式计算框架，来访问存储在HDFS或HBase等NoSQL中的数据。

需要注意的是，Spark SQL这类SQL-on-Hadoop解决方案和传统的MPP解决方案在架构上存在很大差异。根据Hadoop生态系统的特点，SQL-on-Hadoop解决方案从架构上来看可以简单地划分为三层结构。最上层是应用（语言）层，应用层为用户提供数据管理查询的接口，不同的SQL-on-Hadoop系统往往提供各自的SQL语法特性，如Hive的HiveQL、Pig的PigLatin和Spark SQL的DataFrame等。在大数据场景下，应用层也包含一些针对特别需求的接口，如BlinkDB所支持的近似查询功能等。应用层之下是分布式执行层，SQL-on-Hadoop系统通过一定的规则或策略将SQL语句转换为对应的计算模型。除MapReduce、Spark等通用的计算框架外，分布式执行层可能是某些系统自定义的计算单元，例如Impala中的Query Exec Engine等。分布式执行层通过接口访问数据存储层中的数据，并完成相应的计算任务。SQL-on-Hadoop系统的底层是数据存储层，主要负责对关系数据表这样的逻辑视图进行存储与管理。

目前，各种SQL-on-Hadoop数据存储层基本都支持分布式文件系统HDFS和分布式NoSQL数据库。总的来看，SQL-on-Hadoop解决方案类似“堆积木”，各层之间松耦合，并可以灵活组合。数据存储层与分布式执行层之间通过特定的数据读写接口进行数据的交互。这种分层解耦的方式一方面具有通用性（各层可以分别分离为子系统）和灵活性（彼此能够互相组合）的优势，另一方面隔离了各层的特性，限制了深度集成优化的空间。

## Spark SQL发展历程
Spark SQL的前身是Shark，即“Hive on Spark”，由Reynold Xin主导开发。Shark项目最初启动于2011年，当时Hive几乎算是唯一的SQL-on-Hadoop选择方案。Hive将SQL语句翻译为MapReduce，正如前文所提到的，性能会受限于MapReduce计算模型，始终无法满足各种交互式SQL分析的需求，因此许多机构仍然依赖传统的企业数据仓库（EDW）。Shark的提出就是针对这种需求的，目标是既能够达到EDW的性能，又能够具有MapReduce的水平扩展功能。

Shark建立在Hive代码的基础上，只修改了内存管理、物理计划、执行3个模块中的部分逻辑。Shark通过将Hive的部分物理执行计划交换出来（“swappingout thephysicalexecution engine partofHive”），最终将HiveQL转换为Spark的计算模型，使之能运行在Spark引擎上，从而使得SQL查询的速度得到10～100倍的提升。此外，Shark的最大特性是与Hive完全兼容，并且支持用户编写机器学习或数据处理函数，对HiveQL执行结果进行进一步分析。

但是，随着Spark的不断发展，Shark对Hive的重度依赖体现在架构上的瓶颈越来越突出。一方面，Hive的语法解析和查询优化等模块本身针对的是MapReduce，限制了在Spark系统上的深度优化和维护；另一方面，过度依赖Hive制约了Spark的“One Stack Rule them All”既定方针，也制约了技术栈中各个组件的灵活集成。在此背景下，Spark SQL项目被提出来，由M ichaelArmbrust主导开发。Spark SQL抛弃原有Shark的架构方式，但汲取了Shark的一些优点，如内存列存储（In-Memory Columnar Storage）、Hive兼容性等，重新开发了SQL各个模块的代码。

由于摆脱了对Hive的依赖，Spark SQL在数据兼容、性能优化、组件扩展方面都得到了极大的提升。在2014年7月1日的Spark峰会上，Databricks公司宣布终止对Shark的开发，将后续重点放到Spark SQL上。Spark SQL涵盖了Shark的所有特性，用户可以从Shark进行无缝升级，至此，Shark的发展画上了句号。Spark SQL开始迎来蓬勃的发展阶段。如今，Spark SQL已经成为Apache Spark中最为活跃的子项目。

## Spark SQL能做什么
现在我们知道了Spark SQL是怎么来的，那么Spark SQL到底能做些什么呢？下面我们根据ETL（数据的抽取、转换、加载）的三个过程来讲解一下Spark SQL的作用。

- 抽取（Extract）
Spark SQL可以从多种文件系统（HDFS、S3.本地文件系统等）、关系型数据库（MySQL、Oracle、PostgreSQL等）或NoSQL数据库（Cassandra、HBase、Druid等）中获取数据，Spark SQL支持的文件类型可以是CSV、JSON、XML、Parquet、ORC、Avro等。得益于Spark SQL对多种数据源的支持，Spark SQL能从多种渠道抽取人们想要的数据到Spark中。
- 转换（Transform）
我们常说的数据清洗，比如空值处理、拆分数据、规范化数据格式、数据替换等操作。Spark SQL能高效地完成这类转换操作。
- 加载（Load）
在数据处理完成之后，Spark SQL还可以将数据存储到各种数据源（前文提到的数据源）中。

如果你以为Spark SQL只能做上面这些事情，那你就错了。Spark SQL还可以作为一个分布式SQL查询引擎通过JDBC或ODBC或者命令行的方式对数据库进行分布式查询。Spark SQL中还有一个自带的Thrift JDBC/ODBC服务，可以用Spark根目录下的sbin文件夹中的start-thriftserver.sh脚本启动这个服务。Spark中还自带了一个Beeline的命令行客户端，读者可以通过这个客户端连接启动的Thrift JDBC/ODBC，然后提交SQL。

如果你以为Spark SQL能做的只有这些，那你就错了。Spark SQL还可以和Spark的其他模块搭配使用，完成各种各样复杂的工作。比如和Streaming搭配处理实时的数据流，和MLlib搭配完成一些机器学习的应用。










