---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# Spark源码调度RDD详解
RDD（Resilient Distributed Datasets，弹性分布式数据集）代表可并行操作元素的不可变分区集合。严格来讲，RDD的转换及DAG的构成并不属于调度系统的内容，但是RDD却是调度系统操作的主要对象，因此有必要对RDD进行详细介绍。

## 为什么需要RDD
以下从数据处理模型、依赖划分原则、数据处理效率及容错处理4个方面解释Spark为什么需要RDD。

### 数据处理模型
RDD是一个容错的、并行的数据结构，可以控制将数据存储到磁盘或内存，能够获取数据的分区。RDD提供了一组类似于Scala的操作，比如map、flatMap、filter、reduceByKey、join、mapPartitions等，这些操作实际是对RDD进行转换（transformation）。此外，RDD还提供了collect、foreach、count、reduce、countByKey等操作完成数据计算的动作（action）。

当前的大数据应用场景非常丰富，如流式计算、图计算、机器学习等，它们既有相似之处，又各有不同。为了能够对所有场景下的数据处理使用统一的方式，抽象出RDD这一模型。

通常数据处理的模型包括迭代计算、关系查询、MapReduce、流式处理等。Hadoop采用MapReduce模型，Storm采用流式处理模型，而Spark则借助RDD实现了以上所有模型。

### 依赖划分原则
一个RDD包含一个或者多个分区，每个分区实际是一个数据集合的片段。在构建DAG的过程中，会将RDD用依赖关系串联起来。每个RDD都有其依赖（除了最顶级RDD的依赖是空列表），这些依赖分为窄依赖（即NarrowDependency）和Shuffle依赖（即ShuffleDependency，也称为宽依赖）两种。为什么要对依赖进行区分？从功能角度讲它们是不一样的。NarrowDependency会被划分到同一个Stage中，这样它们就能以管道的方式迭代执行。ShuffleDependency由于所依赖的分区Task不止一个，所以往往需要跨节点传输数据。从容灾角度讲，它们恢复计算结果的方式不同。NarrowDependency只需要重新执行父RDD的丢失分区的计算即可恢复，而ShuffleDependency则需要考虑恢复所有父RDD的丢失分区。

解释了依赖划分的原因，实际也解释了为什么要划分Stage这个问题。

### 数据处理效率
RDD的计算过程允许在多个节点并发执行。如果数据量很大，可以适当增加分区数量，这种根据硬件条件对并发任务数量的控制，能更好地利用各种资源，也能有效提高Spark的数据处理效率。

### 容错处理
传统关系型数据库往往采用日志记录的方式来容灾容错，数据恢复都依赖于重新执行日志。Hadoop为了避免单机故障概率较高的问题，通常将数据备份到其他机器容灾。由于所有备份机器同时出故障的概率比单机故障概率低很多，所以在发生宕机等问题时能够从备份机读取数据。RDD本身是一个不可变的（Scala中称为immutable）数据集，当某个Worker节点上的Task失败时，可以利用DAG重新调度计算这些失败的Task（执行已成功的Task可以从CheckPoint（检查点）中读取，而不用重新计算）。在流式计算的场景中，Spark需要记录日志和CheckPoint，以便利用CheckPoint和日志对数据恢复。

## RDD实现的初次分析
抽象类RDD定义了所有RDD的规范，我们从RDD的属性开始，逐步了解RDD的实现。
- _sc：指SparkContext。_sc由@transient修饰，所以此属性不会被序列化。
- deps：构造器参数之一，是Dependency的序列，用于存储当前RDD的依赖。RDD的子类在实现时不一定会传递此参数。由于deps由@transient修饰，所以此属性不会被序列化。
- partitioner：当前RDD的分区计算器。partitioner由@transient修饰，所以此属性不会被序列化。
- id：当前RDD的唯一身份标识。此属性通过调用SparkContext的nextRddId属性生成。
- name：RDD的名称。name由@transient修饰，所以此属性不会被序列化。
- dependencies_：与deps相同，但是可以被序列化。
- partitions_：存储当前RDD的所有分区的数组。partitions_由@transient修饰，所以此属性不会被序列化。
- storageLevel：当前RDD的存储级别。
- creationSite：创建当前RDD的用户代码。creationSite由@transient修饰，所以此属性不会被序列化。
- scope：当前RDD的操作作用域。scope由@transient修饰，所以此属性不会被序列化。
- checkpointData：当前RDD的检查点数据。
- checkpointAllMarkedAncestors：是否对所有标记了需要保存检查点的祖先保存检查点。
- doCheckpointCalled：是否已经调用了doCheckpoint方法设置检查点。此属性可以阻止对RDD多次设置检查点。

RDD采用了模板方法的模式设计，抽象类RDD中定义了模板方法及一些未实现的接口，这些接口将需要RDD的各个子类分别实现。下面先来介绍RDD中定义的接口。

- compute：对RDD的分区进行计算。此方法的定义如下：
```
　@DeveloperApi
　　def compute(split: Partition, context: TaskContext): Iterator[T]
```

- getPartitions：获取当前RDD的所有分区。此方法的定义如下：
```
protected def getPartitions: Array[Partition]
```
- getDependencies：获取当前RDD的所有依赖。此方法的定义如下：
```
protected def getDependencies: Seq[Dependency[_]] = deps
```
- getPreferredLocations：获取某一分区的偏好位置。此方法的定义如下：
```
　　protected def getPreferredLocations(split: Partition): Seq[String] = Nil
```

RDD中除定义了以上接口外，还实现了一些模板方法。


## RDD依赖
DAG中的各个RDD之间存在着依赖关系。换言之，正是RDD之间的依赖关系构建了由RDD所组成的DAG。Spark使用Dependency来表示RDD之间的依赖关系，Dependency的定义如下。
```
@DeveloperApi
abstract class Dependency[T] extends Serializable {
  def rdd: RDD[T]
}

```
抽象类Dependency只定义了一个名叫rdd的方法，此方法返回当前依赖的RDD。

Dependency分为NarrowDependency和ShuffleDependency两种依赖，下面对它们分别进行介绍。

### 窄依赖
如果RDD与上游RDD的分区是一对一的关系，那么RDD和其上游RDD之间的依赖关系属于窄依赖（NarrowDependency）。NarrowDependency继承了Dependency，以表示窄依赖。NarrowDependency的定义如下。
```
@DeveloperApi
abstract class NarrowDependency[T](_rdd: RDD[T]) extends Dependency[T] {
  def getParents(partitionId: Int): Seq[Int]
  override def rdd: RDD[T] = _rdd
}
```






