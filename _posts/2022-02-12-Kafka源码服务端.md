---
layout: post
categories: [Kafka]
description: none
keywords: Kafka
---
# Kafka源码服务端
一个完整的kafka链路是由上游的生产者，kafka集群本身，还有下游的消费者组成，前面的文章中已经分析生产者发送消息的流程、集群的元数据和消息的封装、以及最终真正负责发送消息的sender线程和极其重要的NetworkClient网络通信组件，介绍了NetworkClient依赖的几个重要的类。下面我们开始针对Kafka服务端进行分析。

## Kafka
Kafka 服务端是连接生产者和消费者的桥梁，前面分析了生产者发送消息原理和流程，消息送到下游的必备条件必须保证服务是正常的，我们需要关注下面几个重点问题：
- 服务端初始化
- 如何接收并处理上游请求
- 如何存储接收到的数据
- 副本数据同步
- 元数据更新

## 服务端初始化
熟悉 Kafka 服务的同学应该知道部署好 Kafka 集群后通过 jps 指令会得到一个叫 Kafka 的服务，因此我们从 Kafka 服务本身入手，从源码中可以发现一个类，与服务同名---Kafka。

Kafka这个类的代码只有短短的几十行，只有两个方法，getPropsFromArgs（）和 main（）方法，显然 main（）方法才是我们要关注的方法，同样的思路，我们看源码的时候第一遍只关注主线，不要花时间去研究旁枝末节，否则容易看着看着就不知道跑到哪去了，这是很多人容易出现的误区。
```
 def main(args: Array[String]): Unit = {
  try {
    //解析启动 kafka 服务时传入的参数
    val serverProps = getPropsFromArgs(args)
    val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps)
    // attach shutdown handler to catch control-c
    Runtime.getRuntime().addShutdownHook(new Thread() {
      override def run() = {
        kafkaServerStartable.shutdown
      }
    })
    // 核心代码
    kafkaServerStartable.startup
    kafkaServerStartable.awaitShutdown
  }
  catch {
    case e: Throwable =>
      fatal(e)
      System.exit(1)
  }
  System.exit(0)
}
调用 startup方法启动服务，往下看。
def startup() {
  try {
    //启动服务
    server.startup()
  }
  //异常则退出
  catch {
    case e: Throwable =>
      fatal("Fatal error during KafkaServerStartable startup. Prepare to shutdown", e)
      // KafkaServer already calls shutdown() internally, so this is purely for logging & the exit code
      System.exit(1)
  }
}
```
这里可以看到 startup（）方法中封装了另外一个 startup（）方法，这样可以大大提高代码的可读性以及将复杂底业务逻辑剥离出来。

```
/**
 * Start up API for bringing up a single instance of the Kafka server.
 * Instantiates the LogManager, the SocketServer and the request handlers - KafkaRequestHandlers
 */
 //负责启动 Kafka Server 同时初始化 LogManger、SocketServer以及KafkaRequestHandlers
 
def startup() {
  try {
    info("starting")
    if(isShuttingDown.get)
      throw new IllegalStateException("Kafka server is still shutting down, cannot re-start!")
    if(startupComplete.get)
      return
    val canStartup = isStartingUp.compareAndSet(false, true)
    if (canStartup) {
      metrics = new Metrics(metricConfig, reporters, kafkaMetricsTime, true)
      quotaManagers = QuotaFactory.instantiate(config, metrics, time)
      brokerState.newState(Starting)
      /* start scheduler */
      kafkaScheduler.startup()
      // 核心代码，初始化 zk 集群
      zkUtils = initZk()
      /* Get or create cluster_id */
      _clusterId = getOrGenerateClusterId(zkUtils)
      info(s"Cluster ID = $clusterId")
      notifyClusterListeners(kafkaMetricsReporters ++ reporters.asScala)
      // 实例化logManager
      logManager = createLogManager(zkUtils.zkClient, brokerState)
      //启动 LogManager
      logManager.startup()
      /* generate brokerId */
      config.brokerId =  getBrokerId
      this.logIdent = "[Kafka Server " + config.brokerId + "], "
      metadataCache = new MetadataCache(config.brokerId)
 
      //创建 SocketServer 服务端
      socketServer = new SocketServer(config, metrics, kafkaMetricsTime)
      //启动 SocketServer
      socketServer.startup()
 
      //实例化ReplicaMananger
      //核心参数logManager
      replicaManager = new ReplicaManager(config, metrics, time, kafkaMetricsTime, zkUtils, kafkaScheduler, logManager,
        isShuttingDown, quotaManagers.follower)
      //启动ReplicaMananger
      replicaManager.startup()
      //实例化启动controller
      kafkaController = new KafkaController(config, zkUtils, brokerState, kafkaMetricsTime, metrics, threadNamePrefix)
      //启动 KafkaController
      kafkaController.startup()
      adminManager = new AdminManager(config, metrics, metadataCache, zkUtils)
      /* start group coordinator */
      groupCoordinator = GroupCoordinator(config, zkUtils, replicaManager, kafkaMetricsTime)
      groupCoordinator.startup()
      /* Get the authorizer and initialize it if one is specified.*/
      authorizer = Option(config.authorizerClassName).filter(_.nonEmpty).map { authorizerClassName =>
        val authZ = CoreUtils.createObject[Authorizer](authorizerClassName)
        authZ.configure(config.originals())
        authZ
      }
      /* start processing requests */
      apis = new KafkaApis(socketServer.requestChannel, replicaManager, adminManager, groupCoordinator,
        kafkaController, zkUtils, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers, clusterId)
      // 就是它去处理队列里面的请求的
      requestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.requestChannel, apis, config.numIoThreads)
      Mx4jLoader.maybeLoad()
      /* start dynamic config manager */
      dynamicConfigHandlers = Map[String, ConfigHandler](ConfigType.Topic -> new TopicConfigHandler(logManager, config, quotaManagers),
                                                         ConfigType.Client -> new ClientIdConfigHandler(quotaManagers),
                                                         ConfigType.User -> new UserConfigHandler(quotaManagers),
                                                         ConfigType.Broker -> new BrokerConfigHandler(config, quotaManagers))
      // Create the config manager. start listening to notifications
      dynamicConfigManager = new DynamicConfigManager(zkUtils, dynamicConfigHandlers)
      dynamicConfigManager.startup()
      /* tell everyone we are alive */
      val listeners = config.advertisedListeners.map {case(protocol, endpoint) =>
        if (endpoint.port == 0)
          (protocol, EndPoint(endpoint.host, socketServer.boundPort(protocol), endpoint.protocolType))
        else
          (protocol, endpoint)
      }
      // 这儿就是每个broker完成注册的代码
      kafkaHealthcheck = new KafkaHealthcheck(config.brokerId, listeners, zkUtils, config.rack,
        config.interBrokerProtocolVersion)
      kafkaHealthcheck.startup()
      // Now that the broker id is successfully registered via KafkaHealthcheck, checkpoint it
      checkpointBrokerId(config.brokerId)
      /* register broker metrics */
      registerStats()
      brokerState.newState(RunningAsBroker)
      shutdownLatch = new CountDownLatch(1)
      startupComplete.set(true)
      isStartingUp.set(false)
      AppInfoParser.registerAppInfo(jmxPrefix, config.brokerId.toString)
      info("started")
    }
  }
  catch {
    case e: Throwable =>
      fatal("Fatal error during KafkaServer startup. Prepare to shutdown", e)
      isStartingUp.set(false)
      shutdown()
      throw e
  }
}
```

## ZkUtils 工具类初始化
可以看到initZk（）最终返回了一个ZkUtils 工具类，其作用是读取 kafka 配置文件中的 zookeeper 配置，用来操作 zookeeper 集群。
```
object ZkUtils {
  val ConsumersPath = "/consumers"
  val ClusterIdPath = "/cluster/id"
  val BrokerIdsPath = "/brokers/ids"
  val BrokerTopicsPath = "/brokers/topics"
  val ControllerPath = "/controller"
  val ControllerEpochPath = "/controller_epoch"
  val ReassignPartitionsPath = "/admin/reassign_partitions"
  val DeleteTopicsPath = "/admin/delete_topics"
  val PreferredReplicaLeaderElectionPath = "/admin/preferred_replica_election"
  val BrokerSequenceIdPath = "/brokers/seqid"
  val IsrChangeNotificationPath = "/isr_change_notification"
  val EntityConfigPath = "/config"
  val EntityConfigChangesPath = "/config/changes"
  ......
  }
```

初始化 ZkUtils：
```
private def initZk(): ZkUtils = {
  info(s"Connecting to zookeeper on ${config.zkConnect}")
  //这些都是读取的我们之前的配置文件里面的参数
  val chrootIndex = config.zkConnect.indexOf("/")
  val chrootOption = {
    if (chrootIndex > 0) Some(config.zkConnect.substring(chrootIndex))
    else None
  }
  val secureAclsEnabled = config.zkEnableSecureAcls
  val isZkSecurityEnabled = JaasUtils.isZkSecurityEnabled()
  if (secureAclsEnabled && !isZkSecurityEnabled)
    throw new java.lang.SecurityException(s"${KafkaConfig.ZkEnableSecureAclsProp} is true, but the verification of the JAAS login file failed.")
  chrootOption.foreach { chroot =>
    val zkConnForChrootCreation = config.zkConnect.substring(0, chrootIndex)
    val zkClientForChrootCreation = ZkUtils(zkConnForChrootCreation,
                                            config.zkSessionTimeoutMs,
                                            config.zkConnectionTimeoutMs,
                                            secureAclsEnabled)
    zkClientForChrootCreation.makeSurePersistentPathExists(chroot)
    info(s"Created zookeeper path $chroot")
    zkClientForChrootCreation.zkClient.close()
  }
  //实例化 ZkUtils 对象
  val zkUtils = ZkUtils(config.zkConnect,
                        config.zkSessionTimeoutMs,
                        config.zkConnectionTimeoutMs,
                        secureAclsEnabled)
  zkUtils.setupCommonPaths()
  zkUtils
}
```

## LogManager 初始化
```
logManager = createLogManager(zkUtils.zkClient, brokerState)
logManager.startup()
```
首先是实例化了 LogManager。
```
private def createLogManager(zkClient: ZkClient, brokerState: BrokerState): LogManager = {
  //解析配置文件里面的参数
  val defaultProps = KafkaServer.copyKafkaConfigToLog(config)
  val defaultLogConfig = LogConfig(defaultProps)
 
  val configs = AdminUtils.fetchAllTopicConfigs(zkUtils).map { case (topic, configs) =>
    topic -> LogConfig.fromProps(defaultProps, configs)
  }
  // read the log configurations from zookeeper
  val cleanerConfig = CleanerConfig(numThreads = config.logCleanerThreads,
                                    dedupeBufferSize = config.logCleanerDedupeBufferSize,
                                    dedupeBufferLoadFactor = config.logCleanerDedupeBufferLoadFactor,
                                    ioBufferSize = config.logCleanerIoBufferSize,
                                    maxMessageSize = config.messageMaxBytes,
                                    maxIoBytesPerSecond = config.logCleanerIoMaxBytesPerSecond,
                                    backOffMs = config.logCleanerBackoffMs,
                                    enableCleaner = config.logCleanerEnable)
  //创建对象
  //logDirs 通常情况下会对应多个目录（生产环境里面）
  new LogManager(logDirs = config.logDirs.map(new File(_)).toArray,
                 topicConfigs = configs,
                 defaultConfig = defaultLogConfig,
                 cleanerConfig = cleanerConfig,
                 ioThreads = config.numRecoveryThreadsPerDataDir,
                 flushCheckMs = config.logFlushSchedulerIntervalMs,
                 flushCheckpointMs = config.logFlushOffsetCheckpointIntervalMs,
                 retentionCheckMs = config.logCleanupIntervalMs,
                 scheduler = kafkaScheduler,
                 brokerState = brokerState,
                 time = time)
}
```
然后启动 LogManager，通过定时任务刷写日志，以及清理过期日志。
```
/**
 *  Start the background threads to flush logs and do log cleanup
 */
 //启动后台线程用于刷写日志以及清理日志
def startup() {
  //定时调度了三个任务
  /* Schedule the cleanup task to delete old logs */
  if(scheduler != null) {
    info("Starting log cleanup with a period of %d ms.".format(retentionCheckMs))
    // 1）定时检查文件，清理过期的文件。
    scheduler.schedule("kafka-log-retention",
                       cleanupLogs,
                       delay = InitialTaskDelayMs,
                       period = retentionCheckMs,
                       TimeUnit.MILLISECONDS)
    info("Starting log flusher with a default period of %d ms.".format(flushCheckMs))
    // 2）定时把内存里面的数据刷写到磁盘
    scheduler.schedule("kafka-log-flusher",
                       flushDirtyLogs,
                       delay = InitialTaskDelayMs,
                       period = flushCheckMs,
                       TimeUnit.MILLISECONDS)
    //定时更新一个检查点的文件，Kafka服务重启的时候恢复数据使用。
    scheduler.schedule("kafka-recovery-point-checkpoint",
                       checkpointRecoveryPointOffsets,
                       delay = InitialTaskDelayMs,
                       period = flushCheckpointMs,
                       TimeUnit.MILLISECONDS)
  }
  if(cleanerConfig.enableCleaner)
    cleaner.startup()
}
```

## SocketServer 初始化
```
//实例化 SocketServer
socketServer = new SocketServer(config, metrics, kafkaMetricsTime)
//启动 SocketServer
socketServer.startup()
```
启动完 LogManger 之后就创建 SocketServer对象，本身就是 NIO socket 服务端，线程的模型是基于 Acceptor，一个 Acceptor 线程用于接受并处理所有的新连接，每个Acceptor对应多个Processor线程，每个Processor线程拥有自己的Selector，主要用于从连接中读取请求和写回响应。
```
/**
 * An NIO socket server. The threading model is
 *   1 Acceptor thread that handles new connections
 *   Acceptor has N Processor threads that each have their own selector and read requests from sockets
 *   M Handler threads that handle requests and produce responses back to the processor threads for writing.
 */
class SocketServer(val config: KafkaConfig, val metrics: Metrics, val time: Time) extends Logging with KafkaMetricsGroup {
 
  private val endpoints = config.listeners
  private val numProcessorThreads = config.numNetworkThreads
  private val maxQueuedRequests = config.queuedMaxRequests
  private val totalProcessorThreads = numProcessorThreads * endpoints.size
 
  private val maxConnectionsPerIp = config.maxConnectionsPerIp
  private val maxConnectionsPerIpOverrides = config.maxConnectionsPerIpOverrides
 
  this.logIdent = "[Socket Server on Broker " + config.brokerId + "], "
 
  val requestChannel = new RequestChannel(totalProcessorThreads, maxQueuedRequests)
  private val processors = new Array[Processor](totalProcessorThreads)
 
  private[network] val acceptors = mutable.Map[EndPoint, Acceptor]()
  private var connectionQuotas: ConnectionQuotas = _
 
  private val allMetricNames = (0 until totalProcessorThreads).map { i =>
    val tags = new util.HashMap[String, String]()
    tags.put("networkProcessor", i.toString)
    metrics.metricName("io-wait-ratio", "socket-server-metrics", tags)
  }
```
然后就启动 SocketServer 服务端。
```
/**
 * Start the socket server
 */
def startup() {
  this.synchronized {
 
    connectionQuotas = new ConnectionQuotas(maxConnectionsPerIp, maxConnectionsPerIpOverrides)
    // Socket 发送请求缓存的大小
    val sendBufferSize = config.socketSendBufferBytes
    //Socket 接收请求缓存的大小
    val recvBufferSize = config.socketReceiveBufferBytes
    //当前broker主机的id
    val brokerId = config.brokerId
 
    var processorBeginIndex = 0
 
    /**
     * Kafka
     *
     */
    //遍历endpoints列表
    //listeners = PLAINTEXT://your.host.name:9092
    endpoints.values.foreach { endpoint =>
      val protocol = endpoint.protocolType
      //numProcessorThreads 等同于num.network.threads配置，默认是3
      val processorEndIndex = processorBeginIndex + numProcessorThreads
      
      for (i <- processorBeginIndex until processorEndIndex)
        //创建了三个Processor的线程
        processors(i) = newProcessor(i, connectionQuotas, protocol)
      // 创建Acceptor，同时为processor创建对应的线程
      val acceptor = new Acceptor(endpoint, sendBufferSize, recvBufferSize, brokerId,
        processors.slice(processorBeginIndex, processorEndIndex), connectionQuotas)
        
      acceptors.put(endpoint, acceptor)
      // 创建Acceptor对应的线程，并启动
      Utils.newThread("kafka-socket-acceptor-%s-%d".format(protocol.toString, endpoint.port), acceptor, false).start()
      // 主线程阻塞等待Acceptor线程启动完成
      acceptor.awaitStartup()
      // 修改processorBeginIndex，为下一个Endpint准备
      processorBeginIndex = processorEndIndex
    }
  }
 
  newGauge("NetworkProcessorAvgIdlePercent",
    new Gauge[Double] {
      def value = allMetricNames.map( metricName =>
        metrics.metrics().get(metricName).value()).sum / totalProcessorThreads
    }
  )
 
  info("Started " + acceptors.size + " acceptor threads")
}
```





























