---
layout: post
categories: [Hadoop]
description: none
keywords: Hadoop
---
# Hadoop简介
Apache Hadoop本身是一个框架，它可以用简单的编程模型在计算机集群中对大型数据集进行分布式处理。它可以被设计成单个机器或成千上万台机器的集群，实现提供计算和存储服务。

## Hadoop简介与意义
Hadoop是Apache软件基金会旗下的一个开源分布式计算平台。用于大数据存储、计算、分析的分布式存储和分布式运算。
Hadoop的两大核心如下。
- HDFS（Hadoop Distributed File System，分布式存储系统）：是Hadoop中的核心组件之一，除了可以保存海量数据，还具有高可靠性、高扩展性和高吞吐率的特点。
- MapReduce：属于分布式计算框架，一般用于对海量数据的计算，它的特点是易于编程、高容错和高扩展等优点。另外，MapReduce可以独立于HDFS使用。

总结来说，Hadoop中的核心HDFS为海量数据提供了存储，而MapReduce则为海量数据提供了计算服务。

通过Hadoop可以快速搭建自己的分布式存储系统和分布式运算系统，它可以缩短处理数据的时间，同时可以尽量在低成本的情况下完成数据的分析与挖掘。这里说的低成本，主要是因为Hadoop可以基于廉价的普通PC机搭建集群。

## Hadoop的历史
Hadoop的源头是Apache Nutch，该项目始于2002年，是Apache Lucene的子项目之一。
2004年，Google在“操作系统设计与实现”（Operating System Design and Implementation, OSDI）会议上公开发表了题为MapReduce：Simplifed Data Processing on Large Clusters（《MapReduce：简化大规模集群上的数据处理》）的论文之后，受到启发的Doug Cutting等人开始尝试实现MapReduce计算框架，并将它与NDFS（Nutch Distributed File System）结合，用以支持Nutch引擎的主要算法。由于NDFS和MapReduce在Nutch引擎中有着良好的应用，所以它们于2006年2月被分离出来，成为一套完整而独立的软件，并命名为Hadoop。
到了2008年年初，Hadoop已成为Apache的顶级项目，包含众多子项目。它被应用到包括Yahoo！在内的很多互联网公司。Hadoop1.0.1版本已经发展成为包含HDFS、MapReduce子项目，与Pig、ZooKeeper、Hive、HBase等项目相关的大型应用工程。

## Hadoop的优势
Hadoop是一个能够让用户轻松架构和使用的分布式计算平台。用户可以轻松地在Hadoop上开发运行处理海量数据的应用程序。它主要有以下几个优点：
- 高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。
- 高扩展性。Hadoop是在可用的计算机集簇间分配数据完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。
- 高效性。Hadoop能够在节点之间动态地移动数据，以保证各个节点的动态平衡，因此其处理速度非常快。
- 高容错性。Hadoop能够自动保存数据的多份副本，并且能够自动将失败的任务重新分配。

## Hadoop项目及其结构
现在Hadoop已经发展成为包含很多项目的集合。虽然其核心内容是MapReduce和Hadoop分布式文件系统，但与Hadoop相关的Common、Avro、Chukwa、Hive、HBase等项目也是不可或缺的。它们提供了互补性服务或在核心层上提供了更高层的服务。

下面将对Hadoop的各个关联项目进行更详细的介绍。
- Common：
Common：Common是为Hadoop其他子项目提供支持的常用工具，它主要包括FileSystem、RPC和串行化库。它们为在廉价硬件上搭建云计算环境提供基本的服务，并且会为运行在该平台上的软件开发提供所需的API。
- Avro
Avro：Avro是用于数据序列化的系统。它提供了丰富的数据结构类型、快速可压缩的二进制数据格式、存储持久性数据的文件集、远程调用RPC的功能和简单的动态语言集成功能。其中代码生成器既不需要读写文件数据，也不需要使用或实现RPC协议，它只是一个可选的对静态类型语言的实现。
Avro系统依赖于模式（Schema），数据的读和写是在模式之下完成的。这样可以减少写入数据的开销，提高序列化的速度并缩减其大小；同时，也可以方便动态脚本语言的使用，因为数据连同其模式都是自描述的。
在RPC中，Avro系统的客户端和服务端通过握手协议进行模式的交换，因此当客户端和服务端拥有彼此全部的模式时，不同模式下相同命名字段、丢失字段和附加字段等信息的一致性问题就得到了很好的解决。
- MapReduce
MapReduce：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。映射（Map）、化简（Reduce）的概念和它们的主要思想都是从函数式编程语言中借鉴而来的。它极大地方便了编程人员—即使在不了解分布式并行编程的情况下，也可以将自己的程序运行在分布式系统上。MapReduce在执行时先指定一个Map（映射）函数，把输入键值对映射成一组新的键值对，经过一定处理后交给Reduce, Reduce对相同key下的所有value进行处理后再输出键值对作为最终的结果。
- HDFS
HDFS：HDFS是一个分布式文件系统。因为HDFS具有高容错性（fault-tolerent）的特点，所以它可以设计部署在低廉（low-cost）的硬件上。它可以通过提供高吞吐率（high throughput）来访问应用程序的数据，适合那些有着超大数据集的应用程序。HDFS放宽了对可移植操作系统接口（POSIX, Portable Operating System Interface）的要求，这样可以实现以流的形式访问文件系统中的数据。HDFS原本是开源的Apache项目Nutch的基础结构，最后它却成为了Hadoop基础架构之一。
- Chukwa
Chukwa：Chukwa是开源的数据收集系统，用于监控和分析大型分布式系统的数据。Chukwa是在Hadoop的HDFS和MapReduce框架之上搭建的，它继承了Hadoop的可扩展性和健壮性。Chukwa通过HDFS来存储数据，并依赖MapReduce任务处理数据。Chukwa中也附带了灵活且强大的工具，用于显示、监视和分析数据结果，以便更好地利用所收集的数据。
- Hive
Hive：Hive最早是由Facebook设计的，是一个建立在Hadoop基础之上的数据仓库，它提供了一些用于对Hadoop文件中的数据集进行数据整理、特殊查询和分析存储的工具。Hive提供的是一种结构化数据的机制，它支持类似于传统RDBMS中的SQL语言的查询语言，来帮助那些熟悉SQL的用户查询Hadoop中的数据，该查询语言称为Hive QL。与此同时，传统的MapReduce编程人员也可以在Mapper或Reducer中通过Hive QL查询数据。Hive编译器会把Hive QL编译成一组MapReduce任务，从而方便MapReduce编程人员进行Hadoop系统开发。
- HBase
HBase：HBase是一个分布式的、面向列的开源数据库，该技术来源于Google论文《Bigtable：一个结构化数据的分布式存储系统》。如同Bigtable利用了Google文件系统（Google File System）提供的分布式数据存储方式一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase不同于一般的关系数据库，原因有两个：其一，HBase是一个适合于非结构化数据存储的数据库；其二，HBase是基于列而不是基于行的模式。HBase和Bigtable使用相同的数据模型。用户将数据存储在一个表里，一个数据行拥有一个可选择的键和任意数量的列。由于HBase表是疏松的，用户可以为行定义各种不同的列。HBase主要用于需要随机访问、实时读写的大数据（Big Data）。具体介绍请参考第12章。
- Pig
Pig：Pig是一个对大型数据集进行分析、评估的平台。Pig最突出的优势是它的结构能够经受住高度并行化的检验，这个特性使得它能够处理大型的数据集。目前，Pig的底层由一个编译器组成，它在运行的时候会产生一些MapReduce程序序列，Pig的语言层由一种叫做Pig Latin的正文型语言组成。有关Pig的具体内容请参考第14章。
- ZooKeeper
ZooKeeper：ZooKeeper是一个为分布式应用所设计的开源协调服务。它主要为用户提供同步、配置管理、分组和命名等服务，减轻分布式应用程序所承担的协调任务。ZooKeeper的文件系统使用了我们所熟悉的目录树结构。ZooKeeper是使用Java编写的，但是它支持Java和C两种编程语言。有关ZooKeeper的具体内容请参考第15章。

## Hadoop体系结构
HDFS和MapReduce是Hadoop的两大核心。而整个Hadoop的体系结构主要是通过HDFS来实现分布式存储的底层支持的，并且它会通过MapReduce来实现分布式并行任务处理的程序支持。

下面首先介绍HDFS的体系结构。HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。HDFS允许用户以文件的形式存储数据。从内部来看，文件被分成若干个数据块，而且这若干个数据块存放在一组DataNode上。NameNode执行文件系统的命名空间操作，比如打开、关闭、重命名文件或目录等，它也负责数据块到具体DataNode的映射。DataNode负责处理文件系统客户端的文件读写请求，并在NameNode的统一调度下进行数据块的创建、删除和复制工作。

NameNode和DataNode都可以在普通商用计算机上运行。这些计算机通常运行的是GNU/Linux操作系统。HDFS采用Java语言开发，因此任何支持Java的机器都可以部署NameNode和DataNode。一个典型的部署场景是集群中的一台机器运行一个NameNode实例，其他机器分别运行一个DataNode实例。当然，并不排除一台机器运行多个DataNode实例的情况。集群中单一NameNode的设计大大简化了系统的架构。NameNode是所有HDFS元数据的管理者，用户需要保存的数据不会经过NameNode，而是直接流向存储数据的DataNode。

接下来介绍MapReduce的体系结构。MapReduce是一种并行编程模式，利用这种模式软件开发者可以轻松地编写出分布式并行程序。在Hadoop的体系结构中，MapReduce是一个简单易用的软件框架，基于它可以将任务分发到由上千台商用机器组成的集群上，并以一种可靠容错的方式并行处理大量的数据集，实现Hadoop的并行任务处理功能。MapReduce框架是由一个单独运行在主节点的JobTracker和运行在每个集群从节点的TaskTracker共同组成的。主节点负责调度构成一个作业的所有任务，这些任务分布在不同的从节点上。主节点监控它们的执行情况，并且重新执行之前失败的任务；从节点仅负责由主节点指派的任务。当一个Job被提交时，JobTracker接收到提交作业和其配置信息之后，就会将配置信息等分发给从节点，同时调度任务并监控TaskTracker的执行。

从上面的介绍可以看出，HDFS和MapReduce共同组成了Hadoop分布式系统体系结构的核心。HDFS在集群上实现了分布式文件系统，MapReduce在集群上实现了分布式计算和任务处理。HDFS在MapReduce任务处理过程中提供了对文件操作和存储等的支持，MapReduce在HDFS的基础上实现了任务的分发、跟踪、执行等工作，并收集结果，二者相互作用，完成了Hadoop分布式集群的主要任务。

## Hadoop与分布式开发
我们通常所说的分布式系统其实是分布式软件系统，即支持分布式处理的软件系统。它是在通信网络互联的多处理机体系结构上执行任务的系统，包括分布式操作系统、分布式程序设计语言及其编译（解释）系统、分布式文件系统和分布式数据库系统等。Hadoop是分布式软件系统中文件系统层的软件，它实现了分布式文件系统和部分分布式数据库系统的功能。Hadoop中的分布式文件系统HDFS能够实现数据在计算机集群组成的云上高效的存储和管理，Hadoop中的并行编程框架MapReduce能够让用户编写的Hadoop并行应用程序运行得以简化。

Hadoop上并行应用程序的开发是基于MapReduce编程模型的。MapReduce编程模型的原理是：利用一个输入的key/value对集合来产生一个输出的key/value对集合。MapReduce库的用户用两个函数来表达这个计算：Map和Reduce。 用户自定义的Map函数接收一个输入的key/value对，然后产生一个中间key/value对的集合。MapReduce把所有具有相同key值的value集合在一起，然后传递给Reduce函数。用户自定义的Reduce函数接收key和相关的value集合。Reduce函数合并这些value值，形成一个较小的value集合。一般来说，每次调用Reduce函数只产生0或1个输出的value值。通常我们通过一个迭代器把中间value值提供给Reduce函数，这样就可以处理无法全部放入内存中的大量的value值集合了。

简而言之，这个过程就是将大数据集分解为成百上千个小数据集，每个（或若干个）数据集分别由集群中的一个节点（一般就是一台普通的计算机）进行处理并生成中间结果，然后这些中间结果又由大量的节点合并，形成最终结果。MapReduce框架下并行程序中的两个主要函数：Map、Reduce。在这个结构中，用户需要完成的工作是根据任务编写Map和Reduce两个函数。

那么这样的并行计算是如何做到的呢？下面将简单介绍一下其原理。
- 数据分布存储
Hadoop分布式文件系统（HDFS）由一个名字节点（NameNode）和多个数据节点（DataNode）组成，每个节点都是一台普通的计算机。在使用方式上HDFS与我们熟悉的单机文件系统非常类似，利用它可以创建目录，创建、复制、删除文件，并且可以查看文件内容等。但文件在HDFS底层被切割成了Block，这些Block分散地存储在不同的DataNode上，每个Block还可以复制数份数据存储在不同的DataNode上，达到容错容灾的目的。NameNode则是整个HDFS的核心，它通过维护一些数据结构来记录每一个文件被切割成了多少个Block、这些Block可以从哪些DataNode中获得，以及各个DataNode的状态等重要信息。
- 分布式并行计算
Hadoop中有一个作为主控的JobTracker，用于调度和管理其他的TaskTracker。JobTracker可以运行于集群中的任意一台计算机上；TaskTracker则负责执行任务，它必须运行于DataNode上，也就是说DataNode既是数据存储节点，也是计算节点。JobTracker将Map任务和Reduce任务分发给空闲的TaskTracker，让这些任务并行运行，并负责监控任务的运行情况。如果某一个TaskTracker出了故障，JobTracker会将其负责的任务转交给另一个空闲的TaskTracker重新运行。
- 本地计算
数据存储在哪一台计算机上，就由哪台计算机进行这部分数据的计算，这样可以减少数据在网络上的传输，降低对网络带宽的需求。在Hadoop这类基于集群的分布式并行系统中，计算节点可以很方便地扩充，因此它所能够提供的计算能力近乎无限。但是数据需要在不同的计算机之间流动，故而网络带宽变成了瓶颈。“本地计算”是一种最有效的节约网络带宽的手段，业界将此形容为“移动计算比移动数据更经济”。
- 任务粒度
在把原始大数据集切割成小数据集时，通常让小数据集小于或等于HDFS中一个Block的大小（默认是64MB），这样能够保证一个小数据集是位于一台计算机上的，便于本地计算。假设有M个小数据集待处理，就启动M个Map任务，注意这M个Map任务分布于N台计算机上，它们将并行运行，Reduce任务的数量R则可由用户指定。
- 数据分割（Partition）
把Map任务输出的中间结果按key的范围划分成R份（R是预先定义的Reduce任务的个数），划分时通常使用Hash函数（如hash（key）mod R），这样可以保证某一段范围内的key一定是由一个Reduce任务来处理的，可以简化Reduce的过程。
- 数据合并（Combine）
在数据分割之前，还可以先对中间结果进行数据合并（Combine），即将中间结果中有相同key的＜key, value＞对合并成一对。Combine的过程与Reduce的过程类似，在很多情况下可以直接使用Reduce函数，但Combine是作为Map任务的一部分、在执行完Map函数后紧接着执行的。Combine能够减少中间结果中＜key, value＞对的数目，从而降低网络流量。
- Reduce
Map任务的中间结果在执行完Combine和Partition之后，以文件形式存储于本地磁盘上。中间结果文件的位置会通知主控JobTracker, JobTracker再通知Reduce任务到哪一个TaskTracker上去取中间结果。注意，所有的Map任务产生的中间结果均按其key值通过同一个Hash函数划分成了R份，R个Reduce任务各自负责一段key区间。每个Reduce需要向许多个Map任务节点取得落在其负责的key区间内的中间结果，然后执行Reduce函数，形成一个最终的结果文件。
- 任务管道
有R个Reduce任务，就会有R个最终结果。很多情况下这R个最终结果并不需要合并成一个最终结果，因为这R个最终结果又可以作为另一个计算任务的输入，开始另一个并行计算任务，这也就形成了任务管道。

## Hadoop计算模型—MapReduce
MapReduce是Google公司的核心计算模型，它将运行于大规模集群上的复杂的并行计算过程高度地抽象为两个函数：Map和Reduce。Hadoop是Doug Cutting受到Google发表的关于MapReduce的论文启发而开发出来的。Hadoop中的MapReduce是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千台商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集，实现了Hadoop在集群上的数据和任务的并行计算与处理。

一个Map/Reduce作业（Job）通常会把输入的数据集切分为若干独立的数据块，由Map任务（Task）以完全并行的方式处理它们。框架会先对Map的输出进行排序，然后把结果输入给Reduce任务。通常作业的输入和输出都会被存储在文件系统中。整个框架负责任务的调度和监控，以及重新执行已经失败的任务。

通常，Map/Reduce框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点在一起。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这样可以使整个集群的网络带宽得到非常高效的利用。

Map/Reduce框架由一个单独的Master JobTracker和集群节点上的Slave TaskTracker共同组成。Master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上。Master监控它们的执行情况，并重新执行已经失败的任务，而Slave仅负责执行由Master指派的任务。

在Hadoop上运行的作业需要指明程序的输入/输出位置（路径），并通过实现合适的接口或抽象类提供Map和Reduce函数。同时还需要指定作业的其他参数，构成作业配置（Job Configuration）。在Hadoop的JobClient提交作业（JAR包/可执行程序等）和配置信息给JobTracker之后，JobTracker会负责分发这些软件和配置信息给slave及调度任务，并监控它们的执行，同时提供状态和诊断信息给JobClient。

## Hadoop数据管理

## HDFS的数据管理
HDFS是分布式计算的存储基石，Hadoop分布式文件系统和其他分布式文件系统有很多类似的特性：
- 对于整个集群有单一的命名空间；
- 具有数据一致性，都适合一次写入多次读取的模型，客户端在文件没有被成功创建之前是无法看到文件存在的；
- 文件会被分割成多个文件块，每个文件块被分配存储到数据节点上，而且会根据配置由复制文件块来保证数据的安全性。
HDFS通过三个重要的角色来进行文件系统的管理：NameNode、DataNode和Client。NameNode可以看做是分布式文件系统中的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。NameNode会将文件系统的Metadata存储在内存中，这些信息主要包括文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode中的信息等。DataNode是文件存储的基本单元，它将文件块（Block）存储在本地文件系统中，保存了所有Block的Metadata，同时周期性地将所有存在的Block信息发送给NameNode。Client就是需要获取分布式文件系统文件的应用程序。接下来通过三个具体的操作来说明HDFS对数据的管理。
- 文件写入
1）Client向NameNode发起文件写入的请求。
2）NameNode根据文件大小和文件块配置情况，返回给Client所管理的DataNode的信息。
3）Client将文件划分为多个Block，根据DataNode的地址信息，按顺序将其写入到每一个DataNode块中。
- 文件读取
1）Client向NameNode发起文件读取的请求。
2）NameNode返回文件存储的DataNode信息。
3）Client读取文件信息。
- 文件块（Block）复制
1）NameNode发现部分文件的Block不符合最小复制数这一要求或部分DataNode失效。
2）通知DataNode相互复制Block。
3）DataNode开始直接相互复制。

作为分布式文件系统，HDFS在数据管理方面还有值得借鉴的几个功能：

文件块（Block）的放置：一个Block会有三份备份，一份放在NameNode指定的DataNode上，另一份放在与指定DataNode不在同一台机器上的DataNode上，最后一份放在与指定DataNode同一Rack的DataNode上。备份的目的是为了数据安全，采用这种配置方式主要是考虑同一Rack失败的情况，以及不同Rack之间进行数据复制会带来的性能问题。
心跳检测：用心跳检测DataNode的健康状况，如果发现问题就采取数据备份的方式来保证数据的安全性。
数据复制（场景为DataNode失败、需要平衡DataNode的存储利用率和平衡DataNode数据交互压力等情况）：使用Hadoop时可以用HDFS的balancer命令配置Threshold来平衡每一个DataNode的磁盘利用率。假设设置了Threshold为10%，那么执行balancer命令时，首先会统计所有DataNode的磁盘利用率的平均值，然后判断如果某一个DataNode的磁盘利用率超过这个平均值，那么将会把这个DataNode的Block转移到磁盘利用率低的DataNode上，这对于新节点的加入十分有用。
数据校验：采用CRC32做数据校验。在写入文件块的时候，除了会写入数据外还会写入校验信息，在读取的时候则需要先校验后读入。

单个NameNode：如果单个NameNode失败，任务处理信息将会记录在本地文件系统和远端的文件系统中。
数据管道性的写入：当客户端要写入文件到DataNode上时，首先会读取一个Block，然后将其写到第一个DataNode上，接着由第一个DataNode将其传递到备份的DataNode上，直到所有需要写入这个Block的DataNode都成功写入后，客户端才会开始写下一个Block。
安全模式：分布式文件系统启动时会进入安全模式（系统运行期间也可以通过命令进入安全模式），当分布式文件系统处于安全模式时，文件系统中的内容不允许修改也不允许删除，直到安全模式结束。安全模式主要是为了在系统启动的时候检查各个DataNode上数据块的有效性，同时根据策略进行必要的复制或删除部分数据块。在实际操作过程中，如果在系统启动时修改和删除文件会出现安全模式不允许修改的错误提示，只需要等待一会儿即可。

## HBase的数据管理
HBase是一个类似Bigtable的分布式数据库，它的大部分特性和Bigtable一样，是一个稀疏的、长期存储的（存在硬盘上）、多维度的排序映射表，这张表的索引是行关键字、列关键字和时间戳。表中的每个值是一个纯字符数组，数据都是字符串，没有类型。用户在表格中存储数据，每一行都有一个可排序的主键和任意多的列。由于是稀疏存储的，所以同一张表中的每一行数据都可以有截然不同的列。列名字的格式是“＜family＞：＜label＞”，它是由字符串组成的，每一张表有一个family集合，这个集合是固定不变的，相当于表的结构，只能通过改变表结构来改变表的family集合。但是label值相对于每一行来说都是可以改变的。
HBase把同一个family中的数据存储在同一个目录下，而HBase的写操作是锁行的，每一行都是一个原子元素，都可以加锁。所有数据库的更新都有一个时间戳标记，每次更新都会生成一个新的版本，而HBase会保留一定数量的版本，这个值是可以设定的。客户端可以选择获取距离某个时间点最近的版本，或者一次获取所有版本。
以上从微观上介绍了HBase的一些数据管理措施。那么HBase作为分布式数据库在整体上从集群出发又是如何管理数据的呢？

HBase在分布式集群上主要依靠由HRegion、HMaster、HClient组成的体系结构从整体上管理数据。

HBase体系结构有三大重要组成部分：
- HBaseMaster：HBase主服务器，与Bigtable的主服务器类似。
- HRegionServer：HBase域服务器，与Bigtable的Tablet服务器类似。
- HBase Client：HBase客户端是由org.apache.hadoop.HBase.client.HTable定义的。

下面将对这三个组件进行详细的介绍。
- HBaseMaster
一个HBase只部署一台主服务器，它通过领导选举算法（Leader Election Algorithm）确保只有唯一的主服务器是活跃的，ZooKeeper保存主服务器的服务器地址信息。如果主服务器瘫痪，可以通过领导选举算法从备用服务器中选择新的主服务器。
主服务器承担着初始化集群的任务。当主服务器第一次启动时，会试图从HDFS获取根或根域目录，如果获取失败则创建根或根域目录，以及第一个元域目录。在下次启动时，主服务器就可以获取集群和集群中所有域的信息了。同时主服务器还负责集群中域的分配、域服务器运行状态的监视、表格的管理等工作。
- HRegionServer
HBase域服务器的主要职责有服务于主服务器分配的域、处理客户端的读写请求、本地缓冲区回写、本地数据压缩和分割域等功能。
每个域只能由一台域服务器来提供服务。当它开始服务于某域时，它会从HDFS文件系统中读取该域的日志和所有存储文件，同时还会管理操作HDFS文件的持久性存储工作。客户端通过与主服务器通信获取域和域所在域服务器的列表信息后，就可以直接向域服务器发送域读写请求，来完成操作。
- HBaseClient
HBase客户端负责查找用户域所在的域服务器地址。HBase客户端会与HBase主机交换消息以查找根域的位置，这是两者之间唯一的交流。
定位根域后，客户端连接根域所在的域服务器，并扫描根域获取元域信息。元域信息中包含所需用户域的域服务器地址。客户端再连接元域所在的域服务器，扫描元域以获取所需用户域所在的域服务器地址。定位用户域后，客户端连接用户域所在的域服务器并发出读写请求。用户域的地址将在客户端被缓存，后续的请求无须重复上述过程。
综上所述，在HBase的体系结构中，HBase主要由主服务器、域服务器和客户端三部分组成。主服务器作为HBase的中心，管理整个集群中的所有域，监控每台域服务器的运行情况等；域服务器接收来自服务器的分配域，处理客户端的域读写请求并回写映射文件等；客户端主要用来查找用户域所在的域服务器地址信息。

## Hive的数据管理
Hive是建立在Hadoop上的数据仓库基础构架。它提供了一系列的工具，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。Hive定义了简单的类SQL的查询语言，称为Hive QL，它允许熟悉SQL的用户用SQL语言查询数据。作为一个数据仓库，Hive的数据管理按照使用层次可以从元数据存储、数据存储和数据交换三方面来介绍。
- 元数据存储
Hive将元数据存储在RDBMS中，有三种模式可以连接到数据库：
Single User Mode：此模式连接到一个In-memory的数据库Derby，一般用于Unit Test。
Multi User Mode：通过网络连接到一个数据库中，这是最常用的模式。
Remote Server Mode：用于非Java客户端访问元数据库，在服务器端启动一个。
MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer来访问元数据库。
- 数据存储
首先，Hive没有专门的数据存储格式，也没有为数据建立索引，用户可以非常自由地组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符，它就可以解析数据了。
其次，Hive中所有的数据都存储在HDFS中，Hive中包含4种数据模型：Table、External Table、Partition和Bucket。
Hive中的Table和数据库中的Table在概念上是类似的，每一个Table在Hive中都有一个相应的目录来存储数据。例如，一个表pvs，它在HDFS中的路径为：/wh/pvs，其中，wh是在hive-site.xml中由${hive.metastore.warehouse.dir}指定的数据仓库的目录，所有的Table数据（不包括External Table）都保存在这个目录中。
- 数据交换
用户接口：包括客户端、Web界面和数据库接口。
元数据存储：通常存储在关系数据库中，如MySQL、Derby等。
解释器、编译器、优化器、执行器。
Hadoop：利用HDFS进行存储，利用MapReduce进行计算。
用户接口主要有三个：客户端、数据库接口和Web界面，其中最常用的是客户端。Client是Hive的客户端，当启动Client模式时，用户会想要连接Hive Server，这时需要指出Hive Server所在的节点，并且在该节点启动HiveServer。Web界面是通过浏览器访问Hive的。
Hive将元数据存储在数据库中，如MySQL、Derby中。Hive中的元数据包括表的名字、表的列、表的分区、表分区的属性、表的属性（是否为外部表等）、表的数据所在目录等。
解释器、编译器、优化器完成Hive QL查询语句从词法分析、语法分析、编译、优化到查询计划的生成。生成的查询计划存储在HDFS中，并且随后由MapReduce调用执行。
Hive的数据存储在HDFS中，大部分的查询由MapReduce完成（包含*的查询不会生成MapRedcue任务，比如select*from tbl）。
以上从Hadoop的分布式文件系统HDFS、分布式数据库HBase和数据仓库工具Hive入手介绍了Hadoop的数据管理，它们都通过自己的数据定义、体系结构实现了数据从宏观到微观的立体化管理，完成了Hadoop平台上大规模的数据存储和任务处理。

## Hadoop集群安全策略
众所周知，Hadoop的优势在于其能够将廉价的普通PC组织成能够高效稳定处理事务的大型集群，企业正是利用这一特点来构架Hadoop集群、获取海量数据的高效处理能力的。但是，Hadoop集群搭建起来后如何保证它安全稳定地运行呢？旧版本的Hadoop中没有完善的安全策略，导致Hadoop集群面临很多风险，例如，用户可以以任何身份访问HDFS或MapReduce集群，可以在Hadoop集群上运行自己的代码来冒充Hadoop集群的服务，任何未被授权的用户都可以访问DataNode节点的数据块等。经过Hadoop安全小组的努力，在Hadoop 1.0.0版本中已经加入最新的安全机制和授权机制（Simple和Kerberos），使Hadoop集群更加安全和稳定。下面从用户权限管理、HDFS安全策略和MapReduce安全策略三个方面简要介绍Hadoop的集群安全策略。有关安全方面的基础知识如Kerberos认证等读者可自行查阅相关资料。
- 用户权限管理
Hadoop上的用户权限管理主要涉及用户分组管理，为更高层的HDFS访问、服务访问、Job提交和配置Job等操作提供认证和控制基础。
Hadoop上的用户和用户组名均由用户自己指定，如果用户没有指定，那么Hadoop会调用Linux的“whoami”命令获取当前Linux系统的用户名和用户组名作为当前用户的对应名，并将其保存在Job的user.name和group.name两个属性中。这样用户所提交Job的后续认证和授权以及集群服务的访问都将基于此用户和用户组的权限及认证信息进行。例如，在用户提交Job到JobTracker时，JobTracker会读取保存在Job路径下的用户信息并进行认证，在认证成功并获取令牌之后，JobTracker会根据用户和用户组的权限信息将Job提交到Job队列（具体细节参见本小节的HDFS安全策略和MapReduce安全策略）。
Hadoop集群的管理员是创建和配置Hadoop集群的用户，它可以配置集群，使用Kerberos机制进行认证和授权。同时管理员可以在集群的服务（集群的服务主要包括NameNode、DataNode、JobTracker和TaskTracker）授权列表中添加或更改某确定用户和用户组，系统管理员同时负责Job队列和队列的访问控制矩阵的创建。
- HDFS安全策略
用户和HDFS服务之间的交互主要有两种情况：用户机和NameNode之间的RPC交互获取待通信的DataNode位置，客户机和DataNode交互传输数据块。
RPC交互可以通过Kerberos或授权令牌来认证。在认证与NameNode的连接时，用户需要使用Kerberos证书来通过初试认证，获取授权令牌。授权令牌可以在后续用户Job与NameNode连接的认证中使用，而不必再次访问Kerberos Key Server。授权令牌实际上是用户机与NameNode之间共享的密钥。授权令牌在不安全的网络上传输时，应给予足够的保护，防止被其他用户恶意窃取，因为获取授权令牌的任何人都可以假扮成认证用户与NameNode进行不安全的交互。需要注意的是，每个用户只能通过Kerberos认证获取唯一一个新的授权令牌。用户从NameNode获取授权令牌之后，需要告诉NameNode：谁是指定的令牌更新者。指定的更新者在为用户更新令牌时应通过认证确定自己就是NameNode。更新令牌意味着延长令牌在NameNode上的有效期。为了使MapReduce Job使用一个授权令牌，用户应将JobTracker指定为令牌更新者。这样同一个Job的所有Task都会使用同一个令牌。JobTracker需要保证这一令牌在整个任务的执行过程中都是可用的，在任务结束之后，它可以选择取消令牌。
数据块的传输可以通过块访问令牌来认证，每一个块访问令牌都由NameNode生成，它们都是特定的。块访问令牌代表着数据访问容量，一个块访问令牌保证用户可以访问指定的数据块。块访问令牌由NameNode签发被用在DataNode上，其传输过程就是将NameNode上的认证信息传输到DataNode上。块访问令牌是基于对称加密模式生成的，NameNode和DataNode共享了密钥。对于每个令牌，NameNode基于共享密钥计算一个消息认证码（Message Authentication Code, MAC）。接下来，这个消息认证码就会作为令牌验证器成为令牌的主要组成部分。当一个DataNode接收到一个令牌时，它会使用自己的共享密钥重新计算一个消息认证码，如果这个认证码同令牌中的认证码匹配，那么认证成功。
- MapReduce安全策略
MapReduce安全策略主要涉及Job提交、Task和Shuffle三个方面。
对于Job提交，用户需要将Job配置、输入文件和输入文件的元数据等写入用户home文件夹下，这个文件夹只能由该用户读、写和执行。接下来用户将home文件夹位置和认证信息发送给JobTracker。在执行过程中，Job可能需要访问多个HDFS节点或其他服务，因此，Job的安全凭证将以＜String key, binary value＞形式保存在一个Map数据结构中，在物理存储介质上将保存在HDFS中JobTracker的系统目录下，并分发给每个TaskTracker。Job的授权令牌将NameNode的URL作为其关键信息。为了防止授权令牌过期，JobTracker会定期更新授权令牌。Job结束之后所有的令牌都会失效。为了获取保存在HDFS上的配置信息，JobTracker需要使用用户的授权令牌访问HDFS，读取必需的配置信息。
任务（Task）的用户信息沿用生成Task的Job的用户信息，因为通过这个方式能保证一个用户的Job不会向TaskTracker或其他用户Job的Task发送系统信号。这种方式还保证了本地文件有权限高效地保存私有信息。在用户提交Job后，TaskTracker会接收到JobTracker分发的Job安全凭证，并将其保存在本地仅对该用户可见的Job文件夹下。在与TaskTracker通信的时候，Task会用到这个凭证。
当一个Map任务完成时，它的输出被发送给管理此任务的TaskTracker。每一个Reduce将会与TaskTracker通信以获取自己的那部分输出，此时，就需要MapReduce框架保证其他用户不会获取这些Map的输出。Reduce任务会根据Job凭证计算请求的URL和当前时间戳的消息认证码。这个消息认证码会和请求一起发到TaskTracker，而TaskTracker只会在消息认证码正确并且在封装时间戳的N分钟之内提供服务。在TaskTracker返回数据时，为了防止数据被木马替换，应答消息的头部将会封装根据请求中的消息认证码计算而来的新消息认证码和Job凭证，从而保证Reduce能够验证应答消息是由正确的TaskTracker发送而来。

# 参考资料
Hadoop实战
