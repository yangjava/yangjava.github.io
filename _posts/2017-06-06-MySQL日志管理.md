---
layout: post
categories: [MySQL]
description: none
keywords: MySQL
---
# MySQL日志管理
InnoDB存储引擎是支持事务ACID特性的，它是以二十多年前IBM的一篇著名文章ARIES:A Transaction RecoveryMethod SupportingFine-Granularity Lockingand PartialRollbacksUsingWrite-Ahead Logging 为理论基础，大多数关系型数据库的实现都是基于这个理论的，包括Oracle DM等。

这个理论基本就是一个关系型数据库相关的数据库恢复原型设计，包括日志、回滚、REDO、并发控制、Buffer Pool管理等方面，内容非常全面。同时，这些内容是一个不可分割的整体，它们的共同目标之一就是保证数据库数据的一致性，保证数据库事务的ACID特性，所以这一章要讲的东西都是互相迁连的，它们之间相互作用，相互配合，相互驱动，才能保证数据库的数据完整性。下面就先从Buffer Pool的实现开始讲起。

## BufferPool的背景
InnoDB的Buffer Pool主要用来存储访问过的数据页面，它就是一块连续的内存，通过一定的算法可以使这块内存得到有效的管理。它是数据库系统中拥有最大块内存的系统模块。

InnoDB存储引擎中数据的访问是按照页（有的也叫块，默认为16KB）的方式从数据库文件读取到Buffer Pool中的，然后在内存中用同样大小的内存空间来做一个映射。为了提高数据访问效率，数据库系统预先就分配了很多这样的空间，用来与文件中的数据进行交换。访问时按照最近最少使用（LRU）算法来实现Buffer Pool页面的管理，经常访问的页面在最前面，最不经常的页面在最后面。如果Buffer Pool中没有空闲的页面来做文件数据的映射，就找到Buffer Pool中最后面且不使用的位置，将其淘汰，然后用来映射新数据文件页面，同时将它移到LRU链表中的最前面。这样就能保证经常访问的页面在没有刷盘的情况下始终在Buffer Pool中，从而保证了数据库的访问效率。

Buffer Pool的大小可以在配置文件中配置，由参数innodb_buffer_pool_size的大小来决定，默认大小为128MB。在MySQL 5.7.4之前，一旦MySQL已经启动，这个值便不能再做修改，如果需要修改，只能退出MySQL进程，然后修改对应的配置文件来设置新的Buffer Pool大小，重新启动后才能生效。这在运维上非常不方便，因为很多时候，需要去调整Buffer Pool的大小，特别是在单机多实例，或者提供云数据库服务的情况下，我们需要根据用户及实际业务的需要，不断地去动态增加或减少Buffer Poolsize，从而合理地利用内存及优化数据库。

让人庆幸的是，MySQL官方也发现了这种不便。在MySQL 5.7.5之后，MySQL在源码上改变了对BufferPool的管理，可以在MySQL进程运行的情况下，动态地配置innodb_buffer_pool_size。另外，需要强调的是，如果Buffer Pool的大小超过了1GB，应该通过调整innodb_buffer_pool_ instances=N，把它分成若干个instance的做法，来提升MySQL处理请求的并发能力，因为Buffer Pool是通过链表的方式来管理页面的，同时为了保护页面，需要在存取的时候对链表加锁，在多线程的情况下，并发去读写Buffer Pool里面缓存的页面需要锁的竞争和等待。所以，修改为多个instance，每个instance各自管理自己的内存和链表，可以提升效率。

## BufferPool实现原理
在启动MySQL服务时，会将所有的内嵌存储引擎启动，包括InnoDB。InnoDB会通过函数buf_pool_init初始化所有的子系统，其中就包括了InnoDBBuffer Pool子系统。Buffer Pool可以有多个实例，可以通过配置文件中的参数innodb_buffer_pool_instances来设置，默认值为1，实现多实例的Buffer Pool主要是为了提高数据页访问时的并发度。每个实例的空间大小都是相同的，也就是说系统会将整个配置的Buffer Pool大小按实例个数平分，然后每个实例各自进行初始化操作。

在代码中，一个Buffer Pool实例用buf_pool_t结构体来描述，这个结构体是用来管理Buffer Pool实例的一个核心工具，它包括了很多信息，主要有如下四部分。-FREE链表：用来存储这个实例中所有空闲的页面。-flush_list链表：用来存储所有被修改过且需要刷到文件中的页面。-mutex：主要用来保护这个Buffer Pool实例，因为一个实例只能由一个线程访问。-chunks：指向这个Buffer Pool实例中第一个真正内存页面的首地址，页面都是连续存储，所以通过这个指针就可以直接访问所有的其他页面。

上面的两个链表，管理的对象是结构体buf_page_t，这是一个物理页面在内存中的管理结构，是一个页面状态信息的结合体，其中包括所属表空间、Page ID、最新及最早被修改的LSN值（最早LSN信息会在做检查点时使用，后面将会讲到），以及形成Page链表的指针等逻辑信息。实际上，这个结构是被另一个结构管理的，它是buf_block_t，buf_block_t与buf_page_t是一一对应的，都对应Buffer Pool中的一个Page，只是buf_page_t是逻辑的，而buf_block_t包含一部分物理的概念，比如这个页面的首地址指针frame等。关于buf_block_t，后面还会继续介绍。

初始化一个Buffer Pool实例内存空间的函数是buf_chunk_init。一个Buffer Pool实例的内存分布是一块连续的内存空间，这块内存空间中存储了两部分内容，前面是这些数据缓存页面的控制头结构信息（buf_block_t结构），每一个控制头信息管理一个物理页面，这些控制头信息的存储，占用了部分Buffer Pool空间，所以在运维过程中，看到状态参数innodb_buf fer_ pool_bytes_data总是比innoDB_buf fer_pool_size小，就是因为控制头信息占用了部分空间。实际的分配方式是，Buffer Pool页面从整个实例池中从后向前分配，每次分配一个页面，而控制结构是从前向后分配，每次分配一个buf_block_t结构的大小，直到相遇为止，这样就将一个实例初始化好了。但一般情况下，中间都会剩余一部分没有被使用，因为剩余的空间不能再放得下一个控制结构与一个页面了。相应的分配代码如下。

其中，chunk->size是在前面提前根据Buffer Pool实例内存大小计算出来的，可以存储的最多的Page及Page对应控制结构的个数。

一个Buffer Pool实例中的所有控制头信息连续存储在一起，所以控制信息存储完成之后才是真正的缓冲页面，图11.1所示的是一个Buffer Pool实例的内存分布情况。

对于Buffer Pool中的所有页面，都有一个控制头信息与它对应，从图11.1可以看出，每一个ctl都表示了一个属于自己的page使用情况。初始化实例时当然还需要对每一个控制头信息进行初始化，也就是每一个buf_block_t结构。初始化一个页面控制信息是通过buf_block_init函数实现的，buf_block_t结构中包含了很多信息，主要包括如下四部分。

•其对应的页面地址frame。

•页信息结构buf_page_t，这个结构用来描述一个页面的信息，包括所属表空间的ID号、页面号、被修改时产生的LSN（newest_modification及oldest_modification）、使用状态（现在共有9种状态）等（上面已经介绍过与buf_block_t的关系）。

•用来保护这个页面的互斥量mutex。

•访问页面时对这个页面上的锁lock（read/write）等。

在初始化完每一个页面之后，需要将每一个页面加入到上面提到的空闲页链表中，因为这些页面现在的状态都是未使用（BUF_BLOCK_NOT_USED）。

到现在为止，缓冲池的一个实例就算初始化完成了，在访问数据库的时候会通过这些内存页面来缓存文件数据。

相对于整个Buffer Pool而言，多个Buffer Pool实例之间的关系，需要在这里再讲述一下。上面所说的单个实例的初始化，是完全独立的，多个实例之间没有任何关系，单独申请、单独管理、单独刷盘，可以从其实现的代码中看到这一点，代码如下。

通过Buffer Pool多实例的管理机制，可以减少系统运行过程中不同页面之间一些操作的相互影响，从而很好地解决了由于页面之间的资源争抢导致的性能低下的问题，所以在实际的运维过程中，建议要分多实例的管理方式，把MySQL及InnoDB用好，让业务少一些烦恼。

## REDO LOG日志文件管理的用途
REDO LOG是用来做数据库crash recovery的，这是数据库保障数据安全的重要功能之一。在数据库操作中，它保存了对InnoDB表中数据的修改记录，所以也叫日志文件。在InnoDB存储引擎中，一般默认包括2个日志文件，新建数据库之后，会有名为ib_logfile0和ib_logfile1的两个文件，如果在启动数据库时，这两个文件不存在，则InnoDB会根据配置参数或默认值，重新创建日志文件。

在InnoDB内部的日志管理中，一个很重要的概念是LSN，全名叫Log SequenceNumber，它用来精确记录日志位置信息，且是连续增长的。在InnoDB中，大小为8个字节的值，它的增长量是根据一个MTR（m ini-transaction，后面会讲到）写入的日志量来计算的，写多少日志（单位字节），LSN就增长多少。日志文件轮循一圈（所有日志文件是以循环方式使用的），那么LSN的增长量大约就是整个日志文件的大小（日志文件存在文件头等会占用一部分空间）。它是一个集逻辑意义与物理意义于一身的概念。而在有些数据库中，LSN是一个完全逻辑的概念，每提交一个物理事务，LSN就加1。

上面提到，日志文件是以类似循环圈的方式使用的，如图11.2所示。

在InnoDB中，通过日志组来管理日志文件，是一个逻辑定义，包含若干个日志文件，一个组中的日志文件大小相等，大小通过参数来设置。现在InnoDB只 持一个日志组。在MySQL 5.5及之前的版本中，整个日志组的容量不能大于4GB（实际上是3.9GB多，因为还有一些文件头信息等），到了MySQL 5.6.3版本之后，整个日志组的容量可以设置得很大，最大可以达到512GB。

REDO日志的写入，都是字节连续的，虽然看上去是多个日志文件，但理解的时候，完全可以把它想象成一个文件，对每一文件掐头去尾，把剩下的空间连接起来，就是总的日志空间了。

日志组中的每一个日志文件，都有自己的格式，内部也是按照大小相等的页面切割，但这里的页面大小是512个字节，由于历史的原因，考虑到机械硬盘的块大小是512字节，日志块大小也如此设计。这是因为写日志其实就是为了提高数据库写入吞吐量，如果每次写入是磁盘块大小的倍数，效率才是最高的，并且日志将逻辑事务对数据库的分散随机写入转化成了顺序的512字节整数倍数据的写入，这样就大大提高了数据库的效率。正是因为这个原因，

REDO日志才可以说是数据库管理系统与通过直接写文件来管理数据的最根本的区别之一。下面展示的是日志文件的格式。

需要注意的是，图11.3中第一列指的是每一项在页面中的偏移位置，而下一项则是这个值加上该值在页面中所占长度得到的值。

图11.3中展示的4个页面（2048字节），主要用于管理日志内容及整个数据库状态。在这2KB内容之后，就是正常的用来存储日志内容的部分，也是按照512字节页面大小的方式存储，图11.4中展示的是正常日志页面的格式。

普通页面中，都会有12个字节用来存储页面头信息，这些信息主要用于管理这个页面本身的数据存储方式。

•LOG_BLOCK_HDR_NO：4个字节，一个与LSN有关系的块号。

•LOG_BLOCK_HDR_DATA_LEN：2个字节，表示当前页面中存储的日志长度，这个值一般都等于512-12（12为页面头的大小），因为日志在相连的块中是连续存储的，中间不会存在空闲空间，所以如果这个长度不为500，表示此时日志已经扫描完成（Crash Recovery的工作）。

•LOG_BLOCK_FIRST_REC_GROUP：2个字节，表示在当前块中是不是有一个MTR（关于这个概念的意义，会在下一节中专门介绍）的开始位置。因为一个MTR所产生的日志量有可能是超过一个块大小的，那么如果一个MTR跨多个块时，这个值就表示了这个MTR的开始位置究竟是在哪一个块中。如果为0，则表示当前块的日志都属于同一个MTR；而如果其值大于0并且小于上面LOG_BLOCK_HDR_DATA_LEN所表示的值，则说明当前块中的日志是属于两个MTR的，后面MTR的开始位置就是LOG_BLOCK_FIRST_REC_GROUP所表示的位置。

LOG_BLOCK_CHECKPOINT_NO：4个字节，存储的是检查点的序号。具体什么是检查点，后面会详细介绍。

上面所讲述的就是日志文件的组织结构，只有前面2KB是日志头，后面所有的都是一个个连续的、用来存储MTR产生的日志页面。

## 物理事务
上面已经提到了关于MTR的概念，实际上，它是InnoDB存储引擎中一个很重要的用来保证物理页面写入操作完整性及持久性的机制。之所以被称为MTR，是因为它的意义相当于一个M ini-transaction，用MTR来表示，这里把它称作“物理事务”，这样叫是相对逻辑事务而言的。

对于逻辑事务，熟悉数据库的人都很清楚，它是数据库区别于文件系统最重要的特性之一，它具有ACID四个特性，用来保证数据库的完整性——要么都做修改，要么什么都不做。物理事务从名字来看，是物理的，因为在InnoDB存储引擎中，只要是涉及文件修改、文件读取等物理操作的，都离不开这个物理事务，可以说物理事务是Buffer Pool中的内存Page与文件之间的一个桥梁。

从图11.5中可以看出，不管读还是写，只要使用到底层BufferPool的页面，都会使用到MTR，它是上面逻辑层与下面物理层的交互窗口，同时也是用来保证下层物理数据正确性、完整性及持久性的机制。

前面已经介绍过InnoDB的页面Buffer Pool系统，已经知道在访问一个文件页面的时候，系统都会将要访问的页面载入到Buffer Pool中，然后才可以访问这个页面，此时可以读取或更新这个页面。在这个页面不断更新变化的过程中，有一个系统一直扮演着很重要的角色，那就是日志系统。因为InnoDB采用的也是LOGWRITE-AHEAD，所以所有的写操作，都会有日志记录，这样才能保证数据库事务的ACID特性。

而写日志是一个物理操作，其实它也需要一个完整性。比如在底层页面插入一条记录，如果只修改页头信息而没有修改页尾信息，其实对于这个页面来说是不完整的，所以这个物理操作还是需要一个机制来保证它的完整性的。那么在InnoDB中，这个机制就是上面介绍的物理事务，因为它也是用来保证完整性的，所以也被称作“事务”。

物理事务既然被称为事务，那它同样有事务的开始与提交，物理事务的开始其实就是对物理事务结构体m tr_struct的初始化，其中包括下面一些成员。

分别介绍一下每个成员的意义，如下。

•memo：是一个动态数组空间，用来存储所有这个物理事务用到（访问）的页面（实际上存储的就是Buffer Pool中管理页面的控制块结构buf_block_t），这些页面都是被所属的物理事务上了锁的（读锁或者写锁，某些时候会不上锁）。这个锁是读写锁、页面锁，与逻辑事务中所说的表锁和行锁要区分开来。

•log：也是一个动态数组空间，用来存储这个物理事务在访问修改数据页面的过程中产生的所有日志，这个日志就是数据库中经常说到的重做（REDO）日志。

•n_log_recs：表示这个物理事务产生的日志量，单位为日志记录条数。

•log_mode：表示这个物理事务的日志模式，包括MTR_LOG_ALL（写日志）、MTR_LOG_ NONE（不写日志）等。

•start_lsn：表示这个物理事务开始前的LSN。

•end_lsn：表示这个物理事务提交后产生的新的LSN。

首先，在系统将一个页面载入Buffer Pool的时候，需要一个新开始（m tr_start）或者一个已经开始的物理事务，载入时需要指定页面的获取方式，比如是用来读取的还是用来修改的，这样会影响物理事务对这个页面的上锁情况，如果用来修改，则上X锁，否则上S锁（当然还可以指定不上锁）。在确定了获取方式、页面的表空间ID及页面号之后，就可以通过函数buf_page_get来获取指定页面了，当找到相应页面后，物理事务就要对它上指定的锁，此时需要对这个页面的上锁情况进行检查，一个页面的上锁情况是在结构体buf_block_struct的lock中体现的，此时如果这个页面还没有上锁，这个物理事务就会直接对其上锁，否则还需要考虑两个锁的兼容性，只有两个锁都是共享锁（S）的情况下才可以上锁成功，否则需要等待。当上锁成功后，物理事务会将这个页面的内存结构存储到上面提到的memo动态数组中，然后这个物理事务就可以访问这个页面了。

物理事务对页面的访问包括两种操作，一种是读，另一种是写。读就是简单读取其指定页面内偏移及长度的数据；写则是指定从某一偏移开始写入指定长度的新数据。同时，如果这个物理事务是写日志的（MTR_LOG_ALL），此时还需要对刚才的写操作记下日志，这里的日志就是逻辑事务中提到的REDO日志。写下相应的日志之后，同样将其存储到上面的log动态数组中，同时要将上面结构体中的n_log_recs自增，维护这个物理事务的日志计数值。

物理事务的读写过程主要就是上面介绍的内容，其最重要的是它的提交过程。物理事务的提交是通过m tr_comm it来实现的。在讲m tr_comm it之前，先讲一下，什么时候该提交，内部是如何控制的。

这里首先需要知道的是，InnoDB的REDO日志不完全是物理日志，它包含了部分逻辑意义在里面，比如插入一行记录时，MTR记录的是在一个页面中写入这条记录，内容大致包括页面号、文件号（表空间号）及这条记录的值（包括每个列信息），这样就有了逻辑概念。需要注意的是，在做REDO恢复时，需要保证这个页面是正确的、完整的，不然这个REDO就会失败，这也正是InnoDB存储引擎中著名的DOUBLEWRITE存在的意义，不过这是后话而如果是纯物理的REDO，日志内容应该会拆得更散，比如还是插入一条记录，它会记录页面号、文件号（表空间号）、页面内偏移值，并且有多个这样的REDO记录，因为会涉及多个位置的修改操作，这就没有任何逻辑内容了。而针对一个插入操作，需要在一个页面内的不同位置写入不同的数据，当然如果是纯物理REDO，相应地会产生多条REDO记录，这是物理与逻辑的简单区别。

再说MTR的提交，一个逻辑事务是由多个物理事务组成，用来保证数据库的ACID特性的，有这个就够了，所以物理事务可以保证一次物理修改是完整的。所谓一次物理修改，可以理解为一个底层的相对完整的写入操作，比如插入一条记录的过程中，会包括写一条回滚记录及插入时写入一个页面等，那么这些逻辑上是一个动作的物理写入，就可以被认为是一个独立的物理事务，也就是在写回滚记录时执行m tr_start，写完之后执行m tr_comm it，真正插入时写一个页面也是同样的道理。

接着介绍MTR提交的细节。物理事务的提交主要是将所有这个物理事务产生的日志写入到InnoDB日志系统的日志缓冲区中，然后等待srv_master_thread线程定时将日志系统的日志缓冲区中的日志数据刷到日志文件中，这会涉及日志刷盘时机的问题，不过还是先来看看MTR、日志缓冲区及日志文件之间的关系，如图11.6所示。

从图11.6中可以看出，左边的若干个MTR产生了各自的REDO LOG，有些MTR已经提交了，有些正在写入。正在写入日志的MTR，它们的日志都存储在自己MTR结构的log动态数组中，这个MTR还是不完整的，所以还是自己保存着，而对于那些已经提交的MTR，它们对应的日志已经在提交的时候转存到了日志缓冲区中，相当于这些日志已经是实实在在地产生了，将来必然要占用数据库日志文件的一部分空间（除非数据库此时挂了）。

日志缓冲区的存储只是一个暂时的中间状态，日志缓冲区的大小可以通过参数innodb_log_ buffer_size来设置，一般都比较小，存储不了太多的日志。因为已经提交并写入到日志缓冲的日志是确定的，所以它们是占用了LSN的，也就是说它们会使LSN变大。

最后提交的那个MTR代表着整个数据库最新的LSN值，也就是图11.7中所示的Log Sequence number，这也正是在MySQL客户端中执行命令show engine innodb status\G时，返回的信息中Log模块中的第一行。

而日志缓冲区也是有大小的，当多个MTR提交时，缓冲区被占满了，那么此时系统会将日志缓冲区的日志刷到日志文件中（这里涉及的另一个问题就是日志刷盘时机，这里只是一种情况，其他的后面做专门介绍），为其他新的MTR释放空间。此时，日志的流向就是从中间的日志缓冲区向右边的日志文件转移，上面已经提到过，转移其实是平移，在缓冲区是什么内容，写入文件也是什么内容，也是完全连续的，且在日志文件中，还是一个个的MTR连续存储。

最新写入日志文件的那个MTR产生的LSN值（图11.7中所示的Log flushed up to），其实就是图11.7中所示的Log状态的第二行，也就是日志最新写入文件的LSN值，这个值的意义很重大，表示的是，到这个LSN为止，所有的修改都是完整的了，如果此时数据库挂了，写到这个位置的数据都是可以恢复的，而不需要去关心Buffer页面是不是被刷到磁盘。但此时在日志缓冲区中的日志所对应的操作就丢失了，这里是否会丢失事务数据与参数innodb_flush_log_at_trx_comm it有关系，如果将参数innodb_flush_log_at_trx_comm it设置为1，当前事务的提交肯定会将日志缓冲区中的日志刷到日志文件中；如果设置为2，那么日志只是写入了操作系统缓存，并没有写入磁盘，那么此时有可能丢失部分已经提交的事务，丢失多少由操作系统决定，这种情况下，即使数据库挂了，只要机器不挂，就问题不大，因为操作系统还会将它对应的缓存写入磁盘；但如果设置为0的话，就无能为力了，因为InnoDB只负责将事务对应的日志写入到日志缓冲区中，无论是操作系统，还是数据库，都不能保证日志的安全性，所以最好不要设置成这样。

进一步而言，日志文件的大小也是有限的，不可能无限量地将日志写入日志文件中。前面已经提到过，它是循环使用的，如果日志写入的头（图11.7中所示的Log flushed up to）和尾相遇了，此时日志就不能再写入了，因为如果再写入的话，就要“追尾”了，这样会将之前产生的日志覆盖掉，导致日志不可用，不完整。此时就会使用一种机制来保证新的日志还能继续写入，尾部日志还是完整的，这个机制叫作checkpoint（检查点）。

说白了，日志产生的作用，是将随机页面的写入变成顺序日志的写入，从而用一个速度更快的写入来保证速度较慢的写入的完整性，以提高整体数据库的性能。其根本目的是要将随机变成顺序，所以日志的量才是一个相对固定循环使用的空间。有了这个思想之后，使用检查点来保证日志的重复写入、数据库完整性就是顺其自然的事情。

使用检查点来保证数据库完整性的主体思想，主要是让日志失效，也就是让Buffer Pool中的页面修改写入到磁盘上面。因为日志的存在实际上就是让Buffer Pool中的Page尽可能少地刷磁盘，尽可能长时间地将页面数据缓存起来，尽可能提高访问速度，因为不管如何修改，Buffer Pool中的页面都是最新的，只是不一定写入磁盘中（没有刷入没关系，由日志来保证）。如果日志文件大小不够用，此时只要将Buffer Pool中的某些页面刷入到磁盘中，其对应的日志就失效了，因为这些日志就是用来保证Page没有刷入时但数据库挂了的情况下数据库的完整性的，而这些Page如果已经写入磁盘了，相应的日志也就没有用了，这就是检查点的根本意义所在。而上面提到的，做检查点时，只是将某些页面刷入磁盘，其中的”某些”是有讲究的。俗话说：“家有三件事，先从紧处来”，现在的问题是日志空间不够用了，而日志是循环使用的，必须是按照顺序，不能跳着写，所以最主要的是从LSN值最小的日志开始，按照从小到大的顺序不断地让这些日志失效。每次做检查点都会有一个比例，此时系统会根据最小的有效LSN（m in_valid_lsn）和检查点处理的日志比例计算出最大的将要失效的LSN值（取名叫lsn_checkpoint_up_to）。计算完之后，再去扫描Buffer Pool的flush_list链表，找出所有被更新过的页面中，曾经修改这些页面的MTR对应的LSN中的最小值（因为一个页面有可能被多次修改，但只需要考虑最小的LSN的那一次，使用的是前面介绍结构buf_block_t时，这里面所存储的oldest_modification的值），如果这个值比lsn_checkpoint_up_to值小，就将这个页面刷入磁盘，也就是说，如果将小于lsn_checkpoint_up_to的MTR修改过的页面都刷入磁盘了，那么日志文件中在LSN值lsn_checkpoint_up_to以前的日志就都可以失效了，那么在整个日志文件空间中，从m in_valid_lsn到lsn_checkpoint_up_to之间的空间，又可以被重新使用了，直接覆盖即可，而不会导致数据库不完整、数据丢失等问题。

此时，再接着上面MTR产生日志的图11.6来讲，上面找到的日志文件的位置lsn_checkpoint_ up_to就是图11.7中所示的Last checkpoint at，也是上面命令show engine innodb status\G中关于Log部分的第四行信息。而从这个点开始到最新的已经刷盘的日志文件位置Log f lushed up to之间的日志都是有效日志了，不能被覆盖，只有空间又不够用了的情况下，再将最小的有效日志位置向前推，产生新的位置，像这样不断循环，周而复始的工作，这就是日志、Buffer Pool及检查点之间的工作原理。

上面提到的show engine innodb status\G命令生成的Log部分中显示的第三行信息，是Buffer Pool中Page刷盘时刷到的一个最新的LSN。但此时检查点的最新点不一定做得及时，所以它是大于等于第四行的，而图11.7中所示的四行对应的值，从上到下以递减的顺序排序，其中的道理都已经非常明确了。

上面已经讲过，物理事务和逻辑事务一样，也是可以保证数据库操作的完整性的。一般说来，一个操作必须要在一个物理事务中完成，也就是说要么这个操作已经完成，要么什么也没有做，否则就有可能造成数据不完整的问题，因为在数据库系统做REDO操作时是以一个物理事务为单位做的，如果一个物理事务的日志是不完整的，则它对应的所有日志都不会重做。那么，如何辨别一个物理事务是否完整呢？这个问题是在物理事务提交时用了一个很巧妙的方法来保证的。在提交前，如果发现这个物理事务有日志，则在日志最后再写一些特殊的日志，这些特殊的日志就是一个物理事务结束的标志，提交时一起将这些特殊的日志写入，在重做时如果当前这一批日志信息最后面存在这个标志，则说明这些日志是完整的，否则就是不完整的，就不会重做。

物理事务提交时还有一项很重要的工作就是处理上面结构体中动态数组memo中的内容，现在已经知道这个数组中存储的是这个物理事务访问过的所有页面，并且都已经上了锁。在它提交时，如果发现这些页面中已经有被修改过的，这些页面就成了脏页，这些脏页需要被加入到InnoDBBuffer Pool中的更新链表中（讲BUFFER时已经讲过）。当然，如果已经在更新链中，则直接跳过（不能重复加入），svr_master_thread线程会定时检查这个链表，将一定数目的脏页刷到磁盘中，加入之后还需要将这个页面上的锁释放掉，表示这个页面已经处理完成；如果页面没有被修改，或者只是用来读取数据的，则只需要直接将其共享锁（S锁）释放掉即可。

上面的内容就是物理事务的一个完整的讲述，它是比较底层的一个模块，牵扯的东西比较多，这里重点讲述了物理事务的意义、操作原理、与BUFFER系统的关联、日志的产生等内容。

下面继续讲述有关日志的其他内容。

## 日志的意义
上面已经讲述过，日志是在逻辑事务对数据库做DML操作时，其所包含的物理事务MTR所记录的，针对所有涉及的Buffer Pool页面的修改记录。

为了更好的讲述日志的意义，这里通过以下几个方面来更好地说明。

假如没有写日志

假如没有写日志，那数据库在做了任何修改之后，必须要直接将Buffer Page刷磁盘，不然如果此时数据库挂了，即使事务已经被提交，这些修改还是没办法恢复。这将带来的灾难是，IO大量增加。此时的数据库，相当于是一个简单的文件系统，无论写什么数据，都必须马上刷入磁盘，Buffer Pool的作用可能只是一个用来修改文件页面的临时缓存而已。

假如没有写日志，在数据库做了DML操作之后，数据库可能在事务没有提交时就将Buffer Page刷到磁盘了，但此时需要回滚。而我们知道，回滚段的内容也是通过Buffer Pool管理的，它的每个页和B树页面是一样的，只是作用不一样而已。由此可知，回滚段数据也是通过REDO日志来保证完整性的。那么如果没有了日志，Buffer Page中的回滚段页面也需要直接写入，没有了任何缓存，性能就会非常低。

假如没有写日志，数据库在关闭（挂掉）后再启动时，就不需要做REDO操作了（因为没有写日志），但需要做UNDO操作，因为UNDO不是通过REDO来恢复的，而是自己写入（假设每次写Buffer Page之后都直接刷盘了），所以回滚段是有效的，还可以让没有提交的事务回滚掉（因为如果一个事务修改的页面很多的话，肯定会有一部分页面先被刷掉，所以有可能需要回滚），勉强还可以保证数据库的完整性。

综合上面的假设，现在已经明白，日志的作用就是用来保证Buffer Pool页面的数据写入不丢失。反过来说，如果每个Buffer Pool中的Page每次都刷入到磁盘中，这样就不需要REDO日志了，此时的数据库就成了一个文件系统，因为Buffer Pool每次都进行刷盘，相当于每次写完直接写文件。所以说，日志是数据库管理系统与文件系统最核心的区别。

所以如果没有日志，数据库的性能就低到完全没有办法用了。因为IO太大了，同时，这种IO操作都是随机写入，很容易导致IO到达瓶颈，所以为了提高数据库性能，就必须要使用REDO日志机制。

使用日志能提高性能的关键原因，有以下三个方面。

•因为日志是用来记录Buffer Pool中Page的修改记录的，所以把对Page的写入转化为对日志的写入，那此时Page就不需要每次都刷盘，写Page页面只需要在内存中写入即可，性能会非常好。

•通常，一个页面是16KB，如果不写日志的话，每次的写入单位还是16KB，即使修改很少量的数据，也是如此。这样会导致无效IO非常严重，反过来说，也只有通过日志机制，才能真正体现出真实写入的数据量，不会存在对IO的浪费，Page的刷盘数量会大大减少。

•如果没有日志，就会每次都刷Page，而这些Page的相对位置是乱的，并不是顺序的，刷盘大多都是随机IO，这对于机械硬盘来说，性能是非常差的，而有了日志，就可以巧妙地将随机IO转化成日志的顺序IO，这将大大地提高IOPS，性能也会非常好。

日志文件大小的区别

使用日志对数据库的性能有很大的影响，那对于日志来说，还有什么其他因素会影响数据库的性能呢？那就是日志文件空间容量。

现在已经知道，日志在设置好后其容量是固定的，它是循环使用的，如果不够用了，引发的事件是做一个检查点，让最小有效的LSN向前推，让出一部分空间给新产生的日志来使用。也就是说，只要这个日志空间未用完，那么Buffer Pool中的Page就会一直不刷盘（因为还有其他的刷盘时机，所以这里单指因为日志不够用导致检查点的刷盘），任何修改都是在内存中发生的。那么，下面做一个计算。

假如当前日志容量设置为128MB，某一个DML操作只针对某一行记录一直做修改操作。每次操作产生日志量为1KB（包括Buffer中数据页面的修改及UNDO记录的产生），这样算下来，128MB的日志量可以容纳对这条记录的131072（128MB/1KB）次修改。也就是说，在这么多次修改之后，这个页面才需要刷盘，才会产生一次随机刷盘操作。而如果把日志文件设置为1280MB，很容易知道，这将容纳对这条记录的1310720次修改，这么多次修改只产生一次随机刷盘操作。而如果还是128MB的话，则需要10次随机刷盘。很明显，日志容量对数据库的性能还是有很大影响的。

但也不是设置得越大越好，这里有以下两点需要注意。

•如果设置得非常大，固然性能可能会很好，但如果某一天（真的有可能到来），数据库异常挂了，此时可能有很多的日志都没有刷盘，也就是Log flushed up to与Lastcheckpoint at两个值之间相差太多，恢复起来可能需要比较长的时间。但这个一般问题不大，本身挂的概率不大，同时REDO日志的恢复是顺序的，都是根据页面号的大小排序恢复的，所以比较快。同时，在以后的MySQL版本中，会有多线程REDO恢复（听说的），这样就更快了，所以这一点不需要太担心。

•日志容量大小的设置，最好与Buffer Pool的总大小匹配。如果日志容量太小，Buffer Pool太大，这就会导致Buffer Pool频繁做检查点，大的Buffer Pool不能被好好利用。如果是日志容量很大，而Buffer Pool很小，此时Buffer Page经常会被淘汰出去，增加了IO频次，同时如果数据库意外挂掉，Buffer Pool小的话，恢复起来也会比较慢。一般情况下，Buffer Pool的总大小与日志容量的大小比例最好保持在10～5：1的范围内。

## 日志记录格式
前面已经讲述了太多日志相关的内容了，这一节将要讲一下具体到一个日志记录时它是如何组织的，一条日志记录究竟存储了什么。这些问题在这一节都会说清楚。前面已经讲到，InnoDB的日志是具有逻辑意义的物理日志，所以，日志记录的格式就不完全是物理信息，而是有一定逻辑意义的。首先看一个基本的格式，如图11.9所示。

图11.9中各列代表的意义如下。

•Type：日志类型，是一个日志记录的最高位，只占一个字节的空间。

•Space：表空间ID值，如果是系统页面（UNDO页面，或者是字典表页面），则是0；如果是索引页面，则是这个索引所在的表空间ID值。

•Offset：上面Space所指定的文件中的页面号，以页面大小为单位，它是第几个页面（从0开始计数），则这个Offset就是几。

•Data：表示这条日志记录对应的数据，这个数据是不确定的，根据不同的Type值而不同，分别具有自己的格式。

Type类型有很多，下面列举了一些在InnoDB中比较常用的类型，并简单做一些解释，以便可以更好地理解。InnoDB中的REDO，究竟是在做什么？究竟存储了哪些内容？功能是什么？知道每个类型之后，这些问题也就清楚了。

注意：下面讲到的数据记录，都是以Compact格式的记录为对象的，其他类型这里不做考虑。
•MLOG_1BYTE、MLOG_2BYTES、MLOG_4BYTES、MLOG_8BYTES：这四个类型，表示要在某一个位置，写入一个（两个、四个、八个）字节的内容，在日志记录中，Type分别是MLOG_1BYTE（MLOG_2BYTES、MLOG_4BYTES、MLOG_8BYTES），Space就是对应的表空间ID，Offset对应的是页面号。在Data中，还需要存储三个（四个、六个、十个）字节，前两个为要写入的数据在页面内的偏移值，因为页面大小为16KB，所以需要用两个字节来存储，而后面才是真正需要写入的数据，占一个（两个、四个、八个）字节，这就是关于这个类型的日志的完整内容。

•MLOG_WRITE_STRING：这种类型的日志，其实和MLOG_1BYTE是类似的，只是MLOG _1BYTE是要写一个固定长度的数据，而MLOG_WRITE_STRING是要写一段变长的数据。Data部分的格式，首先用2个字节存储在页面中的写入位置，然后是2个字节写入数据长度，最后是存储指定长度的字符串。

•MLOG_COMP_REC_M IN_MARK：这个类型的日志，是在将一条记录设置为页面中的最小记录（这个涉及页面管理的内容，在一个页面中只有一个最小记录，它指向的是B树下一层的最左边的节点）时产生的，因为只是打个标记，存储内容比较简单，除了基本的日志头外，在Data内容中只存储了这条最小记录在页面内的偏移位置。

•MLOG_UNDO_INSERT：这个类型的日志，是用来保证一个插入操作可以在事务没有提交的情况下回滚时用的，在插入一条记录时，不止要写一个插入操作的日志（类型为MLOG_REC_INSERT，后面会着重介绍），还要写一个针对这个操作的回滚记录。我们已经知道，回滚记录的写入，其实也是向ibdata文件中写入数据，同样也是写在Buffer Pool中的，这个操作对应的REDO日志，就是当前介绍的MLOG_UNDO_INSERT类型的日志。在数据库恢复时，只有这个REDO日志做完了，相应的UNDO记录才有效（存在），如果对应的事务没有提交，会通过这个回滚记录将这个插入操作回滚掉，这也正是REDO必须要在UNDO之前执行的原因。

至于这种类型的日志格式是什么样子的，与前面所说类型的区别还是在Data上面。前面两个字节存储的是回滚记录的长度，接着就是回滚记录的完整数据，不包括回滚记录前后各两个字节的指针信息，具体到回滚记录的格式，后面会讲述。

•MLOG_INIT_FILE_PAGE：这个类型的日志比较简单，只有前面的基本头信息，没有Data部分。因为在InnoDB中，初始化一个页面，所有的信息都是固定的，没有额外的处理，只要表明初始化哪一个位置的页面就好了，所以没有Data部分。这里初始化页面所做的操作，只涉及对页面中文件管理方面的信息，比如这个页面的页面号、文件号（表空间ID）等信息，与后面将要介绍的MLOG_COMP_PAGE_CREATE是不同的，这个属于页面管理的文件信息部分的初始化，而MLOG_COMP_PAGE_CREATE属于页面的索引、数据存储方面的管理信息的初始化。后者是在前者的基础上做的。

•MLOG_COMP_PAGE_CREATE：这个类型的日志，其实和上面已经说过的MLOG_INIT_ FILE_PAGE是一样的道理，因为在Buffer中创建一个新的可以使用的页面是固定的，只需要存储一个类型及要创建的页面的位置即可。创建一个页面所做的操作，包括初始化页面头信息，创建页面中的最小记录与最大记录，初始化页面中的记录数、HEAP大小HEAP首地址及槽信息，初始化之后，这个页面就可以在B树中使用了，它是一个页面在没有插入任何数据时的状态。

•MLOG_MULTI_REC_END：这个类型的日志是非常特殊的，它只起一个标记的作用，其存储的内容只有占一个字节的类型值。在前面介绍MTR时说到，一个MTR所写的日志，要么全部写入，要么全部不写入。那么，如何保证这个原子性就是通过这个类型的日志，来实现的呢？即每次MTR提交时，都会在后面加上这个日志记录，用来表示这个MTR已经结束了。只有在恢复的时候才会使用它，在分析MTR时，只有找到这个日志，前面的日志才会去做REDO，做完之后，再向后扫描找到这个日志，然后再去REDO，如此反复。如果有一次找不到了，则说明日志文件是不完整的，已经扫描到的REDO日志就不会去执行了，从而保证了已经执行的MTR每个都是完整的。

•MLOG_COMP_REC_CLUST_DELETE_MARK：这个类型的日志是表示，需要将聚集索引中的某一个记录打上删除标志。因为，众所周知，在InnoDB数据库中聚簇索引的删除在没有提交之前，只是打了一个删除标志而已。这个类型的日志记录内容，除了基本的内容之外，其Data数据的组成主要包括两个字节的索引列的个数n，以及两个字节的唯一索引的个数u。接下来存储的是所有索引列的长度信息，每个列用2个字节存储，占用空间2*n个字节。然后，再存储索引中两个系统列信息，分别是TRXID在索引中的列位置信息、ROLLPTR的值及TRXID的值。最后，再存储当前要删除记录在所在页面中的偏移值，也就是那条记录的头指针信息。这种类型的日志，存储的内容比较复杂，其Data部分使用图11.10来简明表示一下。

这里有一个奇怪的地方是，在给一个记录打删除标志时，为什么不使用这条记录的主键值来直接定位，而是使用了一些在定位记录时被认为是没有用的东西呢？因为如果需要数据恢复，只需要找到这行记录的主键信息，就可以重新给这个记录打删除标志。那为什么存储的都是一些索引的定义信息呢？比如索引列个数，唯一键列个数，每个列的长度等。关于这个问题，是因为InnoDB还需要考虑其自身的问题，那就是它的REDO日志是半逻辑半物理的，在恢复时，不能保证对应的数据字典是可用的（因为数据字典的正确性还是需要REDO来保证），所以这个日志就会记录一些索引的信息，在恢复时使用这些信息来构造一个LOG_DUMMY表及LOG_DUMMY索引，然后再用这个表和索引来辅助这个REDO日志的执行，这样真正的表及索引可以不正确（暂时的），因为此时是不需要它们的。综合上面所述的日志Data部分，就可以知道这条记录的确切信息了，也就可以对它加删除标志了。

•MLOG_COMP_REC_UPDATE_IN_PLACE：这个类型的日志，和上面的MLOG_COMP_ REC_CLUST_DELETE_MARK基本是差不多的，只是此类型的日志会在最后存储原地更新后的记录信息，包括所有被更新的列的信息。存储方式是：前面用一个字节或两个字节来存储长度，后面跟着的是更新后的数据，直到记录所有的列为止。

•MLOG_COMP_REC_DELETE：在InnoDB中，删除数据是通过打删除标志来实现的，但是，在事务提交后做Purge操作时，这条记录始终是要被删除的，所以，还存在一个真正将数据记录删除的操作，那这个类型的日志就是用来记录这个动作的。不过这个日志需要记录的内容也比较少，除了基本的日志头信息之外，在Data中只需要存储这条记录在页面内的偏移即可。那么在恢复数据时，这种类型的日志的作用就是会将这个页面中对应的记录直接删除掉，而不再是打删除标记那么简单了。

•MLOG_COMP_PAGE_REORGANIZE：这个类型的日志，表示的是要重组指定的页面，其记录的内容也是很简单的，只需要存储要重组哪一个页面即可，没有Data部分。在恢复的时候，找到这个页面，对其中的数据碎片做整理，将页面内部的记录一条条向前移，将原来记录之间不能再被使用的空间收回合在一起变成一块连续的空间，这样原来貌似已经满了的页面，又可以插入新的数据了，这就是表的碎片整理过程。

•MLOG_COMP_REC_INSERT：这个类型是在插入一条记录时产生的，它的产生过程可能存在一点争议，这里重点说一下。首先，当然还是基本的日志头信息，然后存储的是被插入记录在页面内的偏移信息，接下来就是关于索引的信息，这些都与上面MLOG_COMP_ REC_CLUST_DELETE_MARK类型日志的内容相同。然而，再往后所存储的信息就比较复杂了。首先会计算出当前要插入的记录与前一条记录第一个不相同的字节的位置，然后在日志中记录从这个位置开始到当前记录结束位置之间的数据，当然还有一些其他的信息，比如第一个不相同的字节的位置信息等。这里主要想说的是它的设计方式，简单一点说，就是当前记录中存储的只是记录的后半部分数据，前半部分数据依赖的是前一条记录，这样存储会比存储整个记录省多少空间呢？最主要的是，这需要依赖插入数据之间的相关性，如果非常像，则可能会省一些，否则可能效果不明显。

上面讲述的是，在InnoDB存储引擎中，REDO日志的一部分类型，并对不同类型做了解释。从解释中可以看到，基本上每一个类型其实都是具有逻辑意义的，与DML相关的类型中，不是存储了列数据，就是存储了记录在页面内的偏移等信息，这样做的优点有如下两点。

•可以写REDO解析工具，去做一个第三方的同步工具，或者了解数据库做了什么操作，类似Binlog内容，但侧重点不同。

•日志占用空间比全物理日志少。

最大的缺点就是系统首先要保证日志对应页面的正确性，否则会造成逻辑日志执行不成功，或者造成数据不一致等问题，这个问题在InnoDB中的解决方式，就是后面介绍的Double W rite机制。

## 日志刷盘时机

前面已经介绍了大部分关于REDO日志的内容了，但还有一个问题没有讲，就是日志刷盘的时机，也就是什么时候才会将日志刷入磁盘。

现在已经知道，当MTR提交时，所产生的日志，都会先写入到Log Buffer中，这是日志产生的最初来源。从这个源头开始，InnoDB会在不同的时机，将这些日志写入到磁盘，分别有下面五种时机。

•Log Buffer空间用完了，便会将已经产生的Log Buffer中的日志刷到磁盘中，这个时机在前面介绍M tr时已经说过了。这是最普遍的一种方式。

•Master线程在后台每秒钟刷一次，将当前Log Buffer中的日志刷到磁盘中。

•每次执行DML操作时，都会主动检查日志空间是否足够，如果使用空间的量已经超过了一个预设的经验值，就会主动去刷日志，以保证在后面真正执行时，不会在执行过程中被动地等待刷盘，但这里只会是写文件（写入OS缓存中），不会刷磁盘。

•在做检查点的时候，要保证所有要刷的数据页面中LSN值最小（最旧）的日志已经刷入到磁盘。不然，如果此时数据库挂了，日志不存在，但数据页面已经被修改，从而导致数据不一致，就违背了先写日志的原则。

•提交逻辑事务时，会因为参数innodb_flush_log_at_trx_comm it值的不同，产生不同的行为。如果设置为0，则在事务提交时，根本不会去刷日志缓冲区，这种设置是最危险的，如果此时运气不好，那对数据库最新的修改都会丢失，即使事务已经提交了，但丢失的事务一般是最新1秒内产生的，因为Master线程会每隔1秒刷一次。如果设置为1，则在事务提交时会将日志缓冲区中的日志写入到文件中，同时会将这次写入强刷到磁盘中，保证数据完全不丢失，但这种设置会使得数据库性能下降很多，影响性能。如果设置为2，则在事务提交时会将日志写入到文件中，但不会去刷盘，只要操作系统不挂，即使数据库挂了，数据还是不会丢失，一般都是设置为2即可。关于这个问题，可以用图11.11来简单表示。

上面所说的基本上就是全部的日志刷盘时机了，相关内容都已经介绍清楚，在接下来的两节中，会重要讲述数据库的恢复问题。

## REDO日志恢复
前面已经很全面地介绍了日志的生成、格式、刷盘、工作原理等，但这些实际上只是数据库运行时的一个“累赘”，没办法才会这样做，因为如果数据库不挂，日志是没有用的，但不挂是不可能的，所以日志是必须要有的。而前面介绍的所有内容都是建立在有日志的前提下，解决如何提高性能，如何保证数据完整性等问题的。那这里将介绍关于日志的新内容，日志的用途之一：数据库恢复。

在第5章中，已经介绍了在InnoDB存储引擎的启动过程中，InnoDB需要做的事情有哪些，具体细节可以参考第5章了解。在这一节中，需要重点关注的主要有两个，包括recv_recovery_ from_checkpoint_start及recv_recovery_from_checkpoint_finish两个函数的处理（关于两个函数的关系，请参阅第5章相关章节）。

InnoDB启动之前，肯定是处于shutdown状态的，而导致shutdown的原因只有两种可能性，即正常关闭及Crash关闭。这里所说的数据恢复，主要处理的就是针对异常关闭时的情况。当然了，有一个叫innodb_fast_shutdown的参数，如果设置为2，也相当于是一次Crash了，道理也是一样的。

那可能有人就要问了，如果正常关闭（innodb_fast_shutdown设置为0或者1），那是不是就不执行数据库恢复了？其实不是这样的，不管如何关闭数据库，启动时都会做数据库恢复的操作，只不过正常关闭的情况下，不存在没有做过checkpoint的日志，或者说，最新的checkpoint已经在最新的LSN位置了，又或者说所有的数据页面都已经被刷成了最新的状态。说法可以有多种，但意义其实是一样的。

## 日志扫描

在开始准备做数据库恢复时，首先要做的就是从日志文件中找到最新的检查点信息。我们已经知道，在日志文件最开始的4个页面（每个页面512字节）中，存储的是用来管理日志文件及日志写入情况的信息，具体格式可以从前面看到。这里所关注的检查点信息是存储在第1号页面和第3号页面中的，即所谓的LOG_CHECKPOINT_1和LOG_CHECKPOINT_2。在做检查点时，这两个存储位置是轮换着使用的。

基于此，想要找到最新的检查点位置，就需要从上面的两个位置中找到一个最大值，也就是在这个点之前所有的日志都是失效的，并且对应的数据页面都是完整的。而在这个位置之后的页面，有可能是完整的，也有可能需要做REDO，这个决定于当时Buffer Pool的刷盘情况，如果正好有被淘汰出去的页面，那就是完整的，否则还需要通过REDO日志来恢复。先来看一段对应的精简后的代码，如下。

上面的代码，其实就是我们所熟悉的函数recv_recovery_from_checkpoint_start_func的执行过程。归纳起来，其所做的操作包括以下两部分。

•从日志文件的固定位置找到最新的检查点信息。

•从最新的检查点位置开始扫描日志文件，做数据库恢复。

现在，主要的工作就落在了recv_group_scan_log_recs上面，这个函数所要做的工作，就是将checkpoint_lsn位置开始的日志分片处理，每一片为2MB大小，对应的精简之后的代码如下

## 数据库回滚
在第5章讲述InnoDB存储引擎启动的那一节中，已经知道，在调用了函数recv_recovery_from _checkpoint_start之后，又调用了recv_recovery_from_checkpoint_finish。这里就是用来做数据库回滚的地方，也可以看出来，InnoDB的REDO是在UNDO之前做的，是等到物理的数据库操作都完成之后，才能在物理数据一致的基础上去做一些逻辑的操作，即UNDO回滚操作。

但在讲如何回滚之前，需要先了解UNDO日志的存储方式。

数据库UNDO段管理

回滚段的管理，也是有一个入口位置用来存储回滚段的管理信息。在InnoDB中，是用第6个页面（5号）来管理的，这个页面是专门用来存储事务相关信息的，先来看一下其页面格式，如下。

上面定义的是第6号页面中存储的信息及其对应的位置，每一项的详细意义如下。

•TRX_SYS_TRX_ID_STORE：用来存储事务号，在每次新启动一个事务时，都会去检查当前最大事务号是不是达到了TRX_SYS_TRX_ID_WRITE_MARGIN（256）的倍数，如果达到了，就会将最大的事务号写入这个位置，在下次启动时，将这个值取出来，再加上一个步长（256），来保证事务号的唯一性，其实就是一个经典取号器的实现原理。

•TRX_SYS_FSEG_HEADER：用来存储事务段信息。

•TRX_SYS_RSEGS：这是一个数组，InnoDB有128个回滚段，那这个数组的长度就是128，每一个元素占用8个字节，对应的一个回滚段存储的内容包括回滚段首页面的表空间ID号及页面号。

而针对每一个回滚段，即上面数组中的一个元素，也有其自己的存储格式，代码中的宏定义如下。

上面这些信息的存储，是从页面偏移38的位置开始的，在这个位置之前，存储的是文件管理信息（请参考第8章），从38开始，存储了上面五个信息，它们的意义分别如下。

•TRX_RSEG_MAX_SIZE：回滚段管理页面的总数量，即所有undo段页面之和，一般为ULINT_MAX，即无上限。

•TRX_RSEG_HISTORY_SIZE：这个表用来表示当前InnoDB里，在History List中有多少个页面，即需要做PURGE的回滚段页面的个数。

•TRX_RSEG_HISTORY：用来存储History List的链表首地址，事务提交之后，其对应的回滚段如果还不能PURGE，就都会加入到这个链表中。

•TRX_RSEG_FSEG_HEADER：用来存储回滚段的Inode位置信息，通过这个地址，就可以找到这个段的详细信息。

•TRX_RSEG_UNDO_SLOTS：这个位置所存储的是一个数组，长度为1024，每一个元素是一个页面号，初始化为FIL_NULL，即空页面。

这五个信息，存储了一个回滚段的信息，最后一个位置的数组，用来真正存储回滚段的位置，后面会讲到这128*1024个槽是如何使用的。

根据上面的讲述，现在已经知道所有回滚段的存储架构了，如图11.12所示。

现在就可以知道，InnoDB中支持的回滚段总共有128*1024=131072个，TRX_RSEG_UNDO_ SLOTS数组的每个元素都会指向一个页面，这个页面对应一个段，页面号就是段首页的页面号。

在每一个事务开始的时候，都会分配一个rseg，就是从长度为128的数组中，根据最近使用的情况，找到一个临近位置的rseg，在这个事务的生命周期内，被分配的rseg就会被这个事务所使用。

在事务执行的过程中，会产生两种回滚日志，一种是INSERT的UNDO记录，一种是UPDATE 的UNDO记录，可能有人会问DELETE哪去了？其实是包含在UPDATE的回滚记录中，因为InnoDB把UNDO分为两类，一类就是新增，也就是INSERT，一类就是修改，就是UPDATE，分类的依据就是事务提交后要不要做PURGE操作，因为INSERT是不需要PURGE的，只要事务提交了，那这个回滚记录就可以丢掉了，而对于更新和删除操作而言，如果事务提交了，还需要为MVCC服务，那就需要将这些日志放到History List中去，等待去做PURGE，以及MVCC的多版本查询等，所以分为两类。

所以，一个事务被分配了一个rseg之后，通常情况下，如果一个事务中既有插入，又有更新（或删除），那么这个事务就会对应两个UNDO段，即在一个rseg的1024个槽中，要使用两个槽来存储这个事务的回滚段，一个是插入段，一个是更新段。

在事务要存储回滚记录的时候，事务就要从1024个槽中，根据相应的更新类型（插入或者更新）找到空闲的槽来作为自己的UNDO段。如果已经申请过相同类型的UNDO段，就直接使用，否则就需要新创建一个段，并将段首页号写入这个rseg长度为1024的数组的对应位置（空闲位置）中去，这样就将具体的回滚段与整个架构联系起来了。

如果在1024个槽中找不到空闲的位置，那么这个事务就会被回滚掉，报出错误：“Toomany active concurrent transactions”，错误号为1637的异常。当然，这种情况一般不会见到，如果能把这个用完，估计数据库已经根本动不了了。

上面讲述了整个回滚段存储架构及与事务的相关性，具体到一个事务所使用的某个回滚段的管理，就存储在了回滚段首页中，管理信息包括3部分，分别是Undo pageheader、Undo segmentheader及Undo logheader。下面来分别介绍。

1.Undo pageheader。

数据库UNDO日志记录格式

在存储已经搞定之后，那么还需要继续研究一个要写入的UNDO日志记录的格式是什么样子的。关于记录格式，之前也介绍过InnoDB表中行记录（Com pact）的格式，也介绍了REDO日志的记录格式，其实都是本着省空间、高效率的宗旨来设计的，那么对于UNDO记录也是一样，但是因为UNDO日志有多个类型，针对不同的类型，其格式也不尽相同，UNDO日志的类型有下面四种。

•TRX_UNDO_INSERT_REC：记录插入的UNDO日志类型，插入记录用于回滚时，只需要通过其主键就可以实现回滚操作，所以在UNDO日志中，只记录了表ID及主键信息。回滚时，只需要通过记录中存储的主键，在原B+树中找到对应的记录，然后将其删除即可。

•TRX_UNDO_UPD_EXIST_REC：更新一条存在记录的UNDO日志类型。在日志内容中，需要记录的除了表ID信息之外，还需要记录每一个被更新的列的原始值和新值，同时还需要记录主键信息用于回滚时的检索。回滚时，还是根据主键信息，找到对应的记录，然后以旧换新，恢复原值即可。

•TRX_UNDO_UPD_DEL_REC：更新一条已经打了删除标志记录的UNDO日志类型。格式与上面是一样的，回滚方法也同上。

•TRX_UNDO_DEL_MARK_REC：删除记录时对记录打删除标志的UNDO日志类型，格式与上面插入操作的UNDO日志格式一样，只需要存储主键信息和表ID信息，用来在回滚或者PURGE时找到对应的记录即可。回滚时，根据主键信息，找到对应的记录，然后将删除标志去掉即完成回滚。

除了上面说到的Table ID信息、主键信息之外，还会包括一些公有的信息，比如回滚段指针、最近更新事务号，这样方便MVCC在回溯记录时可以找到以前的版本，关于MVCC的内容在这里就不详细展开了。

再回到记录格式。因为记录格式都不尽相同，所以这里只拿TRX_UNDO_INSERT_REC来举例说明，图11.13即为其格式。


图11.13
每一个位置的解释如下。

•可以看到在整个记录最前面的两个字节和最后面的两个字节是用来方便找到每一个记录的，并且通过这两条信息，就可以找到每一个UNDO页面中的所有记录，相当于是一个由UNDO记录组成的双向链表，因为对于UNDO记录，回滚过程是一个反向操作的过程，所以需要从后向前的搜索功能。

•第二个位置存储的就是UNDO记录类型。

•第三个位置存储的是一个事务的undo_no，用来区分一个事务中的多个UNDO日志的顺序。

•接下来的位置用来存储当前回滚记录对应的表ID，接下来的trx_id存储的就是更新这条记录时的事务ID，即当前事务的事务ID。

•再接着，roll_ptr用来存储当前被更新记录的上一个版本在回滚段中的位置，即这条记录中隐式列roll_ptr的值（用来在读取数据时可以找到老的版本），而当前记录的这个列的值，在写完这条UNDO日志之后，即将被修改为当前UNDO日志的位置，从而实现了一个隐式的单链表，可以使用roll_ptr的值一直回溯到第一次更新之前的版本。

•再接下来的位置，存储的就是真实的主键信息了，存储格式是用前面若干个字节存储列数据的长度，而后面接着其数据，这样依次将所有的主键列存储完。

•最后的位置，在第一点中已经介绍过了。

从图11.13中可以看到，很多位置的存储都是压缩存储的，所以上面第六点说到，列数据长度用的字节个数有可能是若干个，这决定于InnoDB所使用的压缩编码方式。

这里需要注意的一点是，与REDO日志记录存储不同，UNDO日志的存储，是不会跨页面的，所以在页面头中关于日志存储的开始位置和结束位置就至关重要了。

其他类型的回滚记录，这里就不再介绍了，大致结构是一样的，只不过内容可能不尽相同。

需要注意的一点是，假如一个表中有多个索引，在修改一行数据时，回滚日志中也只会记录聚簇索引中的信息，而其他二级索引是不会被记录的。这是因为聚簇索引和二级索引中的每一行都是一一对应的，所以不同操作对聚簇索引操作时，也都会对二级索引有相应的操作，这样就没必要对二级索引写回滚日志了。

## 回滚时刻
前面已经介绍过，UNDO日志的正确性是通过REDO的恢复来保证的，在REDO日志恢复完成之后，UNDO操作就可以安全地进行了。数据库启动过程中，执行了用于REDO恢复的函数recv_recovery_from_checkpoint_start之后，就可以处理UNDO的数据了，InnoDB通过函数trx_sys_init_at_db_start来将所有回滚段相关的128*1024个UNDO扫描出来（如果存在就找到，不存在就忽略），找到之后，每一个UNDO段的状态都已经清楚了，然后将它们都缓存起来。

然后再通过函数trx_lists_init_at_db_start依次处理每一个UNDO段，根据UNDO段的状态，决定后面将采取什么措施，如果状态为TRX_UNDO_PREPARED和TRX_UNDO_ACTIVE，则这个UNDO段是需要做回滚操作的，否则是不需要的。决定回滚需求之后，再将最多128*1024个UNDO段按照上面提到的TRX_UNDO_TRX_NO从大到小的顺序排序。

它根据参数innodb_force_recovery来决定要不要做回滚操作，如果设置为3或3以上，就不回滚了，这样可能导致数据库逻辑上的不一致。

最终，InnoDB通过trx_rollback_or_clean_recovered来做回滚操作，通过扫描上面排序之后的链表，发现其还是以从大到小的顺序遍历，这个顺序很重要，因为UNDO是反向操作，所以应该是先处理新产生的事务，后处理老的事务，通过事务号来区分新老关系。

针对每一个UNDO段，InnoDB会将所有状态为ACTIVE的事务的UNDO日志扫描出来，然后一条一条地做回滚操作，UNDO日志记录格式已经明确，扫描所有的日志就变得非常简单，并且针对不同的操作，对应的回滚方式也已经清楚，等待所有的回滚段处理完成之后，整个数据库的回滚操作也就完成了。回滚过程如图11.14所示。









































































































































































































