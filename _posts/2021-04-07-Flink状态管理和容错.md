---
layout: post
categories: [Flink]
description: none
keywords: Flink
---
# Flink状态管理和容错
本章将重点介绍Flink对有状态计算的支持，其中包括有状态计算和无状态计算的区别，以及在Flink中支持的不同状态类型，分别有Keyed State和Operator State。另外针对状态数据的持久化，以及整个Flink任务的数据一致性保障，Flink提供了Checkpoint机制处理和持久化状态结果数据。最后针对状态数据Flink提供了不同的状态管理器来管理状态数据，例如MemoryStateBackend等。

## 有状态计算
在Flink架构体系中，有状态计算可以说是Flink非常重要的特性之一。有状态计算是指在程序计算过程中，在Flink程序内部存储计算产生的中间结果，并提供给后续Function或算子计算结果使用。状态数据一致维系在本地存储中，这里的存储可以是Flink的堆内存或者堆外内存，也可以借助第三方的存储介质，例如Flink中已经实现的RocksDB，当然用户也可以自己实现相应的缓存系统去存储状态信息，以完成更加复杂的计算逻辑。和状态计算不同的是，无状态计算不会存储计算过程中产生的结果，也不会将结果用于下一步计算过程中，程序只会在当前的计算流程中实行计算，计算完成就输出结果，然后下一条数据接入，然后再处理。

无状态计算实现的复杂度相对较低，实现起来较容易，但是无法完成提到的比较复杂的业务场景，例如下面的例子：
- 用户想实现CEP（复杂事件处理），获取符合某一特定事件规则的事件，状态计算就可以将接入的事件进行存储，然后等待符合规则的事件触发；
- 用户想按照分钟、小时、天进行聚合计算，求取当前的最大值、均值等聚合指标，这就需要利用状态来维护当前计算过程中产生的结果，例如事件的总数、总和以及最大，最小值等； 
- 用户想在Stream上实现机器学习的模型训练，状态计算可以帮助用户维护当前版本模型使用的参数；
- 用户想使用历史的数据进行计算，状态计算可以帮助用户对数据进行缓存，使用户可以直接从状态中获取相应的历史数据。
以上场景充分说明了状态计算在整个流式计算过程中重要性，可以看出，在Flink引入状态这一特性，能够极大地提升流式计算过程中数据的使用范围以及指标计算的复杂度，而不再需要借助类似于Redis外部缓存存储中间结果数据，这种方式需要频繁地和外部系统交互，并造成大量系统性能开销，且不易保证数据在传输和计算过程中的可靠性，当外部存储发生变化，就可能会影响到Flink内部的计算结果。

## Flink状态类型及应用
状态类型:在Flink中根据数据集是否根据Key进行分区，将状态分为Keyed State和Operator State（Non-keyed State）两种类型。

## Keyed State
表示和key相关的一种State，只能用于KeydStream类型数据集对应的Functions和Operators之上。Keyed State是Operator State的特例，区别在于Keyed State事先按照key对数据集进行了分区，每个Key State仅对应一个Operator和Key的组合。Keyed State可以通过Key Groups进行管理，主要用于当算子并行度发生变化时，自动重新分布Keyed Sate数据。在系统运行过程中，一个Keyed算子实例可能运行一个或者多个Key Groups的keys。

## Operator State
与Keyed State不同的是，Operator State只和并行的算子实例绑定，和数据元素中的key无关，每个算子实例中持有所有数据元素中的一部分状态数据。Operator State支持当算子实例并行度发生变化时自动重新分配状态数据。

同时在Flink中Keyed State和Operator State均具有两种形式，
- 其中一种为托管状态（Managed State）形式，由Flink Runtime中控制和管理状态数据，并将状态数据转换成为内存Hash tables或RocksDB的对象存储，然后将这些状态数据通过内部的接口持久化到Checkpoints中，任务异常时可以通过这些状态数据恢复任务。
- 另外一种是原生状态（Raw State）形式，由算子自己管理数据结构，当触发Checkpoint过程中，Flink并不知道状态数据内部的数据结构，只是将数据转换成bytes数据存储在Checkpoints中，当从Checkpoints恢复任务时，算子自己再反序列化出状态的数据结构。
DataStream API支持使用Managed State和Raw State两种状态形式，在Flink中推荐用户使用Managed State管理状态数据，主要原因是Managed State能够更好地支持状态数据的重平衡以及更加完善的内存管理。

## Managed Keyed State
Flink中有以下Managed Keyed State类型可以使用，每种状态都有相应的使用场景，用户可以根据实际需求选择使用。
- ValueState[T]：与Key对应单个值的状态，例如统计user_id对应的交易次数，每次用户交易都会在count状态值上进行更新。ValueState对应的更新方法是update(T)，取值方法是T value()；
- ListState[T]：与Key对应元素列表的状态，状态中存放元素的List列表。例如定义ListState存储用户经常访问的IP地址。在ListState中添加元素使用add(T)或者addAll(List[T])两个方法，获取元素使用Iterable get()方法，更新元素使用update(List[T])方法；
- ReducingState[T]：定义与Key相关的数据元素单个聚合值的状态，用于存储经过指定ReduceFucntion计算之后的指标，因此，ReducingState需要指定ReduceFucntion完成状态数据的聚合。ReducingState添加元素使用add(T)方法，获取元素使用T get()方法；
- AggregatingState[IN,OUT]:定义与Key对应的数据元素单个聚合值的状态，用于维护数据元素经过指定AggregateFunciton计算之后的指标。和ReducingState相比，AggregatingState输入类型和输出类型不一定是相同的，但ReducingState输入和输出必须是相同类型的。和ListState相似，AggregatingState需要指定AggregateFunciton完成状态数据的聚合操作。AggregatingState添加元素使用add(IN)方法，获取元素使用OUT get()方法。
- MapState[UK,UV]：定义与Key对应键值对的状态，用于维护具有key-value结构类型的状态数据，MapState添加元素使用put(UK,UV)或者putAll(Map[UK,UV]方法，获取元素使用get(UK)方法。和HashMap接口相似，MapState也可以通过entries()、keys()、values()获取对应的keys或values的集合。

在Flink中需要通过创建StateDescriptor来获取相应State的操作类。StateDescriptor主要定义了状态的名称、状态中数据的类型参数信息以及状态自定义函数。每种Managed Keyed State有相应的StateDescriptor，例如ValueStateDescriptor、ListStateDescriptor、ReducingState-Descriptor、FoldingStateDescriptor、MapStateDescriptor等。

## Stateful Funciton定义
接下来通过完整的实例来说明如何在RichFlatmapFunction中使用ValueState，完成对接入数据最小值的获取。如代码清单5-1所示，通过定义leastValueState存储系统中指标的最小值，并在每次计算时和当前接入的数据对比，如果当前元素的数值小于状态中的最小值，则更新状态。然后在输出操作中增加对应指标的最小值作为新的数据集的字段。
通过创建ValueState来获取指标的最小值
```java
val env = StreamExecutionEnvironment.getExecutionEnvironment
//创建元素数据集
val inputStream: DataStream[(Int, Long)] = env.fromElements((2, 21L), (4, 1L), (5, 4L))
inputStream.keyBy(_._1).flatMap {
  //定义和创建RichFlatMapFunction,第一个参数为输入数据类型，第二个参数为输出数据类型
  new RichFlatMapFunction[(Int, Long), (Int, Long, Long)] {
//
    private var leastValueState: ValueState[Long] = _
    override def open(parameters: Configuration): Unit = {
      //创建ValueStateDescriptor,定义状态名称为leastValue,并指定数据类型
      val leastValueStateDescriptor = new ValueStateDescriptor[Long]("leastValue", classOf[Long])
      //通过getRuntimeContext.getState获取State
      leastValueState = getRuntimeContext.getState(leastValueStateDescriptor)
    }
    override def flatMap(t: (Int, Long), collector: Collector[(Int, Long, Long)]): Unit = {
      //通过value方法从leastValueState中获取最小值
      val leastValue = leastValueState.value()
      //如果当前指标大于最小值，则直接输出数据元素和最小值
      if (t._2 > leastValue) {
        collector.collect((t._1, t._2, leastValue))
      } else {
        //如果当前指标小于最小值，则更新状态中的最小值
        leastValueState.update(t._2)
        //将当前数据中的指标作为最小值输出
        collector.collect((t._1, t._2, t._2))
      }}}}
```
从以上代码实例中可以看出，在定义的RichFlatMapFunction接口中，Flink提供了RuntimeContext用于获取状态数据，同时RuntimeContext提供了常用的Managed Keyd State的获取方式，可以通过创建相应的StateDescriptor并调用RuntimeContext方法来获取状态数据。例如获取ValueState可以调用ValueState[T] getState(ValueStateDescriptor[T])方法，获取ReducingState可以调用ReducingState[T] getReducingState(ReducingStateDescriptor[T])方法。

## State生命周期
对于任何类型Keyed State都可以设定状态的生命周期（TTL），以确保能够在规定时间内及时地清理状态数据。状态生命周期功能可以通过StateTtlConfig配置，然后将StateTtlConfig配置传入StateDescriptor中的enableTimeToLive方法中即可。
状态生命周期配置
```java
//创建StateTtlConfig
val stateTtlConfig = StateTtlConfig
  //指定TTL时长为10s
  .newBuilder(Time.seconds(10))
  //指定TTL刷新时只对创建和写入操作有效
  .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
  //指定状态可见性为永远不反悔过期数据
  .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
  .build
//创建ValueStateDescriptor
val valueStateDescriptor = new ValueStateDescriptor[String]("valueState", classOf[Long])
//指定创建好的stateTtlConfig
valueStateDescriptor.enableTimeToLive(stateTtlConfig)
```
在StateTtlConfig中除了通过newBuilder方法中设定过期时间的参数是必需的之外，其他参数都是可选的或使用默认值。其中setUpdateType方法中传入的类型有两种：
- StateTtlConfig.UpdateType.OnCreateAndWrite仅在创建和写入时更新TTL；
- StateTtlConfig.UpdateType. OnReadAndWrite所有读与写操作都更新TTL。

需要注意的是，过期的状态数据根据UpdateType参数进行配置，只有被写入或者读取的时间才会更新TTL，也就是说如果某个状态指标一直不被使用或者更新，则永远不会触发对该状态数据的清理操作，这种情况可能会导致系统中的状态数据越来越大。目前用户可以使用StateTtlConfig. cleanupFullSnapshot设定当触发State Snapshot的时候清理状态数据，需要注意这个配置不适合用于RocksDB做增量Checkpointing的操作。

另外可以通过setStateVisibility方法设定状态的可见性，根据过期数据是否被清理来确定是否返回状态数据。
- StateTtlConfig.StateVisibility.NeverReturnExpired：状态数据过期就不会返回（默认）；
- StateTtlConfig.StateVisibility.ReturnExpiredIfNotCleanedUp：状态数据即使过期但没有被清理依然返回。

## Scala DataStream API中直接使用状态
除了通过定义RichFlatMapFunction或者FichMapFunction操作状态之外，Flink Scala版本的DataStream API提供了快捷方式来创建和查询状态数据。在KeyedStream接口中提供了filterWithState、mapWithState、flatMapWithState三种方法来定义和操作状态数据，以mapWithState为例，可以在mapWithState指定输入参数类型和状态数据类型，系统会自动创建count对应的状态来存储每次更新的累加值，整个过程不需要像实现RichFunciton那样操作状态数据。
使用mapuwithState直接操作状态数据
```java
//创建元素数据集
val inputStream: DataStream[(Int, Long)] = env.fromElements((2, 21L), (4, 1L), (5, 4L))
val counts: DataStream[(Int, Int)] = inputStream
  .keyBy(_._1)
  //指定输入参数类型和状态参数类型
  .mapWithState((in: (Int, Long), count: Option[Int]) =>
    //判断count类型是否非空
    count match {
        //输出key,count,并在原来的count数据上累加
      case Some(c) => ((in._1, c), Some(c + in._2))
        //如果输入状态为空，则将指标填入
      case None => ((in._1, 0), Some(in._2))
    })
```
## Managed Operator State
Operator State是一种non-keyed state，与并行的操作算子实例相关联，例如在Kafka Connector中，每个Kafka消费端算子实例都对应到Kafka的一个分区中，维护Topic分区和Offsets偏移量作为算子的Operator State。在Flink中可以实现Checkpointed-Function或者ListCheckpointed<T extends Serializable>两个接口来定义操作Managed Operator State的函数。
- 通过CheckpointedFunction接口操作Operator State
CheckpointedFunction接口定义需要实现两个方法，当checkpoint触发时就会调用snapshotState()方法，当初始化自定义函数的时候会调用initializeState()方法，其中包括第一次初始化函数和从之前的checkpoints中恢复状态数据，同时initializeState()方法中需要包含两套逻辑，一个是不同类型状态数据初始化的逻辑，另外一个是从之前的状态中恢复数据的逻辑。
```java
// CheckpointedFunction接口定义
public interface CheckpointedFunction {
  //每当checkpoint触发时，调用此方法
void snapshotState(FunctionSnapshotContext context) throws Exception;
  //每次自定义函数初始化的时候，调用此方法初始化状态
void initializeState(FunctionInitializationContext context) throws Exception;}
```
在每个算子中Managed Operator State都是以List形式存储，算子和算子之间的状态数据相互独立，List存储比较适合于状态数据的重新分布，Flink目前支持对Managed Operator State两种重分布的策略，分别是Even-split Redistribution和Union Redistribution。
- Even-split Redistribution：每个算子实例中含有部分状态元素的List列表，整个状态数据是所有List列表的合集。当触发restore/redistribution动作时，通过将状态数据平均分配成与算子并行度相同数量的List列表，每个task实例中有一个List，其可以为空或者含有多个元素。
- Union Redistribution：每个算子实例中含有所有状态元素的List列表，当触发restore/redistribution动作时，每个算子都能够获取到完整的状态元素列表。
例如可以通过实现FlatMapFunction和CheckpointedFunction完成对输入数据中每个key的数据元素数量和算子的元素数量的统计。通过在initializeState()方法中分别创建keyedState和operatorState两种状态，存储基于Key相关的状态值以及基于算子的状态值。

## 实现CheckpointedFunction接口利用Operator State统计输入到算子的数据量
```java
private class CheckpointCount(val numElements: Int)
  extends FlatMapFunction[(Int, Long), (Int, Long, Long)] with CheckpointedFunction {
  //定义算子实例本地变量，存储Operator数据数量
  private var operatorCount: Long = _
  //定义keyedState，存储和Key相关的状态值
  private var keyedState: ValueState[Long] = _
  //定义operatorState，存储算子的状态值
  private var operatorState: ListState[Long] = _
  override def flatMap(t: (Int, Long), collector: Collector[(Int, Long, Long)]): Unit = {
    val keyedCount = keyedState.value() + 1
    //更新keyedState数量
    keyedState.update(keyedCount)
    //更新本地算子operatorCount值
    operatorCount = operatorCount + 1
    //输出结果，包括id,id对应的数量统计keyedCount，算子输入数据的数量统计operatorCount
    collector.collect((t._1, keyedCount, operatorCount))
  }

  //初始化状态数据
  override def initializeState(context: FunctionInitializationContext): Unit = {
    //定义并获取keyedState
    keyedState = context.getKeyedStateStore.getState(
      new ValueStateDescriptor[Long](
        "keyedState", createTypeInformation[Long]))
    //定义并获取operatorState
    operatorState = context.getOperatorStateStore.getListState(
      new ListStateDescriptor[Long](
        "operatorState", createTypeInformation[Long]))
    //定义在Restored过程中，从operatorState中恢复数据的逻辑
    if (context.isRestored) {
      operatorCount = operatorState.get().asScala.sum
    }
  }
    //当发生snapshot时，将operatorCount添加到operatorState中
  override def snapshotState(context: FunctionSnapshotContext): Unit = {
    operatorState.clear() 
    operatorState.add(operatorCount)
    }}
```
可以从上述代码中看到的是，在snapshotState()方法中清理掉上一次checkpoint中存储的operatorState的数据，然后再添加并更新本次算子中需要checkpoint的operatorCount状态变量。当系统重启时会调用initializeState方法，重新恢复keyedState和operatorState，其中operatorCount数据可以从最新的operatorState中恢复。

对于状态数据重分布策略的使用，可以在创建operatorState的过程中通过相应的方法指定：如果使用Even-split Redistribution策略，则通过context. getListState(descriptor)获取Operator State；如果使用Union Redistribution策略，则通过context. getUnionList State(descriptor)来获取。实例代码中默认使用的Even-split Redistribution策略。

## 通过ListCheckpointed接口定义Operator State

ListCheckpointed接口和CheckpointedFunction接口相比在灵活性上相对弱一些，只能支持List类型的状态，并且在数据恢复的时候仅支持even-redistribution策略。在ListCheckpointed接口中需要实现以下两个方法来操作Operator State：
```java
List<T> snapshotState(long checkpointId, long timestamp) throws Exception;
void restoreState(List<T> state) throws Exception;
```
其中snapshotState方法定义数据元素List存储到checkpoints的逻辑，restoreState方法则定义从checkpoints中恢复状态的逻辑。如果状态数据不支持List形式，则可以在snapshotState方法中返回Collections.singletonList(STATE)。如代码清单5-6所示，通过实现FlatMapFunction接口和ListCheckpointed接口完成对输入到FlatMapFunction算子中的数据量统计，同时在函数中实现了snapshotState方法，将本地定义的算子变量numberRecords写入Operator State中，并通过restoreState方法从状态中恢复numberRecords数据。
实现ListCheckpointed接口利用Operator State统计算子输入数据量
```java
class numberRecordsCount extends FlatMapFunction[(String, Long), (String, 
Long)] with ListCheckpointed[Long] {
  //定义算子中接入的numberRecords数量
  private var numberRecords: Long = 0L
  override def flatMap(t: (String, Long), collector: Collector[(String, Long)]): Unit = {
    //接入一条记录则进行统计，并输出
    numberRecords += 1
    collector.collect(t._1, numberRecords)
  }
  override def snapshotState(checkpointId: Long, ts: Long): util.List[Long] = {
    //Snapshot状态的过程中将numberRecords写入
    Collections.singletonList(numberRecords)
  }
  override def restoreState(list: util.List[Long]): Unit = {
    numberRecords = 0L
    for (count <- list) {
      //从状态中恢复numberRecords数据
      numberRecords += count }}}
```

## Checkpoints

## Checkpoints检查点机制
Flink中基于异步轻量级的分布式快照技术提供了Checkpoints容错机制，分布式快照可以将同一时间点Task/Operator的状态数据全局统一快照处理，包括前面提到的Keyed State和Operator State。Flink会在输入的数据集上间隔性地生成checkpoint barrier，通过栅栏（barrier）将间隔时间段内的数据划分到相应的checkpoint中。当应用出现异常时，Operator就能够从上一次快照中恢复所有算子之前的状态，从而保证数据的一致性。例如在KafkaConsumer算子中维护Offset状态，当系统出现问题无法从Kafka中消费数据时，可以将Offset记录在状态中，当任务重新恢复时就能够从指定的偏移量开始消费数据。对于状态占用空间比较小的应用，快照产生过程非常轻量，高频率创建且对Flink任务性能影响相对较小。checkpoint过程中状态数据一般被保存在一个可配置的环境中，通常是在JobManager节点或HDFS上。

默认情况下Flink不开启检查点的，用户需要在程序中通过调用enable-Checkpointing(n)方法配置和开启检查点，其中n为检查点执行的时间间隔，单位为毫秒。除了配置检查点时间间隔，针对检查点配置还可以调整其他相关参数：

### Checkpoint开启和时间间隔指定
开启检查点并且指定检查点时间间隔为1000ms，根据实际情况自行选择，如果状态比较大，则建议适当增加该值。
```java
env.enableCheckpointing(1000);
```

### exactly-ance和at-least-once语义选择
可以选择exactly-once语义保证整个应用内端到端的数据一致性，这种情况比较适合于数据要求比较高，不允许出现丢数据或者数据重复，与此同时，Flink的性能也相对较弱，而at-least-once语义更适合于时廷和吞吐量要求非常高但对数据的一致性要求不高的场景。如下通过setCheckpointingMode()方法来设定语义模式，默认情况下使用的是exactly-once模式。
```java
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
```
### Checkpoint超时时间
超时时间指定了每次Checkpoint执行过程中的上限时间范围，一旦Checkpoint执行时间超过该阈值，Flink将会中断Checkpoint过程，并按照超时处理。该指标可以通过setCheckpointTimeout方法设定，默认为10分钟。
```java
env.getCheckpointConfig().setCheckpointTimeout(60000);
```
### 检查点之间最小时间间隔
该参数主要目的是设定两个Checkpoint之间的最小时间间隔，防止出现例如状态数据过大而导致Checkpoint执行时间过长，从而导致Checkpoint积压过多，最终Flink应用密集地触发Checkpoint操作，会占用了大量计算资源而影响到整个应用的性能。
```java
env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);
```
### 最大并行执行的检查点数量
通过setMaxConcurrentCheckpoints()方法设定能够最大同时执行的Checkpoint数量。在默认情况下只有一个检查点可以运行，根据用户指定的数量可以同时触发多个Checkpoint，进而提升Checkpoint整体的效率。
```java
env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);
```
### 外部检查点
设定周期性的外部检查点，然后将状态数据持久化到外部系统中，使用这种方式不会在任务正常停止的过程中清理掉检查点数据，而是会一直保存在外部系统介质中，另外也可以通过从外部检查点中对任务进行恢复。
```java
env.getCheckpointConfig().enableExternalizedCheckpoints(ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);
```
### failOnCheckpointingErrors
