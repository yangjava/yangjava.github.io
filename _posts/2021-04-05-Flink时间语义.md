---
layout: post
categories: [Flink]
description: none
keywords: Flink
---
# Flink时间
在流处理中，时间是一个核心的概念，是整个系统的基石。

## 时间概念类型
对于流式数据处理，最大的特点是数据上具有时间的属性特征，Flink根据时间产生的位置不同，将时间区分为三种时间概念，分别为

- 事件生成时间（Event Time）
数据从终端产生，或者从系统中产生的过程中生成的时间为事件生成时间。是事件创建的时间。它通常由事件中的时间戳描述， 例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问事件时间戳。

使用Event Time，在理想情况下可以一直等待所有事件到达后再进行时间窗口的处理，最终结果是正确且一致的，并且不用担心乱序的问题。但是实际应用中，在涉及到按时间窗口进行统计时，会将窗口内的事件缓存下来，直到接收到一个watermark。Watermark意味着在一个时间窗口下，Flink会等待一个有限的时间，这在一定程度上降低了计算结果的绝对准确性，而且增加了系统的延迟。

- 事件接入时间（Ingestion Time）
当数据经过消息中间件传入到Flink系统中，在DataSource中接入的时候会生成事件接入时间。是数据进入Flink的时间。从源端到下游各个算子中间可能有很多计算环节，任何一个算子处理速度的快慢都可能影响到下游算子的Processing Time。而Ingestion Time是数据流最早进入Flink的时间，因此不会被算子的处理效率影响。

Ingestion Time在概念上是位于Event Time和Processing Time之间，比Processing Time稍早，不需要指定Watermark

- 事件处理时间（Processing Time）
当数据在Flink系统中通过各个算子实例执行转换操作的过程中，算子实例所在系统的时间为数据处理时间。是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是Processing Time。在Processing Time时间窗口下，无论事件什么时候发生，只要该事件在某个时间段到达了某个算子，就会被归结为该窗口。

Processing Time只依赖当前节点的操作系统时间，无需缓存，实现起来更简单，延迟更小。

在Flink的流式处理中，绝大部分的业务都会使用EventTime，一般只在EventTime无法使用时，才会被迫使用ProcessingTime 或者IngestionTime。

### 事件时间（Event Time）
事件时间（Event Time）是每个独立事件在产生它的设备上发生的时间，这个时间通常在事件进入Flink之前就已经嵌入到事件中，时间顺序取决于事件产生的地方，和下游数据处理系统的时间无关。事件数据具有不变的事件时间属性，该时间自事件元素产生就不会改变。通常情况下可以在Flink系统中指定事件时间属性或者设定时间提取器来提取事件时间。

所有进入到Flink流式系统处理的事件，其时间都是在外部系统中产生，经过网络进入到Flink系统内处理的，在理论情况下（所有系统都具有相同系统时钟），事件时间对应的时间戳一定会早于在Flink系统中处理的时间戳，但在实际情况中往往会出现数据记录乱序、延迟到达等问题。基于EventTime的时间概念，数据处理过程依赖于数据本身产生的时间，而不是Flink系统中Operator所在主机节点的系统时间，这样能够借助于事件产生时的时间信息来还原事件的先后关系。

### 接入时间（Ingestion Time）
接入时间（Ingestion Time）是数据进入Flink系统的时间，Ingestion Time依赖于Source Operator所在主机的系统时钟。Ingestion Time介于Event Time和Process Time之间，相对于Process Time，Ingestion Time生成的代价相对较高，Ingestion Time具有一定的可预见性，主要因为Ingestion Time在数据接入过程生成后，时间戳就不再发生变化，和后续数据处理Operator所在机器的时钟没有关系，从而不会因为某台机器时钟不同步或网络时延而导致计算结果不准确的问题。但是需要注意的是相比于Event Time，Ingestion Time不能处理乱序事件，所以也就不用生成对应的Watermarks。

### 处理时间（Processing Time）
处理时间（Processing Time）是指数据在操作算子计算过程中获取到的所在主机时间。当用户选择使用Processing Time时，所有和时间相关的计算算子，例如Windows计算，在当前的任务中所有的算子将直接使用其所在主机的系统时间。Processing Time是Flink系统中最简单的一种时间概念，基于Processing Time时间概念，Flink的程序性能相对较高，延时也相对较低，对接入到系统中的数据时间相关的计算完全交给算子内部决定，时间窗口计算依赖的时间都是在具体算子运行的过程中产生，不需要做任何时间上的对比和协调。但Processing Time时间概念虽然在性能和易用性的角度上具有优势，但考虑到对数据乱序处理的情况，Processing Time就不是最优的选择。同时在分布式系统中，数据本身不乱序，但每台机器的时间如果不同步，也可能导致数据处理过程中数据乱序的问题，从而影响计算结果。总之，Processing Time概念适用于时间计算精度要求不是特别高的计算场景，例如统计某些延时非常高的日志数据等。

## 时间概念指定
1.12版本默认是根据EventTime,之前版本默认是采用ProcessingTime。渐渐的，摄入时间（IngestionTime）越来越不推荐使用了，实际上就生产而言，我们更多选择是根据业务采用不同的窗口分配器，选择根据事件时间还是处理时间进行计算。

用户需要在创建的StreamExecutionEnvironment中调用setStream-TimeCharacteristic()方法设定系统的时间概念

如下代码使用TimeCharacteristic.EventTime作为系统的时间概念，这样对当前的StreamExecutionEnvironment会全局生效。对应的。
```java
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.TimeCharacteristic;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

public class SteamWordCount {

    public static void main(String[] args) throws Exception {
        // 创建流处理执行环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        // 设置时间
        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

        DataStreamSource<Tuple2<String, Integer>> resultStream = env.fromElements(Tuple2.of("Hello", 1683797649), Tuple2.of("World", 1683797649));
        // 指定计算结果输出位置
        resultStream.print();
        // 指定名称并触发流式任务
        env.execute("Stream");
    }

}
```

## Watermark（水位线）
Flink的三种时间语义中，只有Event Time需要设置Watermark 。流式数据从产生到处理中间经过了很多过程，中间因为网络等原因可能会出现乱序，导致Flink接收到的事件的先后顺序不是严格按照Event Time的先后顺序排了的。一旦出现乱序，如果只根据EventTime决定window的运行，不能明确数据是否全部到位，但又不能无限期的等下去，此时必须要有个机制来保证一个特定的时间后，必须触发window去进行计算了，这个特别的机制，就是 Watermark。 Watermark本质上是Flink插入到数据流中的一种特殊的数据结构，它包含一个时间戳，并假设后续不会有小于该时间戳的数据 。

通常情况下，由于网络或系统等外部因素影响，事件数据往往不能及时传输至Flink系统中，导致数据乱序到达或者延迟到达等问题，因此，需要有一种机制能够控制数据处理的过程和进度，比如基于事件时间的Window创建后，具体该如何确定属于该Window的数据元素已经全部到达。如果确定全部到达，就可以对Window的所有数据做窗口计算操作（如汇总、分组等），如果数据没有全部到达，则继续等待该窗口中的数据全部到达才开始处理。这种情况下就需要用到水位线（WaterMarks）机制，它能够衡量数据处理进度（表达数据到达的完整性），保证事件数据（全部）到达Flink系统，或者在乱序及延迟到达时，也能够像预期一样计算出正确并且连续的结果。Flink会将用读取进入系统的最新事件时间减去固定的时间间隔作为Watermark，该时间间隔为用户外部配置的支持最大延迟到达的时间长度，也就是说理论上认为不会有事件超过该间隔到达，否则就认为是迟到事件或异常事件。

## 水位线的定义
在事件时间的语义下，不依赖系统时间，而是基于数据自带的时间戳去定义一个时钟，用来表示当前时间的进展。

在数据流中加入一个时钟标记，记录当前的事件时间，这个标记可以直接广播到下游，当下游任务收到这个标记，就可以更新自己的时钟了，这种类似于水流中用来做标志的记号，在Flink中被称为水位线

## watermark基本概念
在使用Event time时,我们需要思考一个问题，对于一个无限的数据流，窗口大小的情况下，如何确定窗口内的数据都已经全部都到了？例如，现在的窗口大小是1小时。对于有序的数据流而言，我们只需要判断数据的时间即可。08:01的数据一定是在08：02之前进入应用，当09:00的数据到达时，Flink就知道可以操作08:00~09:00的数据了。

但是在我们实际的应用环境中，大部分的数据流都是无序的，而且影响因素可能有很多。在这种情况下，8:58的数据可能是在9点之后才到的，这种情况下，我们的窗口操作又该在何时执行呢？

上面的问题总结一下就是：1. Flink如何确定窗口内的数据全部都到齐了？ 2. Flink如何对待数据流中迟到的数据？

为了解决上面的问题，需要用到Flink中的Watermark(时间水印)机制。Watermark能够衡量数据进度，确保数据在乱序情况下也能被正常处理，得出连续的结果。Watermark作为数据流中一部分随数据流入下游，当一个watermark(t)到达下游时就表示后面的数据时间都是迟于t。

在Flink中用户可以配置大延迟的时间间隔，Flink会用新的数据时间减去这个间隔来更新watermark。当watermark时间大于窗口结束时间，且窗口中有数据时，就会立刻触发窗口计算。例如，我们以30分钟做为大延迟间隔，窗口大小为1个小时，那么窗口时间就应该为(00:00-01:00),(02:00-03:00)...(23:00-00:00)。假设现在有一条03:31的数据进入应用,它减去半个小时就是03:01大于(02:00-03:00)的结束时间，那么就认为没有数据时间迟于03:00了，此时如果窗口内有数据就会立马触发窗口计算。这个计算需要通过延迟间隔和新的数据计算，判断是否已经超过了窗口允许的延迟时间。设置半个小时就意味着每个窗口的数据可以迟到半个小时。如果真的有数据超过了这个延迟时间，那我们就需要指定这类迟到数据的处理策略了。

### 顺序数据流中的watermark
在数据有序的情况下，10:00的数据到达时，我们就知道09:00~10:00的窗口可以操作了，因为不会有比10点还早的数据了，所有09:00~10:00窗口内的时间都已经到了。但是因为我们甚至了30分钟的watermark，10点减去半个小时为09:30小于窗口的结束时间，所以它会等，一直等到10：31数据来了之后，10:31减半个小时大于10:00。原本早就可以执行的计算现在多等了半个小时，所以在数据流有序的情况，并不能很好的发挥watermark的作用，反而会增加应用的延迟。

### 乱序数据流中的watermark
在实际环境中使用event time，我们也会遇到因为网络阻塞或者其他原因导致的无序数据流。在这种情况下watermark便可以保证窗口内的数据按照指定的窗口大小和延迟时间进行计算。值得注意的是，Flink的延迟时间是相对于event time而言的，不是根据系统时间来匹配的。就是说，如果我们设置的窗口大小为1个小时，延迟时间是10分钟。对于(09:00~10:00)的窗口而言，它不一定是会在系统时间超过10:10后计算，因为此刻不一定有时间戳大于10:10的数据到来。只有当watermark大于窗口结束时间时才会进行窗口操作，watermark一般都是根据event time计算的。

```
                                     09:00   ------  10:00 
[09:00] [10:09] [09:38] [10:01] |    [09:50]  [09:40] [09:01]    |
```
假设窗口大小为1小时，延迟时间设为10分钟。明显，数据09:38已经迟到，但它依然会被正确计算，只有当有数据时间大于10:10的数据到达之后（即对应的watermark大于10:10-10min) 09:00~10:00的窗口才会执行计算。

### 并行数据流中的watermark
对应并行度大于1的source task，它每个独立的subtask都会生成各自的watermark。这些watermark会随着流数据一起分发到下游算子，并覆盖掉之前的watermark。当有多个watermark同时到达下游算子的时候，flink会选择较小的watermark进行更新。当一个task的watermark大于窗口结束时间时，就会立马触发窗口操作。

## 水位线的生成
计算处理更快、实时性更强、计算准确性尽可能得到保障，我们就需要设置合理的水位线。

### 水位线生成策略
在Flink的DataStream API中，有一个单独用于生成水位线的方法：assignTimestampsAndWatermarks()，它主要用来为流中的数据分配时间戳，并生成水位线来指示事件时间：
```
public SingleOutputStreamOperator<T> assignTimestampsAndWatermarks(
         WatermarkStrategy<T> watermarkStrategy)
```
上述方法需要传入一个watermarkStrategy参数，这就是所谓的水位线生成策略
```java
public interface WatermarkStrategy<T> extends TimestampAssignerSupplier<T>,
	WatermarkGeneratorSupplier<T>{
 		@Override
 		TimestampAssigner<T> createTimestampAssigner(TimestampAssignerSupplier.Context context);
 		@Override
 		WatermarkGenerator<T> createWatermarkGenerator(WatermarkGeneratorSupplier.Context context);
}
```
- TimestampAssigner：主要负责从流中数据元素的某个字段中提取时间戳，并分配给元素。时间戳的分配是生成水位线的基础
- WatermarkGenerator：主要负责按照既定方式，基于时间戳生成水位线。在WatermarkGenerator接口中有两个方法：onEvent，onPeriodicEmit
- onEvent：每个事件（数据）到来都会调用的方法，它的参数有当前事件、时间戳，以及允许发出水位线的一个WatermarkOutput，可以基于事件做出各种操作
- onPeriodicEmit：周期性调用的方法，可以由WatermarkOutput发出水位线。周期时间为处理时间，可以调用环境配置的…setAutoWatermarkInterval()方法来设置，默认为200ms

```java
public interface WatermarkGenerator<T> {
    void onEvent(T event, long eventTimestamp, WatermarkOutput output);
    void onPeriodicEmit(WatermarkOutput output);
}
```

### Flink内置水位线生成器
WatermarkStrategy这个接口是一个生成水位线策略的抽象，让我们可以灵活地实现自己的需求，如果想要自己实现还是比较麻烦的。

Flink提供了内置的水位线生成器WatermarkGenerator，不仅开箱即用简化了编程，而且也为我们自定义水位线策略提供了模板。
- 固定延迟生成水印 forBoundedOutOfOrderness
- 单调递增生成水印 forMonotonousTimestamps

#### 固定延迟生成水印
通过静态方法forBoundedOutOfOrderness提供,入参接收一个Duration类型的时间间隔，也就是我们可以接受的最大的延迟时间.使用这种延迟策略的时候需要我们对数据的延迟时间有一个大概的预估判断。
```
WatermarkStrategy#forBoundedOutOfOrderness(Duration maxOutOfOrderness)
```
我们实现一个延迟3秒的固定延迟水印，可以这样做：
```
DataStream dataStream = ...... ;
dataStream.assignTimestampsAndWatermarks(WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(3)));
```
他的底层使用的WatermarkGenerator接口的一个实现类BoundedOutOfOrdernessWatermarks。
```
 @Override
 public void onEvent(T event, long eventTimestamp, WatermarkOutput output) {
  maxTimestamp = Math.max(maxTimestamp, eventTimestamp);
 }

 @Override
 public void onPeriodicEmit(WatermarkOutput output) {
  output.emitWatermark(new Watermark(maxTimestamp - outOfOrdernessMillis - 1));
 }
```

#### 单调递增生成水印
通过静态方法forMonotonousTimestamps来提供.
```
WatermarkStrategy.forMonotonousTimestamps()
```
这个也就是相当于上述的延迟策略去掉了延迟时间，以event中的时间戳充当了水印。

在程序中可以这样使用：
```
DataStream dataStream = ...... ;
dataStream.assignTimestampsAndWatermarks(WatermarkStrategy.forMonotonousTimestamps());
```
它的底层实现是AscendingTimestampsWatermarks，其实它就是BoundedOutOfOrdernessWatermarks类的一个子类，没有了延迟时间，我们来看看具体源码的实现.
```
@Public
public class AscendingTimestampsWatermarks<T> extends BoundedOutOfOrdernessWatermarks<T> {

 /**
  * Creates a new watermark generator with for ascending timestamps.
  */
 public AscendingTimestampsWatermarks() {
  super(Duration.ofMillis(0));
 }
}
```

这两个生成器可以通过调用WatermarkStrategy 的静态辅助方法来创建。它们都是周期性 生成水位线的，分别对应着处理有序流和乱序流的场景
```java
import com.demo.Source.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

import java.time.Duration;

public class WatermarkTest {

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        env.getConfig().setAutoWatermarkInterval(100);

        //从元素中读取数据
        SingleOutputStreamOperator<Event> stream = env.fromElements(
                new Event("Mary", "./home", 1000L),
                new Event("Bob", "./cart", 2000L),
                new Event("Alice", "./prod?id=100", 3000L),
                new Event("Bob", "./prod?id=1", 3300L),
                new Event("Bob", "./home", 3500L),
                new Event("Alice", "./prod?id=200", 3200L),
                new Event("Bob", "./prod?id=2", 3800L),
                new Event("Bob", "./prod?id=3", 4200L))
                //有序流的watermark生成
//                .assignTimestampsAndWatermarks(WatermarkStrategy
//                        .<Event>forMonotonousTimestamps()
//                        .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
//                            @Override
//                            public long extractTimestamp(Event element, long recordTimestamp) {
//                                return element.timestamp;
//                            }
//                        }))
                //乱序流的watermark生成
                .assignTimestampsAndWatermarks(WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(2))
                        .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
                            @Override
                            public long extractTimestamp(Event element, long recordTimestamp) {
                                return element.timestamp;
                            }
                        }));

        env.execute();
    }
}
```
事实上，有序流的水位线生成器本质上和乱序流式一样的，相当于延迟设为0的乱序流水位线生成器，两者完全相同：
```
WatermarkStrategy.forMonotonousTimestamps()
WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(0))
```
注意：乱序流中生成的水位线真正的时间戳，其实是当前最大时间戳 - 延迟时间 - 1，这里单位是毫秒。
```
public void onPeriodicEmit(WatermarkOutput output) {
 	output.emitWatermark(new Watermark(maxTimestamp - outOfOrdernessMillis - 1));
}
```

## 自定义水位线策略
一般来说，Flink内置的水位线生成器就可以满足应用需求了。不过有时我们得业务逻辑可能非常复杂，这就必须自定义实现水位线策略WatermarkStrategy。WatermarkGenerator接口中有两个方法：onEvent()、onPeriodicEmit()，前者是在每个时间到来时调用，后者由框架周期性调用。周期性调用的方法中发出水位线，自然就是周期性生成水位线；而在事件触发的方法中发出水位线，自然就是断点式生成了。两种方式的不同就集中体现在这两个方法的实现上

### 周期性水位线生成器
周期性生成器一般是通过onEvent()观察判断输入的事件，而在onPeriodicEmit()里发出水位线
```java
import com.yingzi.chapter05.Source.ClickSource;
import com.yingzi.chapter05.Source.Event;
import org.apache.flink.api.common.eventtime.*;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

public class CustomWatermarkTest {

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        env.addSource(new ClickSource())
                .assignTimestampsAndWatermarks(new CustomWatermarkStrategy()).print();

        env.execute();
    }

    public static class CustomWatermarkStrategy implements WatermarkStrategy<Event> {
        @Override
        public TimestampAssigner<Event> createTimestampAssigner(TimestampAssignerSupplier.Context context) {
            return new SerializableTimestampAssigner<Event>() {
                @Override
                public long extractTimestamp(Event element, long recordTimestamp) {
                    return element.timestamp; // 告诉程序数据源里的时间戳是哪一个字段
                }
            };
        }

        @Override
        public WatermarkGenerator<Event>
        createWatermarkGenerator(WatermarkGeneratorSupplier.Context context) {
            return new CustomPeriodicGenerator();
        }
    }

    public static class CustomPeriodicGenerator implements WatermarkGenerator<Event> {
        private Long delayTime = 5000L; // 延迟时间
        private Long maxTs = Long.MIN_VALUE + delayTime + 1L; // 观察到的最大时间戳

        @Override
        public void onEvent(Event event, long eventTimestamp, WatermarkOutput
                output) {
            // 每来一条数据就调用一次
            maxTs = Math.max(event.timestamp, maxTs); // 更新最大时间戳
        }

        @Override
        public void onPeriodicEmit(WatermarkOutput output) {
            // 发射水位线，默认 200ms 调用一次
            output.emitWatermark(new Watermark(maxTs - delayTime - 1L));
        }
    }
}
```

### 断点式水位线生成器
断点式生成器会不停地检测onEvent()中的事件，当发现带有水位线信息的特殊事件时，立即发出水位线。一般来说，断点式生成器不会通过onPeriodicEmit()发出水位线

```java
public class CustomPunctuatedGenerator implements WatermarkGenerator<Event> {
	@Override
 	public void onEvent(Event r, long eventTimestamp, WatermarkOutput output) {
	// 只有在遇到特定的 itemId 时，才发出水位线
 		if (r.user.equals("Mary")) {
 			output.emitWatermark(new Watermark(r.timestamp - 1));
 		}
 	}
     @Override
     public void onPeriodicEmit(WatermarkOutput output) {
     	// 不需要做任何事情，因为我们在 onEvent 方法中发射了水位线
     }
}
```
我们在 onEvent()中判断当前事件的 user 字段，只有遇到“Mary”这个特殊的值时，才调用 output.emitWatermark()发出水位线。这个过程是完全依靠事件来触发的，所以水位线的生成一 定在某个数据到来之后

## 在自定义数据源中发送水位线
我们也可以在自定义的数据源中抽取事件时间，然后发送水位线。这里要注意的是，在自 定义数据源中发送了水位线以后，就不能再在程序中使用 assignTimestampsAndWatermarks 方 法 来 生 成 水 位 线 了 。 在 自 定 义 数 据 源 中 生 成 水 位 线 和 在 程 序 中 使 用 assignTimestampsAndWatermarks 方法生成水位线二者只能取其一。

在自定义水位线中生成水位线相比 assignTimestampsAndWatermarks 方法更加灵活，可以 任意的产生周期性的、非周期性的水位线，以及水位线的大小也完全由我们自定义。所以非常 适合用来编写 Flink 的测试程序，测试 Flink 的各种各样的特性
```java
import com.demo.Source.Event;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.source.SourceFunction;
import org.apache.flink.streaming.api.watermark.Watermark;

import java.util.Calendar;
import java.util.Random;

public class EmitWatermarkInSourceFunction {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);

        env.addSource(new ClickSourceWithWatermark()).print();
        env.execute();
    }

    // 泛型是数据源中的类型
    public static class ClickSourceWithWatermark implements SourceFunction<Event> {
        private boolean running = true;

        @Override
        public void run(SourceContext<Event> sourceContext) throws Exception {
            Random random = new Random();
            String[] userArr = {"Mary", "Bob", "Alice"};
            String[] urlArr = {"./home", "./cart", "./prod?id=1"};
            while (running) {
                long currTs = Calendar.getInstance().getTimeInMillis(); // 毫秒时间戳
                String username = userArr[random.nextInt(userArr.length)];
                String url = urlArr[random.nextInt(urlArr.length)];
                Event event = new Event(username, url, currTs);
                // 使用 collectWithTimestamp 方法将数据发送出去，并指明数据中的时间戳的字段
                sourceContext.collectWithTimestamp(event, event.timestamp);
                // 发送水位线
                sourceContext.emitWatermark(new Watermark(event.timestamp - 1L));
                Thread.sleep(1000L);
            }
        }

        @Override
        public void cancel() {
            running = false;
        }
    }
}
```
在实际应用中往往上下游都有多个并行子任务，为了统一推进事件时间的进展，我们要求上游任务处理完水位线、时钟改变之后，要把当前的水位线广播给所有的下游任务。这样，后续任务就不需要依赖原始数据中的时间戳，也可以知道当前事件时间了。

上游并行子任务发来不同的水位线，当前任务会为每一个分区设置一个“分区水位线” （Partition Watermark），这是一个分区时钟；而当前任务自己的时钟，就是所有分区时钟里最小的那个。

## event时间的获取
上述我们讲了flink自带的两种水印生成策略，但是对于我们使用eventtime语义的时候，我们想从我们的自己的数据中抽取eventtime，这个就需要TimestampAssigner了
```
@Public
@FunctionalInterface
public interface TimestampAssigner<T> {

    ............
    
 long extractTimestamp(T element, long recordTimestamp);
}
```
使用的时候我们主要就是从我们自己的元素element中提取我们想要的eventtime。

使用flink自带的水印策略和eventtime抽取类，可以这样用：
```
DataStream dataStream = ...... ;
dataStream.assignTimestampsAndWatermarks(
    WatermarkStrategy
      .<Tuple2<String,Long>>forBoundedOutOfOrderness(Duration.ofSeconds(5))
      .withTimestampAssigner((event, timestamp)->event.f1));
```

## 水位线的总结
水位线在事件时间的世界里面，承担了时钟的角色，是唯一的时间尺度。

水位线的默认计算公式：水位线 = 观察到的最大事件时间 – 最大延迟时间 – 1 毫秒

在数据流开始之前，Flink 会插入一个大小是负无穷大的水位线，而在数据流结束时，Flink 会插入一个正无穷大)的水位线，保证所有的窗口闭合以及所有的定时器都被触发。

对于离线数据集，Flink 也会将其作为流读入，也就是一条数据一条数据的读取。在这种 情况下，Flink 对于离线数据集，只会插入两次水位线，也就是在最开始处插入负无穷大的水 位线，在结束位置插入一个正无穷大的水位线。因为只需要插入两次水位线，就可以保证计算的正确，无需在数据流的中间插入水位线了

## 窗口
Flink是一个流式计算框架，在流处理应用中，数据是连续不断的；但有时候的业务需求，需要我们在在流的基础上做一定的聚合处理。比如过去一分钟用户点击量、过去一小时订单成交额等等

Flink引入了窗口这个概念，窗口（Window）是Flink程序中算子之一，是处理无限的核心。窗口将流分成有限大小的“存储块”，我们可以在其上应用计算。

窗口更像一个“桶”，将流切割成有限大小的多个存储桶，每个数据都会分发到对应的桶中，当到达窗口结束时间时，就对每个桶中收集的数据进行计算处理。
- 动态创建：当有落在这个窗口区间范围的数据到达时，才创建对应的窗口
- 窗口关闭：到达窗口结束时间时，窗口就触发计算并关闭

## 窗口的分类

## 按照驱动类型分类
以什么标准来开始和结束数据的截取，我们把它叫做窗口的“驱动类型”，常见的有时间窗口、计数窗口。

计数窗口（Count Window）
- 基于数量的窗口，根据固定的数量定义窗口的大小，例如每5000条数据形成一个窗口，窗口中接入的数据依赖于数据接入到算子中的顺序，如果数据出现乱序情况，将导致窗口的计算结果不确定。在Flink中可以通过调用DataSteam API中的countWindows()来定义基于数量的窗口。
时间窗口
- 基于时间的窗口，窗口基于起始时间戳（闭区间）和终止时间戳（开区间）来决定窗口的大小，数据根据时间戳被分配到不同的窗口中完成计算。Flink使用TimeWindow类来获取窗口的起始时间和终止时间，以及该窗口允许进入的最新时间戳信息等元数据。

### 计数窗口（CountWindow）
基于元素的个数来截取数据，到达固定的个数时就触发计算并关闭窗口。

计数窗口理解简单，只需指定窗口大小，就可以把数据分配到对应的窗口中，Flink内部对应的类来表示计数窗口，底层通过全局窗口（Global Window）实现

### 时间窗口 (TimeWindow)
时间窗口以时间点到来定义窗口的开始（start）和结束（end），所以截取出的就是某一时间段的数据。到达时间时，窗口不再收集数据，触发计算输出结果，并将窗口关闭销毁。

窗口大小 = 结束时间 - 开始时间

Flink中有一个专门的TimeWindow类来表示时间窗口，这个类只有两个私有属性，表示窗口的开始和结束的时间戳，单位为毫秒
```
private final long start;
private final long end;
```
我们可以调用公有的getStart()和getEnd()方法直接获取这两个时间戳。另外TimeWindow还提供了maxTimestamp()方法，用来获取窗口中能够包含数据的最大时间戳，窗口中运行的最大时间戳为end - 1，这代表了我们定义的窗口时间范围都是左闭右开的区间[start,end)
```
public long maxTimestamp(){
    return end - 1;
}
```

## 按照窗口分配数据的规则分类
时间窗口、计数窗口只是对窗口的一个大致划分。在具体应用时，还需要定义更加精细的规则，来控制数据应该划分到哪个窗口中去。不同的分配数据的方式，就可以由不同的功能应用。
根据Windows Assigner数据分配方式的不同将Windows分为4大类，分别是
- 滚动窗口(Tumbling Windows)
- 滑动窗口（Sliding Windows）
- 会话窗口（Session Windows）
- 全局窗口（Global Windows）。

### 滚动窗口（Tumbling Windows）
滚动窗口是根据固定时间或大小进行切分，且窗口和窗口之间的元素互不重叠。这种类型的窗口的最大特点是比较简单，但可能会导致某些有前后关系的数据计算结果不正确，而对于按照固定大小和周期统计某一指标的这种类型的窗口计算就比较适合，同时实现起来也比较方便。

滚动窗口有固定的大小，是一种对数据进行“均匀切片”的划分方式，首尾相接。因为滚动窗口无缝衔接，所以每个数据都会被分配到一个窗口，而且只会属于一个窗口。

滚动窗口可以基于时间定义，也可以基于数据个数定义；需要的参数只有窗口大小，我们可以定义一个长度为1小时的滚动时间窗口，那么每个小时就会进行一次统计；或者定义一个长度为10的滚动计数窗口，就会每10个数进行一次统计

### 滑动窗口（Sliding Windows）
滑动窗口的大小固定，但窗口之间不是首尾相接，而有部分重合。滑动窗口可以基于时间定义、数据个数。

定义滑动窗口的参数与两个：窗口大小，滑动步长。滑动步长是固定的，且代表了两个个窗口开始/结束的时间间隔。数据分配到多个窗口的个数 = 窗口大小/滑动步长

### 会话窗口（Session Windows）
会话窗口只能基于时间来定义，“会话”终止的标志就是隔一段时间没有数据来。

size：两个会话窗口之间的最小距离。我们可以设置静态固定的size，也可以通过一个自定义的提取器（gap extractor）动态提取最小间隔gap的值。

在Flink底层，对会话窗口有比较特殊的处理：每来一个新的数据，都会创建一个新的会话窗口，然后判断已有窗口之间的距离，如果小于给定的size，就对它们进行合并操作。在Winodw算子中，对会话窗口有单独的处理逻辑。

会话窗口的长度不固定、起始和结束时间不确定，各个分区窗口之间没有任何关联。会话窗口之间一定是不会重叠的，且会留有至少为size的间隔

### 全局窗口（Global Windows）
相同key的所有数据都分配到一个同一个窗口中；无界流的数据永无止境，窗口没有结束的时候，默认不做触发计算，如果希望对数据进行计算处理，还需要自定义“触发器”（Trigger）

## 窗口API概览

## 按键分区窗口（Keyed）和非按键分区（Non-Keyed）
在定义窗口操作之前，首先需要确定，到达是基于按键分区（Keyed）的数据流KeyedStream来开窗，还是直接在没有按键分区的DataStream上开窗。也就是在调用窗口算子之前是否有keyBy操作

### 按键分区窗口（Keyed Windows）
经过按按键分区keyBy操作后，数据流会按照key被分为多条逻辑流（logical streams），也就是KeyedStream。基于KeyedStream进行窗口操作时，窗口计算会在多个并行子任务上同时执行。相同key的数据被发送到同一个并行子任务，而窗口操作会基于每个key单独的处理。可以认为每个key上都定义了一组窗口，各自独立地进行统计计算。
```
stream.keyBy(...)
	.window(...)
```

### 非按键分区（Non-Keyed Windows）
如果没有进行keyBy，那么原始的DataStream就不会分成多条逻辑流。这时窗口逻辑只能在一个任务(task)上执行，相当于并行度变成了1
```
stream.windowAll(...)
```

## 代码中窗口API的调用
Windows计算是流式计算中非常常用的数据计算方式之一，通过按照固定时间或长度将数据流切分成不同的窗口，然后对数据进行相应的聚合运算，从而得到一定时间范围内的统计结果。

窗口的操作主要有两个部分：窗口分配器（Window Assigners）和窗口函数（Window Functions）

每个窗口算子中包含了Windows Assigner、Windows Trigger（窗口触发器）、Evictor（数据剔除器）、Lateness（时延设定）、Output Tag（输出标签）以及Windows Funciton等组成部分

其中Windows Assigner和Windows Funciton是所有窗口算子必须指定的属性，其余的属性都是根据实际情况选择指定。

```
stream.keyBy(<key selector>)       // 是Keyed类型数据集
	 .window(<window assigner>)    //指定窗口分配器类型
 	 .reduce/aggregate/fold/apply()   //指定窗口计算函数
 	    [.trigger(...)] //指定触发器类型（可选）
        [.evictor(...)]    //指定evictor或者不指定（可选）
        [.allowedLateness(...)]   //指定是否延迟处理数据（可选）
        [.sideOutputLateData(...)] //指定Output Lag（可选）        
        [.getSideOutput(...)]    //根据Tag输出数据（可选）
```

## 窗口分配器（Window Assigners）
定义窗口分配器是构建窗口算子的第一步，作用是定义数据应该被“分配”到哪个窗口。

窗口按照驱动类型可以分成时间窗口和计数窗口，按照具体的分配规定为滚动窗口、滑动窗口、会话窗口、全局窗口。除去自定义外的全局窗口外，其它常用的类型Flink都给出了内置的分配器实现。

### 时间窗口
时间窗口又可以细分为：滚动、滑动、会话三种

#### 滚动处理时间窗口
```
stream.keyBy(...)
	.window(TumblingProcessingTimeWindows.of(Time.seconds(5)))
	.aggregate(...)
```
这里创建了一个长度为5秒的滚动窗口。

.of()还有一个重载方法，可以传入两个Time类型的参数：size和offset。第二个参数代表窗口起始点的偏移量，比如，标志时间戳是1970年1月1日0时0分0秒0毫秒开始计算的一个毫秒数，这个时间时UTC时间，以0时区为标准，而我们所在的时区为东八区（UTC+8）。我们定义一天滚动窗口时，伦敦时间0但对应北京时间早上8点。那么设定如下就可以得到北京时间每天0点开开启滚动窗口
```
.window(TumblingProcessingTimeWindows.of(Time.days(1), Time.hours(-8)))
```

#### 滑动处理时间窗口
```
stream.keyBy(...)
	.window(SlidingProcessingTimeWindows.of(Time.seconds(10), Time.seconds(5)))
	.aggregate(...)
```
两个Time类型的参数：size和slide。后者表示滑动窗口的滑动步长。当然，可以追加第三个参数offset，用法同上

#### 处理时间会话窗口
```
stream.keyBy(...)
	.window(ProcessingTimeSessionWindows.withGap(Time.seconds(10)))
	.aggregate(...)
```
.withGap()方法需要传入一个Time类型的参数size，表示会话的超时时间，也就是最小间隔session gap，静态的
```
.window(ProcessingTimeSessionWindows.withDynamicGap(new
    SessionWindowTimeGapExtractor<Tuple2<String, Long>>() {
     @Override
     public long extract(Tuple2<String, Long> element) {
    	// 提取 session gap 值返回, 单位毫秒
     	return element.f0.length() * 1000;
     }
}))
```
动态提取时间间隔，这里我们提取了数据元素的第一个字段，用它的长度乘以1000作为会话超时的间隔

#### 滚动事件时间窗口
```
stream.keyBy(...)
	.window(TumblingEventTimeWindows.of(Time.seconds(5)))
	.aggregate(...)
```

#### 滑动事件时间窗口
```
stream.keyBy(...)
.window(SlidingEventTimeWindows.of(Time.seconds(10), Time.seconds(5)))
.aggregate(...)
```

#### 事件时间会话窗口
```
stream.keyBy(...)
	.window(EventTimeSessionWindows.withGap(Time.seconds(10)))
	.aggregate(...)
```

### 计数窗口
底层是全局窗口，Flink为我们提供了非常方便地接口：直接调用countWindow()方法，根据分配规则的不同，又可以分为滚动计数、滑动计数窗口。

#### 滚动计数窗口
```
stream.keyBy(...)
	.countWindow(10)
```

#### 滑动计数窗口
```
stream.keyBy(...)
	.countWindow(10，3)
```
长度为10，滑动步长为3

### 全局窗口
```
stream.keyBy(...)
	.window(GlobalWindows.create());
```
使用全局窗口，必须自行定义触发器才能实现窗口计算，否则起不到任何作用。

## 窗口函数（Window Functions）
定义窗口分配，我们知道了数据属于哪个窗口；定义窗口函数，如何进行计算的操作，这就是所谓的“窗口函数”。

窗口函数定义了要对窗口中收集的数据做的计算操作，根据处理的方式可以分为两类：增量聚合函数、全窗口函数

### 增量函数
窗口将数据收集起来，最基本的处理操作当然就是进行聚合。窗口对无限流的切分，可以看作得到了一个有界数据集。如果我们等到所有数据都收集齐，在窗口到了结束时间要输出结果的一瞬间再去进行聚合，显然就不够高效了——批处理的思路做实时处理

为了提高实时性，我们可以每来一条数据就立即进行计算，中间只要保持一个简单的聚合状态就可以了；区别只是在于不立即输出结果，而是要等到窗口结束时间拿出之前聚合的状态直接输出。

典型的增量聚合函数有两个：ReduceFunction、AggregateFunction

#### 归约函数（ReduceFunction）
将窗口收集到的数据两两进行归约，实现增量式的聚合。

窗口函数提供了ReduceFunction
```java
import com.demo.Source.ClickSource;
import com.demo.Source.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.common.functions.ReduceFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;

import java.time.Duration;

public class WindowReduceExample {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);

        // 从自定义数据源读取数据，并提取时间戳、生成水位线
        SingleOutputStreamOperator<Event> stream = env.addSource(new ClickSource())
                .assignTimestampsAndWatermarks(WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ZERO)
                        .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
                            @Override
                            public long extractTimestamp(Event element, long recordTimestamp) {
                                return element.timestamp;
                            }
                        }));

        stream.map(new MapFunction<Event, Tuple2<String, Long>>() {
            @Override
            public Tuple2<String, Long> map(Event value) throws Exception {
                // 将数据转换成二元组，方便计算
                return Tuple2.of(value.user, 1L);
            }
        }).keyBy(r -> r.f0)
                // 设置滚动事件时间窗口
                .window(TumblingEventTimeWindows.of(Time.seconds(5)))
                .reduce(new ReduceFunction<Tuple2<String, Long>>() {
                    @Override
                    public Tuple2<String, Long> reduce(Tuple2<String, Long> value1, Tuple2<String, Long> value2) throws Exception {
                        // 定义累加规则，窗口闭合时，向下游发送累加结果
                        return Tuple2.of(value1.f0, value1.f1 + value2.f1);
                    }
                }).print();

        env.execute();
    }
}
```

#### 聚合函数（AggregateFunction）
ReduceFunction接口有一个限制：输入数据类型、聚合状同类型、输出结果的类型一样。这就迫使我们在聚会前先将数据转换成预期结果类型。而在有些情况下，需要对状态进一步处理才能得到输出结果时，这时它们的类型可能不同。

Flink的Window API中的aggregate就提供了这样的操作。直接基于WindowedStream调用.aggregate()方法，就可以定义更加灵活的窗口聚合操作。这个方法需要传入一个AggregateFunction的实现类

```java
public interface AggregateFunction<IN, ACC, OUT> extends Function, Serializable{
    ACC createAccumulator();
    ACC add(IN value, ACC accumulator);
    OUT getResult(ACC accumulator);
    ACC merge(ACC a, ACC b);
}
```
AggregateFunction可看作是ReduceFunction的通用版本，这里有三种类型：输入类型（IN）、累加器类型（ACC）、输出类型（OUT）
- createAccumulator()：创建一个累加器，为聚合创建一个初始状态
- add()：将输入的元素添加到累加器中，这就是基于聚合状态，对新来的数据进一步聚合。方法传入两个参数，当前新到的数据value，和当前的累加器accumulator，返回一个新的累加器值。
- getResult()：从累加器中提取聚合输出的结果。
- merge()：合并两个累加器，并将合并的状态作为一个累加器返回。这个方法只在需要合并窗口的场景下才会被调用；最常见的合并窗口的场景就是会话窗口

下面举个例子：PV（页面浏览量）和UV（独立访客量）是非常重要的两个流量指标，我们计算 PV/UV
```java
import com.demo.Source.ClickSource;
import com.demo.Source.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;

import java.time.Duration;
import java.util.HashSet;

public class WindowAggregateTest_PVUV {

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        env.getConfig().setAutoWatermarkInterval(100);

        SingleOutputStreamOperator<Event> stream = env.addSource(new ClickSource())
                //乱序流的watermark生成
                .assignTimestampsAndWatermarks(WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(0))
                        .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
                            @Override
                            public long extractTimestamp(Event element, long recordTimestamp) {
                                return element.timestamp;
                            }
                        }));
        stream.print("data");
        // 所有数据放在一起统计pv和uv
        stream.keyBy(data -> true)
                .window(SlidingEventTimeWindows.of(Time.seconds(10),Time.seconds(2)))
                .aggregate(new AvgPv()).print();

        env.execute();
    }

    //自定义一个AggregateFunction，用Long保存pv个数，用HashSet做uv去重
    public static class AvgPv implements AggregateFunction<Event, Tuple2<Long, HashSet<String>>,Double>{

        @Override
        public Tuple2<Long, HashSet<String>> createAccumulator() {
            return Tuple2.of(0L,new HashSet<>());
        }

        @Override
        public Tuple2<Long, HashSet<String>> add(Event value, Tuple2<Long, HashSet<String>> accumulator) {
            //每来一条数据，pv个数+1，将user放入HashSet中
            accumulator.f1.add(value.user);
            return Tuple2.of(accumulator.f0 + 1,accumulator.f1);
        }

        @Override
        public Double getResult(Tuple2<Long, HashSet<String>> accumulator) {
            //窗口触发时，输出pv和uv的比值
            return (double) accumulator.f0 / accumulator.f1.size();
        }

        @Override
        public Tuple2<Long, HashSet<String>> merge(Tuple2<Long, HashSet<String>> a, Tuple2<Long, HashSet<String>> b) {
            return null;
        }
    }
    
}
```

### 全窗口函数（full window functions）
全窗口需要先收集窗口中的数据，并在内部缓存起来，等到窗口要输出结果的时候再取出数据进行计算。

典型的批处理思路——先攒数据，等一批都到齐了再正式启动处理流程。这种相较之下是低效的。

Flink中，全窗口函数也有两种：WindowFunction和ProcessWindowFunction

#### 窗口函数（WindowFunction）
WindowFunction是老版本的通用窗口函数接口，我们可以基于WindowedStream调用.apply()方法，传入一个WindowFunction实现类
```
stream
 .keyBy(<key selector>)
 .window(<window assigner>)
 .apply(new MyWindowFunction());
```

这个类接口的源码如下：
```java
public interface WindowFunction<IN, OUT, KEY, W extends Window> extends Function,Serializable {
    void apply(KEY key, W window, Iterable<IN> input, Collector<OUT> out) throws Exception;
}
```
当窗口到达结束时间需要触发计算时，就会调用这里的apply方法。我们可以从input集合中取出窗口收集的数据，结合key和window信息，通过收集器输出结果。WindowFunction的作用可以被ProcessWindowFunction全覆盖，一般在实际应用中，直接使用ProcessWindowFunction就可以

#### 处理窗口函数（ProcessWindowFunction）
ProcessWindowFunction 是 Window API 中最底层的通用窗口函数接口，他可以获取到一个“上下文对象”（Context）。这个上下文对象不仅能够获取窗口信息，还可以访问当前的时间和状态信息，这里的时间就包括了处理时间和事件时间水位线。

例子：求UV
```
import com.demo.Source.ClickSource;
import com.demo.Source.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.windowing.ProcessWindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.Collector;

import java.sql.Timestamp;
import java.time.Duration;
import java.util.HashSet;

public class WindowProcessTest {

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        env.getConfig().setAutoWatermarkInterval(100);

        SingleOutputStreamOperator<Event> stream = env.addSource(new ClickSource())
                //乱序流的watermark生成
                .assignTimestampsAndWatermarks(WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(0))
                        .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
                            @Override
                            public long extractTimestamp(Event element, long recordTimestamp) {
                                return element.timestamp;
                            }
                        }));
        //使用ProcessWindowFunction计算UV
        stream.keyBy(data -> true)
                .window(TumblingEventTimeWindows.of(Time.seconds(10)))
                .process(new UvCountByWindow())
                .print();

        env.execute();
    }

    //实现自定义的ProcessWindowFunction，输出一条统计信息
    public static class UvCountByWindow extends ProcessWindowFunction<Event,String,Boolean, TimeWindow>{

        @Override
        public void process(Boolean aBoolean, Context context, Iterable<Event> elements, Collector<String> out) throws Exception {
            //用一个HashSet保存user
            HashSet<String> userSet = new HashSet<>();
            //从elements中遍历数据，放到set中去重
            for (Event element : elements) {
                userSet.add(element.user);
            }

            Integer uv = userSet.size();
            //结合窗口信息
            Long start = context.window().getStart();
            Long end = context.window().getEnd();
            out.collect("窗口" + new Timestamp(start) + "~" + new Timestamp(end) + "UV值为：" + uv);
        }
    }
}
```
增量聚合和全窗口结合
增量聚合的优点：高效，输出更加实时

全窗口的优点：提供更多的信息，更加“通用”的窗口操作。

在实际应用中，我们往往希望兼具这两者的优点,，结合使用，我们在传入窗口函数哪里，这里调用的机制：第一个参数（增量聚合函数）来处理窗口数据，每来一个数据就做一次聚合；等到窗口需要触发计算时，则调用第二个参数（全窗口函数）的处理逻辑输出结果。需要注意的是，这里的全窗口函数就不再缓存所有数据了，而是直接将增量聚合函数的结果拿来当做Iterable类型的输出。

例子：

为了方便处理，单独定义了一个POJO类，来表示输出结果的数据类型
```java
public class UrlViewCount {
    public String url;
    public Long count;
    public Long windowStart;
    public Long windowEnd;

    public UrlViewCount() {
    }

    public UrlViewCount(String url, Long count, Long windowStart, Long windowEnd) {
        this.url = url;
        this.count = count;
        this.windowStart = windowStart;
        this.windowEnd = windowEnd;
    }

    @Override
    public String toString() {
        return "UrlViewCount{" +
                "url='" + url + '\'' +
                ", count=" + count +
                ", windowStart=" + new Timestamp(windowStart) +
                ", windowEnd=" + new Timestamp(windowEnd) +
                '}';
    }
}
```

```java
import com.demo.Source.ClickSource;
import com.demo.Source.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.windowing.ProcessWindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.Collector;

public class UrlCountViewExample {

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        env.getConfig().setAutoWatermarkInterval(100);

        SingleOutputStreamOperator<Event> stream = env.addSource(new ClickSource())
                //乱序流的watermark生成
                .assignTimestampsAndWatermarks(WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(0))
                        .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
                            @Override
                            public long extractTimestamp(Event element, long recordTimestamp) {
                                return element.timestamp;
                            }
                        }));
        stream.print("input");

        //统计每个url的访问量
        stream.keyBy(data -> data.url)
                .window(TumblingEventTimeWindows.of(Time.seconds(10)))
                .aggregate(new UrlViewCountAgg(),new UrlViewCountResult())
                .print();


        env.execute();
    }

    //增量聚合，来一条数据 + 1
    public static class UrlViewCountAgg implements AggregateFunction<Event,Long,Long>{

        @Override
        public Long createAccumulator() {
            return 0L;
        }

        @Override
        public Long add(Event value, Long accumulator) {
            return accumulator + 1;
        }

        @Override
        public Long getResult(Long accumulator) {
            return accumulator;
        }

        @Override
        public Long merge(Long a, Long b) {
            return null;
        }
    }

    //包装窗口信息，输出UrlViewCount
    public static class UrlViewCountResult extends ProcessWindowFunction<Long,UrlViewCount,String, TimeWindow>{

        @Override
        public void process(String s, Context context, Iterable<Long> elements, Collector<UrlViewCount> out) throws Exception {
            Long start = context.window().getStart();
            Long end = context.window().getEnd();
            Long count = elements.iterator().next();
            out.collect(new UrlViewCount(s,count,start,end));
        }
    }
}
```

测试水位线和窗口的使用
```java
import com.demo.Source.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.windowing.ProcessWindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.Collector;

import java.time.Duration;

public class WatermarkTest2 {

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env =
                StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        // 将数据源改为 socket 文本流，并转换成 Event 类型
        env.socketTextStream("hadoop102", 7777)
                .map(new MapFunction<String, Event>() {
                    @Override
                    public Event map(String value) throws Exception {
                        String[] fields = value.split(",");
                        return new Event(fields[0].trim(), fields[1].trim(),
                                Long.valueOf(fields[2].trim()));
                    }
                })
                // 插入水位线的逻辑
                .assignTimestampsAndWatermarks(
                        // 针对乱序流插入水位线，延迟时间设置为 5s
                        WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(5))
                                .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
                                    // 抽取时间戳的逻辑
                                    @Override
                                    public long extractTimestamp(Event element, long recordTimestamp) {
                                        return element.timestamp;
                                    }
                                })
                )
                // 根据 user 分组，开窗统计
                .keyBy(data -> data.user)
                .window(TumblingEventTimeWindows.of(Time.seconds(10)))
                .process(new WatermarkTestResult())
                .print();
        env.execute();
    }

    // 自定义处理窗口函数，输出当前的水位线和窗口信息
    public static class WatermarkTestResult extends ProcessWindowFunction<Event, String, String, TimeWindow> {
        @Override
        public void process(String s, Context context, Iterable<Event> elements, Collector<String> out) throws Exception {
            Long start = context.window().getStart();
            Long end = context.window().getEnd();
            Long currentWatermark = context.currentWatermark();
            Long count = elements.spliterator().getExactSizeIfKnown();
            out.collect("窗口" + start + " ~ " + end + "中共有" + count + "个元素， 窗口闭合计算时，水位线处于：" + currentWatermark);
        }
    }

}
```

## 其他API
对于一些窗口算子而言，窗口分配器和窗口函数是必不可少的，除此之外，Flink还提供了其他一些可选的API，可让我们更加灵活地控制窗口行为

## 触发器（Trigger）
调用trigger()方法，就可以传入一个自定义的窗口触发器
```
stream.keyBy(...)
 	.window(...)
 	.trigger(new MyTrigger())
```
Trigger 是窗口算子的内部属性，每个窗口分配器（WindowAssigner）都会对应一个默认 的触发器；对于 Flink 内置的窗口类型，它们的触发器都已经做了实现。例如，所有事件时间 窗口，默认的触发器都是 EventTimeTrigger；类似还有 ProcessingTimeTrigger 和 CountTrigger。 所以一般情况下是不需要自定义触发器的，不过我们依然有必要了解它的原理。 Trigger 是一个抽象类，自定义时必须实现下面四个抽象方法：

- onElement()：窗口中每到来一个元素，都会调用这个方法
- onEventTime()：当注册的事件时间定时触发时，将调用这个方法
- onProcessingTime()：当注册的处理时间定时器触发时，将调用这个方法
- clear()：当窗口关闭销毁时，调用这个方法。一般用来清除自定义的状态。

这些参数都有都有一个触发器上下文（TriggerContext）对象，可以用来注册定时器回调（callback）。都有一个“触发器上下文”（TriggerContext）对象，可以用来注册定时器回调（callback）。这 里提到的“定时器”（Timer），其实就是我们设定的一个“闹钟”，代表未来某个时间点会执行 的事件。

上面的前三个方法返回类型都是TriggerResult，这是一个枚举类型（enum），其中定义了对窗口进行操作的四种类型

- CONTINUE(继续)：什么都不做
- FIRE(触发)：触发计算，输出结果
- PURGE(清除)：清空窗口中的所有数据，销毁窗口
- FIRE_AND_PURGE（触发并清除）：触发计算输出结果，并清除窗口

```java
import com.demo.Source.ClickSource;
import com.demo.Source.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.state.ValueState;
import org.apache.flink.api.common.state.ValueStateDescriptor;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.windowing.ProcessWindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.triggers.Trigger;
import org.apache.flink.streaming.api.windowing.triggers.TriggerResult;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.Collector;


public class TriggerExample {

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        env.addSource(new ClickSource()).assignTimestampsAndWatermarks(WatermarkStrategy.<Event>forMonotonousTimestamps()
                .withTimestampAssigner(new SerializableTimestampAssigner<Event>() {
                    @Override
                    public long extractTimestamp(Event event, long l) {
                        return event.timestamp;
                    }
                })
        )
                .keyBy(r -> r.url)
                .window(TumblingEventTimeWindows.of(Time.seconds(10)))
                .trigger(new MyTrigger())
                .process(new WindowResult())
                .print();

        env.execute();
    }

    public static class WindowResult extends ProcessWindowFunction<Event, UrlViewCount, String, TimeWindow> {
        @Override
        public void process(String s, Context context, Iterable<Event> iterable, Collector<UrlViewCount> collector) throws Exception {
            collector.collect(
                    new UrlViewCount(
                            s,
                            // 获取迭代器中的元素个数
                            iterable.spliterator().getExactSizeIfKnown(),
                            context.window().getStart(),
                            context.window().getEnd()
                    )
            );
        }
    }

    public static class MyTrigger extends Trigger<Event, TimeWindow> {
        @Override
        public TriggerResult onElement(Event event, long l, TimeWindow timeWindow, TriggerContext triggerContext) throws Exception {
            ValueState<Boolean> isFirstEvent = triggerContext.getPartitionedState(new ValueStateDescriptor<Boolean>("first-event", Types.BOOLEAN));
            if (isFirstEvent.value() == null) {
                for (long i = timeWindow.getStart(); i < timeWindow.getEnd(); i = i + 1000L) {
                    triggerContext.registerEventTimeTimer(i);
                }
                isFirstEvent.update(true);
            }
            return TriggerResult.CONTINUE;
        }

        @Override
        public TriggerResult onEventTime(long l, TimeWindow timeWindow, TriggerContext triggerContext) throws Exception {
            return TriggerResult.FIRE;
        }

        @Override
        public TriggerResult onProcessingTime(long l, TimeWindow timeWindow, TriggerContext triggerContext) throws Exception {
            return TriggerResult.CONTINUE;
        }

        @Override
        public void clear(TimeWindow timeWindow, TriggerContext triggerContext) throws Exception {
            ValueState<Boolean> isFirstEvent = triggerContext.getPartitionedState(
                    new ValueStateDescriptor<Boolean>("first-event", Types.BOOLEAN)
            );
            isFirstEvent.clear();
        }
    }
}
```

## 移除器（Evictor）
移除器主要用来定义移除某些数据的逻辑，实现evictor()方法，就可以传入一个自定义的移除器（Evictor），Evictor 是一个接口，不同的窗口类型都有各自预实现的移除器
```
stream.keyBy(...)
 	.window(...)
 	.evictor(new MyEvictor())
```
Evictor 接口定义了两个方法：
- evictBefore()：定义执行窗口函数之前的移除数据操作
- evictAfter()：定义执行窗口函数之后的数据操作
默认情况下，预实现的移除器都是在执行窗口函数（window fucntions）之前移除数据的

## 允许延迟（Allowed Lateness）
在事件时间语义下，窗口中可能会出现数据迟到的情况。这是因为在乱序流中，水位线 （watermark）并不一定能保证时间戳更早的所有数据不会再来。

Flink一个了一个特殊的接口，可以为窗口算子设置一个“运行的最大延迟”，也就是说我们可以设定允许延迟一段时间。

水位线 = 窗口结束时间 + 延迟时间
```
stream.keyBy(...)
 	.window(TumblingEventTimeWindows.of(Time.hours(1)))
 	.allowedLateness(Time.minutes(1))
```

## 将迟到的数据放入侧输出流
Flink 还提供了另外一种方式处理迟到数据。我们可以将未收入窗口的迟到数据，放入“侧 输出流”（side output）进行另外的处理。所谓的侧输出流，相当于是数据流的一个“分支”， 这个流中单独放置那些错过了该上的车、本该被丢弃的数据

sideOutputLateData() 方法，传入一个输出标签，用来标记分治的迟到数据流
```
DataStream<Event> stream = env.addSource(...);
OutputTag<Event> outputTag = new OutputTag<Event>("late") {};
stream.keyBy(...)
 	.window(TumblingEventTimeWindows.of(Time.hours(1)))
	.sideOutputLateData(outputTag)
```
将迟到数据放入侧输出流之后，还应该可以将它提取出来。基于窗口处理完成之后的 DataStream，调用.getSideOutput()方法，传入对应的输出标签，就可以获取到迟到数据所在的流了
```
SingleOutputStreamOperator<AggResult> winAggStream = stream.keyBy(...)
 	.window(TumblingEventTimeWindows.of(Time.hours(1)))
	.sideOutputLateData(outputTag)
	.aggregate(new MyAggregateFunction())
DataStream<Event> lateStream = winAggStream.getSideOutput(outputTag);
```
## 窗口的生命周期

### 窗口的创建
窗口的类型和基本信息由窗口分配器（window assigners）指定，但窗口不会预先创建好，而是由数据驱动创建。当第一个应该属于这个窗口的数据元素到达时，就会创建对应的窗口

### 窗口计算的触发
除了窗口分配器，每个窗口还会有自己的窗口函数（window functions）和触发器（trigger）。 窗口函数可以分为增量聚合函数和全窗口函数，主要定义了窗口中计算的逻辑；而触发器则是指定调用窗口函数的条件

对于不同的窗口类型，触发计算的条件也会不同。例如，一个滚动事件时间窗口，应该在 水位线到达窗口结束时间的时候触发计算，属于“定点发车”；而一个计数窗口，会在窗口中 元素数量达到定义大小时触发计算，属于“人满就发车”。所以 Flink 预定义的窗口类型都有 对应内置的触发器

对于事件时间窗口而言，除去到达结束时间的“定点发车”，还有另一种情形。当我们设置了允许延迟，那么如果水位线超过了窗口结束时间、但还没有到达设定的最大延迟时间，这 期间内到达的迟到数据也会触发窗口计算

### 窗口的消耗
一般情况下，当时间达到了结束点，就会直接触发计算输出结果、进而清除状态销毁窗口。 这时窗口的销毁可以认为和触发计算是同一时刻。这里需要注意，Flink 中只对时间窗口 （TimeWindow）有销毁机制；由于计数窗口（CountWindow）是基于全局窗口（GlobalWindw） 实现的，而全局窗口不会清除状态，所以就不会被销毁。

在特殊的场景下，窗口的销毁和触发计算会有所不同。事件时间语义下，如果设置了允许延迟，那么在水位线到达窗口结束时间时，仍然不会销毁窗口；窗口真正被完全删除的时间点， 是窗口的结束时间加上用户指定的允许延迟时间

### 窗口API调用总结
Window API 首先按照时候按键分区分成两类。keyBy 之后的 KeyedStream，可以调 用.window()方法声明按键分区窗口（Keyed Windows）；而如果不做 keyBy，DataStream 也可 以直接调用.windowAll()声明非按键分区窗口

接下来首先是通过.window()/.windowAll()方法定义窗口分配器，得到 WindowedStream； 然 后 通 过 各 种 转 换 方 法 （ reduce/aggregate/apply/process ） 给 出 窗 口 函 数 (ReduceFunction/AggregateFunction/ProcessWindowFunction)，定义窗口的具体计算处理逻辑， 转换之后重新得到 DataStream。这两者必不可少，是窗口算子（WindowOperator）最重要的组成部分

此外，在这两者之间，还可以基于 WindowedStream 调用.trigger()自定义触发器、调 用.evictor()定义移除器、调用.allowedLateness()指定允许延迟时间、调用.sideOutputLateData() 将迟到数据写入侧输出流，这些都是可选的 API，一般不需要实现。而如果定义了侧输出流， 可以基于窗口聚合之后的 DataStream 调用.getSideOutput()获取侧输出流













