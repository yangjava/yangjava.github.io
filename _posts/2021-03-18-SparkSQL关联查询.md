---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# SparkSQL关联查询
在数据分析应用中，Join一直以来都是常用的算子，可以将多个关系数据表按照一定的条件连接在一起。对于大数据SQL查询引擎来讲，高效地执行Join至关重要。在分布式集群环境下，因为涉及数据在不同节点间Shuffle，Join可以算是代价最昂贵的操作，背后的实现原理也最复杂。本章对Spark SQL中Join操作的内部机制进行深入剖析，以帮助读者了解其基本实现方式。

## Join查询概述
熟悉关系代数的读者应该知道，在数据库设计阶段通常都会遵循一定的范式，以减少数据模型的冗余。这种设计理念对于OLTP（在线事务处理）类型的应用非常友好，但是在面对多表数据分析的需求时，必须将多个分散的数据表关联起来，也就是需要进行Join操作。在ANSI SQL标准中，共有5种Join方式：内连接（Inner）、全外连接（FullOuter）、左外连接（LeftOuter）、右外连接（RightOuter）和交叉连接（Cross）。

Join查询在时间和空间上都有着很高的复杂度，执行代价比较大，有时还会面临“数据倾斜”等棘手的情况。从20世纪80年代起，关于Join的优化一直都是业界和学术界研究的重点。例如，近年来兴起的“NoSQL运动”，主要理念之一就是鼓励数据分析人员通过设计“宽表”来直接避免Join查询。

本章仍然通过一个简单的例子，从细节层面分析Join的完整实现流程。这里将Join查询中涉及的关系数据表称为“基本表”，假设除student基本表外，还有一个记录了学生成绩的基本表exam，包含studentId和score两列。如果想要知道每个学生的姓名（name）和考试成绩（score），在查询层面就需要对student表和exam表进行连接操作，对应的SQL查询语句如下：
```

```






