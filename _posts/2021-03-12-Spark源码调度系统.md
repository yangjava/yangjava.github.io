---
layout: post
categories: [Spark]
description: none
keywords: Spark
---
# Spark源码调度系统

## 调度系统
在Spark集群上运行的任务多种多样，有的任务计算的数据量很大，有的任务执行的时间较长，有的任务执行的优先级较高，有的任务对公司的业务非常重要。整个Spark集群中各个机器的资源情况又有很多差异，有些机器CPU内核数较多，有些机器的内存很大，有些机器的磁盘空间非常充足，有些机器的网卡配置较高。有些机器在同一个机架上，有些机器可能在其他机房。任务应当分配在哪些机器上执行，任务应当分配多少资源，任务又应当有怎样的优先级？对集群资源及任务的合理分配与调度将决定整个集群的性能和效率。

## 调度系统概述
简单来讲，Spark调度系统用于将用户提交的“任务”调度到集群中的不同节点执行。但是Spark实现的调度系统，并非一句话所概括的这么简单。Spark资源调度分为两层：第一层是Cluster Manager（在YARN模式下为ResourceManager，在Mesos模式下为Mesos Master，在Standalone模式下为Master），将资源分配给Application；第二层是Application，进一步将资源分配给Application的各个Task。

第一层调度中，Standalone模式下的Master对资源的调度，至于其他模式中ResourceManager、Mesos Master对资源的调度，读者可以查阅YARN或Mesos的相关资料了解。

调度的对象是什么？作业或者任务。在业务场景中所说的任务与Spark集群中运行的任务在概念上存在很多偏差。人类往往把一件要做的事情认为是任务，因此“向Spark集群提交一个任务”这句话看似合情合理。工程师向Spark提交的一个任务，Spark却看作一个作业（Job）。

Spark首先会对Job进行一系列RDD转换，并通过RDD之间的依赖关系构建有向无环图（Direct Acyclic Graph，DAG）。然后根据RDD依赖的不同将RDD划分到不同的阶段（Stage），每个阶段按照分区（Partition）的数量创建多个任务（Task）。最后将这些任务提交到集群的各个运行节点上运行。因此Spark中的Task和业务场景中所述的任务是不同的。

## 工作流程
Spark调度系统主要由DAGScheduler和TaskScheduler构成。调度系统的主要工作流程如下。

- build operator DAG
用户提交的Job将首先被转换为一系列RDD并通过RDD之间的依赖关系构建DAG，然后将RDD构成的DAG提交到调度系统。

- split graph into stages of tasks
DAGScheduler负责接收由RDD构成的DAG，将一系列RDD划分到不同的Stage。根据Stage的不同类型（目前有ResultStage和Shuffle MapStage两种），给Stage中未完成的Partition创建不同类型的Task（目前有ResultTask和ShuffleMapTask两种）。每个Stage将因为未完成Partition的多少，创建零到多个Task。DAGScheduler最后将每个Stage中的Task以任务集合（TaskSet）的形式提交给Task Scheduler继续处理。

- launch tasks via cluster manager
使用集群管理器（cluster manager）分配资源与任务调度，对于失败的任务还会有一定的重试与容错机制。TaskScheduler负责从DAGScheduler接收TaskSet，创建TaskSetManager对TaskSet进行管理，并将此TaskSetManager添加到调度池中，最后将对Task的调度交给调度后端接口（SchedulerBackend）处理。SchedulerBackend首先申请TaskScheduler，按照Task调度算法（目前有FIFO和FAIR两种）对调度池中的所有TaskSetManager进行排序，然后对TaskSet按照最大本地性原则分配资源，最后在各个分配的节点上运行TaskSet中的Task。

- execute tasks
执行任务，并将任务中间结果和最终结果存入存储体系。






























