---
layout: post
categories: [Hadoop]
description: none
keywords: Hadoop
---
# Hadoop源码架构环境
HDFS作为一个分布式文件系统，是所有这些项目的基础。分析好HDFS，有利于了解其他系统。

## Hadoop源码架构
Hadoop包之间的依赖关系比较复杂，原因是HDFS提供了一个分布式文件系统，该系统提供API，可以屏蔽本地文件系统和分布式文件系统，甚至象Amazon S3这样的在线存储系统。这就造成了分布式文件系统的实现，或者是分布式文件系统的底层的实现，依赖于某些貌似高层的功能。

功能的相互引用，造成了蜘蛛网型的依赖关系。一个典型的例子就是包conf，conf用于读取系统配置，它依赖于fs，主要是读取配置文件的时候，需要使用文件系统，而部分的文件系统的功能，在包fs中被抽象了。

下面给出了Hadoop的包的功能分析。

| Package   | Dependences                                    |
|-----------|------------------------------------------------|
| tool      | 提供一些命令行工具，如DistCp，archive                      |
| mapreduce | Hadoop的Map/Reduce实现                            |
| filecache | 提供HDFS文件的本地缓存，用于加快Map/Reduce的数据访问速度            |
| fs        | 文件系统的抽象，可以理解为支持多种文件系统实现的统一文件访问接口               |
| hdfs      | HDFS，Hadoop的分布式文件系统实现                          |
| ipc       | 一个简单的IPC的实现，依赖于io提供的编解码功能                      |
| io        | 表示层。将各种数据编码/解码，方便于在网络上传输                       |
| net       | 封装部分网络功能，如DNS，socket                           |
| security  | 用户和用户组信息                                       |
| conf      | 系统的配置参数                                        |
| metrics   | 系统统计数据的收集，属于网管范畴                               |
| util      | 工具类                                            |
| record    | 根据DDL（数据描述语言）自动生成他们的编解码函数，目前可以提供C++和Java       |
| http      | 基于Jetty的HTTP Servlet，用户通过浏览器可以观察文件系统的一些状态信息和日志 |
| log       | 提供HTTP访问日志的HTTP Servlet                        |















